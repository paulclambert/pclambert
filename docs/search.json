[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Paul Lambert",
    "section": "",
    "text": "About me\nI am a biostatistician working at the Cancer Registry of Norway (Kreftregisteret). I also work part-time as a Guest Professor in the Biostatistics Group in the Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden. Previously, I worked at the Biostatistics Research Group at the University of Leicester, UK.\nI have a variety of interests, mainly in the area of survival analysis in epidemiology. Much of my work focuses on the analysis from data from national cancer registries. I particularly enjoy writing software (mainly in Stata) to enable transferal of new methods into practice.\nMy teaching is now mainly specialist courses. and have developed some interactive graphs to help with communication.\n\n\nEducation\n\nPhD in Biostatistics (1999). University of Leicester, UK\nMSc in Medical Statistics (1992). University of Leicester, UK"
  },
  {
    "objectID": "courses/stpm3course.html",
    "href": "courses/stpm3course.html",
    "title": "stpm3course (Stockholm 27 September 2024)",
    "section": "",
    "text": "A zip file containing the course material can be found here\nOr you can just download the lecture notes."
  },
  {
    "objectID": "courses/stpm3course.html#course-material",
    "href": "courses/stpm3course.html#course-material",
    "title": "stpm3course (Stockholm 27 September 2024)",
    "section": "",
    "text": "A zip file containing the course material can be found here\nOr you can just download the lecture notes."
  },
  {
    "objectID": "courses/stpm3course.html#required-software.",
    "href": "courses/stpm3course.html#required-software.",
    "title": "stpm3course (Stockholm 27 September 2024)",
    "section": "Required software.",
    "text": "Required software.\nIf you want to run the examples in the lecture notes / examples you will need to install some software in Stata.\n\nInstalling You will need to install the latest versions of the stpm3, standsurv, gensplines, survsim and addplot commands. You can install these from within Stata from SSC using the code below.\n\nssc install stpm3\nssc install standsurv\nssc install gensplines\nssc install survsim\nssc install addplot"
  },
  {
    "objectID": "courses/stpm3course.html#previous-versions-of-the-course",
    "href": "courses/stpm3course.html#previous-versions-of-the-course",
    "title": "stpm3course (Stockholm 27 September 2024)",
    "section": "Previous versions of the course",
    "text": "Previous versions of the course\n\nOslo 9 September 2024\n\nzipfile\nlecture notes"
  },
  {
    "objectID": "software/stpp/using_stpp.html",
    "href": "software/stpp/using_stpp.html",
    "title": "stpp - Estimating marginal relative (net) survival",
    "section": "",
    "text": "All examples below use the colon cancer data available with strs. I first load and stset the data.\nI have restricted follow-up time to 120.5 months (just over 10 years). Survival time information is available in completed months, so is 0.5 if someone died in the first month after diagnosis etc. stpp requires survival time in years, so I have used the scale(12) option to transform from months to years."
  },
  {
    "objectID": "software/stpp/using_stpp.html#age-standardization-using-individual-weights",
    "href": "software/stpp/using_stpp.html#age-standardization-using-individual-weights",
    "title": "stpp - Estimating marginal relative (net) survival",
    "section": "Age standardization using individual weights",
    "text": "Age standardization using individual weights\nAn alternative way to age standardize is to upweight or downweight individuals relative to the reference population (Rutherford et al 2020). This avoids the need to estimate separately in each if the age groups.\nFirst the weights need to be stored in a variable and then weights are calulated as the ratio of the proportion in the reference population to the proportion in the age group to which an individual belongs.\n. recode ICSSagegrp (1=0.07) (2=0.12) (3=0.23) (4=0.29) (5=0.29), gen(ICSSwt)\n(15,564 differences between ICSSagegrp and ICSSwt)\n\n. label define ICSSlab 1 \"&lt;45\" 2 \"45-54\" 3 \"55-64\" 4 \"65-75\" 5 \"75+\"  \n\n. label values ICSSagegrp ICSSlab\n\n. bysort sex: gen sextotal= _N\n\n. bysort ICSSagegrp sex:gen a_age = _N/sextotal\n\n. gen double wt_age = ICSSwt/a_age\nThe weights for males are shown below\n. by ICSSagegrp sex: gen firstrow = _n==1\n\n. list ICSSagegrp ICSSwt a_age wt_age if firstrow & sex==1, noobs ab(12)\n\n  +---------------------------------------------+\n  | ICSSagegrp   ICSSwt       a_age      wt_age |\n  |---------------------------------------------|\n  |        &lt;45      .07   .06056782   1.1557292 |\n  |      45-54      .12   .09321767   1.2873096 |\n  |      55-64      .23   .21577287   1.0659357 |\n  |      65-75      .29   .33375394   .86890359 |\n  |        75+      .29    .2966877    .9774588 |\n  +---------------------------------------------+\nThe variable ICSSwt shows the proportion in each age group in the reference population and the a_age variables gives the proportion observed in the study popopulation. For the youngest age group there are slightly smaller proportion in the study population and so each individual in this group is upweighted by 1.156. In the oldest age group there is a slighly higher proportion in the study population compared to the reference population and so each individual is slightly downweighted by 0.977.\nNow the weights have been calculated these can be passed to stpp using the indweights() option.\n. stpp R_pp4 using \"https://pclambert.net/data/popmort.dta\", ///\n&gt;       agediag(age) datediag(dx)                            ///\n&gt;       pmother(sex) list(1 5 10)                            ///\n&gt;       by(sex)                                              ///\n&gt;       indweights(wt_age)                                   ///\n&gt;       frame(PP4, replace)\n\n\nPohar Perme Estimates of Marginal Relative Survival\n\n\n-&gt; sex = 1\n\nTime       |   PP     (95% CI) \n-----------+--------------------------\n     1     | 0.692 (0.680 to 0.704)\n     5     | 0.484 (0.468 to 0.502)\n    10     | 0.425 (0.397 to 0.455)\n-----------+--------------------------\n\n-&gt; sex = 2\n\nTime       |   PP     (95% CI) \n-----------+--------------------------\n     1     | 0.696 (0.686 to 0.706)\n     5     | 0.485 (0.472 to 0.498)\n    10     | 0.452 (0.432 to 0.473)\n-----------+--------------------------\n\nWhen using the frame() option, we get the following.\n. frame PP4: list, noobs sepby(sex)\n\n  +------------------------------------------------+\n  | sex   time          PP      PP_lci      PP_uci |\n  |------------------------------------------------|\n  |   1      1    .6915091   .67955376   .70367476 |\n  |   1      5   .48429686   .46758633   .50160458 |\n  |   1     10   .42471792    .3967072   .45470644 |\n  |------------------------------------------------|\n  |   2      1   .69620949   .68639717   .70616207 |\n  |   2      5   .48530249    .4724804   .49847254 |\n  |   2     10   .45201192   .43213496   .47280317 |\n  +------------------------------------------------+\nWe can plot the non-parametric estimate as a function of time.\n. twoway (rarea R_pp4_lci R_pp4_uci _t if sex==1, sort color(red%30) connect(stairstep)) ///\n&gt;       (line R_pp4 _t if sex==1, sort lcolor(red) connect(stairstep))                   ///\n&gt;       (rarea R_pp4_lci R_pp4_uci _t if sex==2, sort color(blue%30) connect(stairstep)) ///\n&gt;       (line R_pp4 _t if sex==2, sort lcolor(blue) connect(stairstep))                  ///\n&gt;       ,legend(order(2 \"males\" 4 \"females\") ring(0) pos(1))                             ///\n&gt;       xtitle(\"Years from diagnosis\")                                                   ///\n&gt;       ytitle(Marginal relative survival)                                               ///\n&gt;       ylabel(,format(%3.1f))                                                           ///\n&gt;       name(R_pp4, replace)"
  },
  {
    "objectID": "software/stpp/using_stpp.html#references",
    "href": "software/stpp/using_stpp.html#references",
    "title": "stpp - Estimating marginal relative (net) survival",
    "section": "References",
    "text": "References\nI. Corazziari, M. Quinn, R. Capocaccia, R. Standard cancer patient population for age standardising survival ratios. Eur J Cancer 2004:40:2307-2316\nE. Coviello, P.W. Dickman, K. Seppä, A. Pokhrel. Estimating net survival using a life table approach. The Stata Journal 2015;15:173-185\nP.W. Dickman, E. Coviello, M.Hills, M. Estimating and modelling relative survival. The Stata Journal 2015;15:186-215\nM. Pohar Perme, J. Stare, J. Estève. On Estimation in Relative Survival Biometrics 2012;68:113-120\nRutherford, M.J., Dickman, P.W., Coviello, E. & Lambert, P.C. Estimation of age-standardized net survival, even when age-specific data are sparse. Cancer Epidemiology 2020, 67, 101745."
  },
  {
    "objectID": "software/stpm3/standsurv.html",
    "href": "software/stpm3/standsurv.html",
    "title": "Standardization",
    "section": "",
    "text": "I will not go into details of standsurv here. There are various tutorials here.\nThere main advantage of using stpm3 rather than stpm2 with standsurv is the support for factor variables. I will ilustrate this with an example.\nThe code below loads the example colon cancer data set.\n. use \"https://pclambert.net/data/colon.dta\", clear\n(Colon carcinoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm,f(status=1,2) id(id) scale(12) exit(time 120.5)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n     15,564  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     15,564  observations remaining, representing\n     15,564  subjects\n     10,459  failures in single-failure-per-subject data\n 51,685.667  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\n\n. gen male = sex==1\nTo illust rate the prediction options I will fit a model with an interaction between age and sex for both main and time-dependent effects, where the effect of age is modelled using natural splines.\n. stpm3 i.male##@ns(age,df(3)),                 ///\n&gt;       tvc(i.male##@ns(age,df(3))) dftvc(2)    ///\n&gt;       df(5) scale(lncumhazard)\n\nIteration 0:  Log likelihood = -26496.501  \nIteration 1:  Log likelihood = -26041.128  \nIteration 2:  Log likelihood = -26005.402  \nIteration 3:  Log likelihood = -26004.879  \nIteration 4:  Log likelihood = -26004.877  \n\n                                                       Number of obs =  15,564\n                                                       Wald chi2(7)  = 1029.65\nLog likelihood = -26004.877                            Prob &gt; chi2   =  0.0000\n\n-----------------------------------------------------------------------------------------------\n                              | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------------------+----------------------------------------------------------------\nxb                            |\n                       1.male |  -.2413054   .2648957    -0.91   0.362    -.7604915    .2778806\n                  _ns_f1_age1 |  -6.206267   .9371474    -6.62   0.000    -8.043042   -4.369492\n                  _ns_f1_age2 |  -.4202365   .4447267    -0.94   0.345    -1.291885    .4514119\n                  _ns_f1_age3 |  -1.728845   .2531885    -6.83   0.000    -2.225086   -1.232605\n                              |\n           male#c._ns_f1_age1 |\n                           1  |   .6846415   1.445986     0.47   0.636     -2.14944    3.518723\n                              |\n           male#c._ns_f1_age2 |\n                           1  |   .2790083   .6314231     0.44   0.659    -.9585582    1.516575\n                              |\n           male#c._ns_f1_age3 |\n                           1  |   .6956873   .4554633     1.53   0.127    -.1970044    1.588379\n------------------------------+----------------------------------------------------------------\ntime                          |\n                         _ns1 |  -10.15155   .8167647   -12.43   0.000    -11.75238   -8.550724\n                         _ns2 |   2.443526   .2234638    10.93   0.000     2.005545    2.881507\n                         _ns3 |  -1.284021   .1792894    -7.16   0.000    -1.635421   -.9326197\n                         _ns4 |  -.8369727   .1507723    -5.55   0.000    -1.132481   -.5414644\n                         _ns5 |  -.6772495   .1283478    -5.28   0.000    -.9288065   -.4256924\n                              |\n              male#c._ns_tvc1 |\n                           1  |   .4080991   .7632087     0.53   0.593    -1.087763    1.903961\n                              |\n              male#c._ns_tvc2 |\n                           1  |   1.358488   .6838173     1.99   0.047     .0182309    2.698745\n                              |\n     c._ns_f1_age1#c._ns_tvc1 |  -19.04827   6.611939    -2.88   0.004    -32.00744   -6.089109\n                              |\n     c._ns_f1_age1#c._ns_tvc2 |   2.555644   2.733908     0.93   0.350    -2.802717    7.914004\n                              |\n     c._ns_f1_age2#c._ns_tvc1 |   3.701198   3.555068     1.04   0.298    -3.266608      10.669\n                              |\n     c._ns_f1_age2#c._ns_tvc2 |  -.0607414   1.341542    -0.05   0.964    -2.690115    2.568632\n                              |\n     c._ns_f1_age3#c._ns_tvc1 |  -2.033876   .8956267    -2.27   0.023    -3.789272     -.27848\n                              |\n     c._ns_f1_age3#c._ns_tvc2 |  -.9184194    .694715    -1.32   0.186    -2.280036     .443197\n                              |\nmale#c._ns_f1_age1#c._ns_tvc1 |\n                           1  |   7.104149   8.667078     0.82   0.412    -9.883011    24.09131\n                              |\nmale#c._ns_f1_age1#c._ns_tvc2 |\n                           1  |  -2.530205   3.925255    -0.64   0.519    -10.22356    5.163153\n                              |\nmale#c._ns_f1_age2#c._ns_tvc1 |\n                           1  |  -4.308112   4.611764    -0.93   0.350      -13.347    4.730778\n                              |\nmale#c._ns_f1_age2#c._ns_tvc2 |\n                           1  |  -1.033032   1.804592    -0.57   0.567    -4.569967    2.503903\n                              |\nmale#c._ns_f1_age3#c._ns_tvc1 |\n                           1  |   .0752104   1.472709     0.05   0.959    -2.811246    2.961666\n                              |\nmale#c._ns_f1_age3#c._ns_tvc2 |\n                           1  |  -2.959448   1.198582    -2.47   0.014    -5.308625   -.6102702\n                              |\n                        _cons |   1.835955   .1428585    12.85   0.000     1.555958    2.115953\n-----------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\nTo obtain the marginal survival for males and females which is standardized over the combined covariate distribution (just age in this case) we can use standsurv.\n. range tt 0 10 101\n(15,463 missing values generated)\n\n. standsurv, at1(male 1) at2(male 0)    ///\n&gt;            atvar(Sm Sf)               ///\n&gt;            survival ci                ///\n&gt;            timevar(tt)                ///\n&gt;            contrast(difference)       ///\n&gt;            contrastvar(Sdiff)\nIf this was an stpm2 model then the spline variables would need to be calculated and then the interactions with age formed and this information passed to standsurv. To demonstrate the advantages of using stpm3 with factor variables and extended functions I will now fit the same model without using them.\n. gensplines age, gen(agens) df(3) type(ns)\n\n. forvalues i = 1/3 {\n  2.   gen m_agens`i' = agens`i' * male\n  3. }\n\n. stpm3 male agens1 agens2 agens3 m_agens1 m_agens2 m_agens3,                 ///\n&gt;       tvc(male agens1 agens2 agens3 m_agens1 m_agens2 m_agens3) dftvc(2)    ///\n&gt;       df(5) scale(lncumhazard)\n\nIteration 0:  Log likelihood = -26496.501  \nIteration 1:  Log likelihood = -26041.128  \nIteration 2:  Log likelihood = -26005.402  \nIteration 3:  Log likelihood = -26004.879  \nIteration 4:  Log likelihood = -26004.877  \n\n                                                       Number of obs =  15,564\n                                                       Wald chi2(7)  = 1029.65\nLog likelihood = -26004.877                            Prob &gt; chi2   =  0.0000\n\n---------------------------------------------------------------------------------------\n                      | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n----------------------+----------------------------------------------------------------\nxb                    |\n                 male |  -.2413055   .2648957    -0.91   0.362    -.7604915    .2778806\n               agens1 |  -6.206267   .9371474    -6.62   0.000    -8.043042   -4.369492\n               agens2 |  -.4202365   .4447267    -0.94   0.345    -1.291885    .4514119\n               agens3 |  -1.728845   .2531885    -6.83   0.000    -2.225086   -1.232605\n             m_agens1 |   .6846414   1.445986     0.47   0.636     -2.14944    3.518723\n             m_agens2 |   .2790084   .6314231     0.44   0.659    -.9585582    1.516575\n             m_agens3 |   .6956873   .4554633     1.53   0.127    -.1970043    1.588379\n----------------------+----------------------------------------------------------------\ntime                  |\n                 _ns1 |  -10.15155   .8167647   -12.43   0.000    -11.75238   -8.550724\n                 _ns2 |   2.443526   .2234638    10.93   0.000     2.005545    2.881507\n                 _ns3 |  -1.284021   .1792894    -7.16   0.000    -1.635421   -.9326197\n                 _ns4 |  -.8369727   .1507723    -5.55   0.000    -1.132481   -.5414644\n                 _ns5 |  -.6772495   .1283478    -5.28   0.000    -.9288065   -.4256924\n                      |\n    c.male#c._ns_tvc1 |   .4080993   .7632087     0.53   0.593    -1.087762    1.903961\n                      |\n    c.male#c._ns_tvc2 |   1.358488   .6838173     1.99   0.047     .0182309    2.698745\n                      |\n  c.agens1#c._ns_tvc1 |  -19.04827   6.611939    -2.88   0.004    -32.00743   -6.089108\n                      |\n  c.agens1#c._ns_tvc2 |   2.555644   2.733907     0.93   0.350    -2.802716    7.914004\n                      |\n  c.agens2#c._ns_tvc1 |   3.701197   3.555068     1.04   0.298    -3.266608      10.669\n                      |\n  c.agens2#c._ns_tvc2 |  -.0607416   1.341542    -0.05   0.964    -2.690115    2.568632\n                      |\n  c.agens3#c._ns_tvc1 |  -2.033876   .8956267    -2.27   0.023    -3.789272   -.2784798\n                      |\n  c.agens3#c._ns_tvc2 |  -.9184194    .694715    -1.32   0.186    -2.280036     .443197\n                      |\nc.m_agens1#c._ns_tvc1 |   7.104146   8.667078     0.82   0.412    -9.883014    24.09131\n                      |\nc.m_agens1#c._ns_tvc2 |  -2.530206   3.925255    -0.64   0.519    -10.22356    5.163152\n                      |\nc.m_agens2#c._ns_tvc1 |  -4.308111   4.611764    -0.93   0.350      -13.347     4.73078\n                      |\nc.m_agens2#c._ns_tvc2 |  -1.033032   1.804592    -0.57   0.567    -4.569967    2.503903\n                      |\nc.m_agens3#c._ns_tvc1 |     .07521   1.472709     0.05   0.959    -2.811246    2.961666\n                      |\nc.m_agens3#c._ns_tvc2 |  -2.959448   1.198582    -2.47   0.014    -5.308625   -.6102702\n                      |\n                _cons |   1.835955   .1428585    12.85   0.000     1.555958    2.115953\n---------------------------------------------------------------------------------------\nIt is necessary to incorporate the interactions into the standsurv call.\n. standsurv, at1(male 1 m_agens1 = agens1 m_agens2 = agens2 m_agens3 = agens3) ///\n&gt;            at2(male 0 m_agens1 0 m_agens2 0 m_agens3 0)                      ///\n&gt;            atvar(Sm2 Sf2)                                                    ///\n&gt;            survival ci                                                       ///\n&gt;            timevar(tt)                                                       ///\n&gt;            contrast(difference)                                              ///\n&gt;            contrastvar(Sdiff2)\nThe standardized estimates are identical, but using factor variables combined with extended functions makes life much easier.\n. list Sm Sm2 Sf Sf2 Sdiff Sdiff2 in 1/21\n\n     +-----------------------------------------------------------------------+\n     |        Sm         Sm2          Sf         Sf2       Sdiff      Sdiff2 |\n     |-----------------------------------------------------------------------|\n  1. |         1           1           1           1           0           0 |\n  2. | .92529544   .92529544   .94122671   .94122671   .01593127   .01593127 |\n  3. | .84974543   .84974543   .87134444   .87134444   .02159901   .02159901 |\n  4. | .80156899   .80156899   .82310037   .82310037   .02153138   .02153138 |\n  5. | .76810437   .76810437   .78841692   .78841692   .02031255   .02031255 |\n     |-----------------------------------------------------------------------|\n  6. | .74118184   .74118184   .76034216   .76034216   .01916031   .01916031 |\n  7. |   .717297     .717297   .73561505   .73561505   .01831805   .01831805 |\n  8. | .69488055   .69488055   .71268416   .71268416   .01780361   .01780361 |\n  9. | .67372368   .67372368   .69128998   .69128998    .0175663    .0175663 |\n 10. | .65393972   .65393972   .67149719   .67149719   .01755747   .01755747 |\n     |-----------------------------------------------------------------------|\n 11. | .63554177   .63554177   .65327781   .65327781   .01773603   .01773603 |\n 12. | .61848439   .61848439   .63654471   .63654471   .01806032   .01806032 |\n 13. | .60270014   .60270014   .62119777   .62119777   .01849764   .01849764 |\n 14. | .58811278   .58811278    .6071354    .6071354   .01902262   .01902262 |\n 15. | .57464333   .57464333   .59425862   .59425862   .01961529   .01961529 |\n     |-----------------------------------------------------------------------|\n 16. | .56218743   .56218743   .58244778   .58244778   .02026035   .02026035 |\n 17. | .55060497   .55060497    .5715515    .5715515   .02094653   .02094653 |\n 18. | .53977597   .53977597   .56144057   .56144057   .02166461   .02166461 |\n 19. | .52960174   .52960174   .55200868   .55200868   .02240694   .02240694 |\n 20. | .52000042   .52000042    .5431676    .5431676   .02316718   .02316718 |\n     |-----------------------------------------------------------------------|\n 21. |  .5109036    .5109036    .5348437    .5348437    .0239401    .0239401 |\n     +-----------------------------------------------------------------------+\nThe marginal estimates can be plotted\n. line Sm Sf tt, xtitle(\"Time since diagnosis\")      ///\n&gt;                ytitle(S(t))                        ///\n&gt;                legend(order(1 \"Males\" 2 \"Females\") ///\n&gt;                       ring(0) pos(1) cols(1))      ///\n&gt;                name(Marginal, replace)\n\n. twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red)),                ///\n&gt;          xtitle(\"Time since diagnosis\")              ///\n&gt;          ytitle(Difference in marginal survival)     /// \n&gt;          legend(off)                                 ///\n&gt;          name(Marginal_diff, replace)"
  },
  {
    "objectID": "software/stpm3/standsurv.html#using-standsurv",
    "href": "software/stpm3/standsurv.html#using-standsurv",
    "title": "Standardization",
    "section": "",
    "text": "I will not go into details of standsurv here. There are various tutorials here.\nThere main advantage of using stpm3 rather than stpm2 with standsurv is the support for factor variables. I will ilustrate this with an example.\nThe code below loads the example colon cancer data set.\n. use \"https://pclambert.net/data/colon.dta\", clear\n(Colon carcinoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm,f(status=1,2) id(id) scale(12) exit(time 120.5)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n     15,564  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     15,564  observations remaining, representing\n     15,564  subjects\n     10,459  failures in single-failure-per-subject data\n 51,685.667  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\n\n. gen male = sex==1\nTo illust rate the prediction options I will fit a model with an interaction between age and sex for both main and time-dependent effects, where the effect of age is modelled using natural splines.\n. stpm3 i.male##@ns(age,df(3)),                 ///\n&gt;       tvc(i.male##@ns(age,df(3))) dftvc(2)    ///\n&gt;       df(5) scale(lncumhazard)\n\nIteration 0:  Log likelihood = -26496.501  \nIteration 1:  Log likelihood = -26041.128  \nIteration 2:  Log likelihood = -26005.402  \nIteration 3:  Log likelihood = -26004.879  \nIteration 4:  Log likelihood = -26004.877  \n\n                                                       Number of obs =  15,564\n                                                       Wald chi2(7)  = 1029.65\nLog likelihood = -26004.877                            Prob &gt; chi2   =  0.0000\n\n-----------------------------------------------------------------------------------------------\n                              | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------------------+----------------------------------------------------------------\nxb                            |\n                       1.male |  -.2413054   .2648957    -0.91   0.362    -.7604915    .2778806\n                  _ns_f1_age1 |  -6.206267   .9371474    -6.62   0.000    -8.043042   -4.369492\n                  _ns_f1_age2 |  -.4202365   .4447267    -0.94   0.345    -1.291885    .4514119\n                  _ns_f1_age3 |  -1.728845   .2531885    -6.83   0.000    -2.225086   -1.232605\n                              |\n           male#c._ns_f1_age1 |\n                           1  |   .6846415   1.445986     0.47   0.636     -2.14944    3.518723\n                              |\n           male#c._ns_f1_age2 |\n                           1  |   .2790083   .6314231     0.44   0.659    -.9585582    1.516575\n                              |\n           male#c._ns_f1_age3 |\n                           1  |   .6956873   .4554633     1.53   0.127    -.1970044    1.588379\n------------------------------+----------------------------------------------------------------\ntime                          |\n                         _ns1 |  -10.15155   .8167647   -12.43   0.000    -11.75238   -8.550724\n                         _ns2 |   2.443526   .2234638    10.93   0.000     2.005545    2.881507\n                         _ns3 |  -1.284021   .1792894    -7.16   0.000    -1.635421   -.9326197\n                         _ns4 |  -.8369727   .1507723    -5.55   0.000    -1.132481   -.5414644\n                         _ns5 |  -.6772495   .1283478    -5.28   0.000    -.9288065   -.4256924\n                              |\n              male#c._ns_tvc1 |\n                           1  |   .4080991   .7632087     0.53   0.593    -1.087763    1.903961\n                              |\n              male#c._ns_tvc2 |\n                           1  |   1.358488   .6838173     1.99   0.047     .0182309    2.698745\n                              |\n     c._ns_f1_age1#c._ns_tvc1 |  -19.04827   6.611939    -2.88   0.004    -32.00744   -6.089109\n                              |\n     c._ns_f1_age1#c._ns_tvc2 |   2.555644   2.733908     0.93   0.350    -2.802717    7.914004\n                              |\n     c._ns_f1_age2#c._ns_tvc1 |   3.701198   3.555068     1.04   0.298    -3.266608      10.669\n                              |\n     c._ns_f1_age2#c._ns_tvc2 |  -.0607414   1.341542    -0.05   0.964    -2.690115    2.568632\n                              |\n     c._ns_f1_age3#c._ns_tvc1 |  -2.033876   .8956267    -2.27   0.023    -3.789272     -.27848\n                              |\n     c._ns_f1_age3#c._ns_tvc2 |  -.9184194    .694715    -1.32   0.186    -2.280036     .443197\n                              |\nmale#c._ns_f1_age1#c._ns_tvc1 |\n                           1  |   7.104149   8.667078     0.82   0.412    -9.883011    24.09131\n                              |\nmale#c._ns_f1_age1#c._ns_tvc2 |\n                           1  |  -2.530205   3.925255    -0.64   0.519    -10.22356    5.163153\n                              |\nmale#c._ns_f1_age2#c._ns_tvc1 |\n                           1  |  -4.308112   4.611764    -0.93   0.350      -13.347    4.730778\n                              |\nmale#c._ns_f1_age2#c._ns_tvc2 |\n                           1  |  -1.033032   1.804592    -0.57   0.567    -4.569967    2.503903\n                              |\nmale#c._ns_f1_age3#c._ns_tvc1 |\n                           1  |   .0752104   1.472709     0.05   0.959    -2.811246    2.961666\n                              |\nmale#c._ns_f1_age3#c._ns_tvc2 |\n                           1  |  -2.959448   1.198582    -2.47   0.014    -5.308625   -.6102702\n                              |\n                        _cons |   1.835955   .1428585    12.85   0.000     1.555958    2.115953\n-----------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\nTo obtain the marginal survival for males and females which is standardized over the combined covariate distribution (just age in this case) we can use standsurv.\n. range tt 0 10 101\n(15,463 missing values generated)\n\n. standsurv, at1(male 1) at2(male 0)    ///\n&gt;            atvar(Sm Sf)               ///\n&gt;            survival ci                ///\n&gt;            timevar(tt)                ///\n&gt;            contrast(difference)       ///\n&gt;            contrastvar(Sdiff)\nIf this was an stpm2 model then the spline variables would need to be calculated and then the interactions with age formed and this information passed to standsurv. To demonstrate the advantages of using stpm3 with factor variables and extended functions I will now fit the same model without using them.\n. gensplines age, gen(agens) df(3) type(ns)\n\n. forvalues i = 1/3 {\n  2.   gen m_agens`i' = agens`i' * male\n  3. }\n\n. stpm3 male agens1 agens2 agens3 m_agens1 m_agens2 m_agens3,                 ///\n&gt;       tvc(male agens1 agens2 agens3 m_agens1 m_agens2 m_agens3) dftvc(2)    ///\n&gt;       df(5) scale(lncumhazard)\n\nIteration 0:  Log likelihood = -26496.501  \nIteration 1:  Log likelihood = -26041.128  \nIteration 2:  Log likelihood = -26005.402  \nIteration 3:  Log likelihood = -26004.879  \nIteration 4:  Log likelihood = -26004.877  \n\n                                                       Number of obs =  15,564\n                                                       Wald chi2(7)  = 1029.65\nLog likelihood = -26004.877                            Prob &gt; chi2   =  0.0000\n\n---------------------------------------------------------------------------------------\n                      | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n----------------------+----------------------------------------------------------------\nxb                    |\n                 male |  -.2413055   .2648957    -0.91   0.362    -.7604915    .2778806\n               agens1 |  -6.206267   .9371474    -6.62   0.000    -8.043042   -4.369492\n               agens2 |  -.4202365   .4447267    -0.94   0.345    -1.291885    .4514119\n               agens3 |  -1.728845   .2531885    -6.83   0.000    -2.225086   -1.232605\n             m_agens1 |   .6846414   1.445986     0.47   0.636     -2.14944    3.518723\n             m_agens2 |   .2790084   .6314231     0.44   0.659    -.9585582    1.516575\n             m_agens3 |   .6956873   .4554633     1.53   0.127    -.1970043    1.588379\n----------------------+----------------------------------------------------------------\ntime                  |\n                 _ns1 |  -10.15155   .8167647   -12.43   0.000    -11.75238   -8.550724\n                 _ns2 |   2.443526   .2234638    10.93   0.000     2.005545    2.881507\n                 _ns3 |  -1.284021   .1792894    -7.16   0.000    -1.635421   -.9326197\n                 _ns4 |  -.8369727   .1507723    -5.55   0.000    -1.132481   -.5414644\n                 _ns5 |  -.6772495   .1283478    -5.28   0.000    -.9288065   -.4256924\n                      |\n    c.male#c._ns_tvc1 |   .4080993   .7632087     0.53   0.593    -1.087762    1.903961\n                      |\n    c.male#c._ns_tvc2 |   1.358488   .6838173     1.99   0.047     .0182309    2.698745\n                      |\n  c.agens1#c._ns_tvc1 |  -19.04827   6.611939    -2.88   0.004    -32.00743   -6.089108\n                      |\n  c.agens1#c._ns_tvc2 |   2.555644   2.733907     0.93   0.350    -2.802716    7.914004\n                      |\n  c.agens2#c._ns_tvc1 |   3.701197   3.555068     1.04   0.298    -3.266608      10.669\n                      |\n  c.agens2#c._ns_tvc2 |  -.0607416   1.341542    -0.05   0.964    -2.690115    2.568632\n                      |\n  c.agens3#c._ns_tvc1 |  -2.033876   .8956267    -2.27   0.023    -3.789272   -.2784798\n                      |\n  c.agens3#c._ns_tvc2 |  -.9184194    .694715    -1.32   0.186    -2.280036     .443197\n                      |\nc.m_agens1#c._ns_tvc1 |   7.104146   8.667078     0.82   0.412    -9.883014    24.09131\n                      |\nc.m_agens1#c._ns_tvc2 |  -2.530206   3.925255    -0.64   0.519    -10.22356    5.163152\n                      |\nc.m_agens2#c._ns_tvc1 |  -4.308111   4.611764    -0.93   0.350      -13.347     4.73078\n                      |\nc.m_agens2#c._ns_tvc2 |  -1.033032   1.804592    -0.57   0.567    -4.569967    2.503903\n                      |\nc.m_agens3#c._ns_tvc1 |     .07521   1.472709     0.05   0.959    -2.811246    2.961666\n                      |\nc.m_agens3#c._ns_tvc2 |  -2.959448   1.198582    -2.47   0.014    -5.308625   -.6102702\n                      |\n                _cons |   1.835955   .1428585    12.85   0.000     1.555958    2.115953\n---------------------------------------------------------------------------------------\nIt is necessary to incorporate the interactions into the standsurv call.\n. standsurv, at1(male 1 m_agens1 = agens1 m_agens2 = agens2 m_agens3 = agens3) ///\n&gt;            at2(male 0 m_agens1 0 m_agens2 0 m_agens3 0)                      ///\n&gt;            atvar(Sm2 Sf2)                                                    ///\n&gt;            survival ci                                                       ///\n&gt;            timevar(tt)                                                       ///\n&gt;            contrast(difference)                                              ///\n&gt;            contrastvar(Sdiff2)\nThe standardized estimates are identical, but using factor variables combined with extended functions makes life much easier.\n. list Sm Sm2 Sf Sf2 Sdiff Sdiff2 in 1/21\n\n     +-----------------------------------------------------------------------+\n     |        Sm         Sm2          Sf         Sf2       Sdiff      Sdiff2 |\n     |-----------------------------------------------------------------------|\n  1. |         1           1           1           1           0           0 |\n  2. | .92529544   .92529544   .94122671   .94122671   .01593127   .01593127 |\n  3. | .84974543   .84974543   .87134444   .87134444   .02159901   .02159901 |\n  4. | .80156899   .80156899   .82310037   .82310037   .02153138   .02153138 |\n  5. | .76810437   .76810437   .78841692   .78841692   .02031255   .02031255 |\n     |-----------------------------------------------------------------------|\n  6. | .74118184   .74118184   .76034216   .76034216   .01916031   .01916031 |\n  7. |   .717297     .717297   .73561505   .73561505   .01831805   .01831805 |\n  8. | .69488055   .69488055   .71268416   .71268416   .01780361   .01780361 |\n  9. | .67372368   .67372368   .69128998   .69128998    .0175663    .0175663 |\n 10. | .65393972   .65393972   .67149719   .67149719   .01755747   .01755747 |\n     |-----------------------------------------------------------------------|\n 11. | .63554177   .63554177   .65327781   .65327781   .01773603   .01773603 |\n 12. | .61848439   .61848439   .63654471   .63654471   .01806032   .01806032 |\n 13. | .60270014   .60270014   .62119777   .62119777   .01849764   .01849764 |\n 14. | .58811278   .58811278    .6071354    .6071354   .01902262   .01902262 |\n 15. | .57464333   .57464333   .59425862   .59425862   .01961529   .01961529 |\n     |-----------------------------------------------------------------------|\n 16. | .56218743   .56218743   .58244778   .58244778   .02026035   .02026035 |\n 17. | .55060497   .55060497    .5715515    .5715515   .02094653   .02094653 |\n 18. | .53977597   .53977597   .56144057   .56144057   .02166461   .02166461 |\n 19. | .52960174   .52960174   .55200868   .55200868   .02240694   .02240694 |\n 20. | .52000042   .52000042    .5431676    .5431676   .02316718   .02316718 |\n     |-----------------------------------------------------------------------|\n 21. |  .5109036    .5109036    .5348437    .5348437    .0239401    .0239401 |\n     +-----------------------------------------------------------------------+\nThe marginal estimates can be plotted\n. line Sm Sf tt, xtitle(\"Time since diagnosis\")      ///\n&gt;                ytitle(S(t))                        ///\n&gt;                legend(order(1 \"Males\" 2 \"Females\") ///\n&gt;                       ring(0) pos(1) cols(1))      ///\n&gt;                name(Marginal, replace)\n\n. twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red)),                ///\n&gt;          xtitle(\"Time since diagnosis\")              ///\n&gt;          ytitle(Difference in marginal survival)     /// \n&gt;          legend(off)                                 ///\n&gt;          name(Marginal_diff, replace)"
  },
  {
    "objectID": "software/stpm3/relative_survival_models.html",
    "href": "software/stpm3/relative_survival_models.html",
    "title": "Relative Survival Models",
    "section": "",
    "text": "This is just a draft at present"
  },
  {
    "objectID": "software/stpm3/relative_survival_models.html#relative-survivalexcess-mortality-models",
    "href": "software/stpm3/relative_survival_models.html#relative-survivalexcess-mortality-models",
    "title": "Relative Survival Models",
    "section": "Relative survival(excess mortality) models",
    "text": "Relative survival(excess mortality) models\nRelative survival(excess mortality) models are used to analyses population-based cancer survival data. As in stpm2 this is done through using the bhazard() option when fitting an stpm3 model.\nstpm3 has better predictions than stpm2 through the use of an expsurv() option.\nThis guide is really aimed at those who are familiar with relative survival models.\nThe code below loads the example colon cancer data set and merges in the expected mortality rates at the event/censoring times.\n. use \"https://pclambert.net/data/colon.dta\", clear\n(Colon carcinoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm,f(status=1,2) id(id) scale(12) exit(time 120.5)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n     15,564  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     15,564  observations remaining, representing\n     15,564  subjects\n     10,459  failures in single-failure-per-subject data\n 51,685.667  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\n\n. gen _age = floor(min(age+_t,99))\n\n. gen _year = floor(yydx +_t)\n\n. gen male = sex==1\n\n. merge m:1 _age _year sex using \"https://pclambert.net/data/popmort.dta\", keep(match master)\n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                            15,564  (_merge==3)\n    -----------------------------------------\nTo illusrate the prediction options I will fit a model with an interaction between age and sex for both main and time-dependent effects, where the effect of age is modelled using natural splines. I will also use winsoring at the 2nd and 98th centiles of age.\n. stpm3 i.male##@ns(age,df(3) winsor(2 98)), ///\n&gt;       tvc(i.male##@ns(age,df(3) winsor(2 98))) dftvc(2) ///\n&gt;       df(5) scale(lncumhazard)  bhazard(rate)\n\nIteration 0:  Log likelihood = -21354.047  \nIteration 1:  Log likelihood =  -20769.05  \nIteration 2:  Log likelihood = -20726.739  \nIteration 3:  Log likelihood = -20725.951  \nIteration 4:  Log likelihood = -20725.949  \nIteration 5:  Log likelihood = -20725.949  \n\n                                                        Number of obs = 15,564\n                                                        Wald chi2(7)  =  17.94\nLog likelihood = -20725.949                             Prob &gt; chi2   = 0.0123\n\n-----------------------------------------------------------------------------------------------\n                              | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------------------+----------------------------------------------------------------\nxb                            |\n                       1.male |  -.3529372   .2438788    -1.45   0.148    -.8309309    .1250566\n                  _ns_f1_age1 |  -.9225446   .4701276    -1.96   0.050    -1.843978   -.0011114\n                  _ns_f1_age2 |   .2828585   .1945014     1.45   0.146    -.0983573    .6640743\n                  _ns_f1_age3 |  -.0417452   .2264952    -0.18   0.854    -.4856676    .4021771\n                              |\n           male#c._ns_f1_age1 |\n                           1  |   1.240154    .847648     1.46   0.143     -.421206    2.901513\n                              |\n           male#c._ns_f1_age2 |\n                           1  |   .0103073   .2858799     0.04   0.971     -.550007    .5706216\n                              |\n           male#c._ns_f1_age3 |\n                           1  |    .486169   .4344473     1.12   0.263    -.3653321     1.33767\n------------------------------+----------------------------------------------------------------\ntime                          |\n                         _ns1 |  -7.658599   .4600483   -16.65   0.000    -8.560277   -6.756921\n                         _ns2 |   2.685312   .1249449    21.49   0.000     2.440425    2.930199\n                         _ns3 |  -.2397703   .1295897    -1.85   0.064    -.4937614    .0142209\n                         _ns4 |   .0815264   .1095782     0.74   0.457    -.1332429    .2962956\n                         _ns5 |   .2678154   .0959583     2.79   0.005     .0797406    .4558901\n                              |\n              male#c._ns_tvc1 |\n                           1  |   .9938131   .4540786     2.19   0.029     .1038354    1.883791\n                              |\n              male#c._ns_tvc2 |\n                           1  |   1.111332   .5122449     2.17   0.030     .1073506    2.115314\n                              |\n     c._ns_f1_age1#c._ns_tvc1 |  -17.30983   2.373232    -7.29   0.000    -21.96128   -12.65838\n                              |\n     c._ns_f1_age1#c._ns_tvc2 |  -5.081748    1.12152    -4.53   0.000    -7.279888   -2.883609\n                              |\n     c._ns_f1_age2#c._ns_tvc1 |   3.098712   1.430068     2.17   0.030     .2958309    5.901593\n                              |\n     c._ns_f1_age2#c._ns_tvc2 |  -.3393347   .5099432    -0.67   0.506    -1.338805    .6601357\n                              |\n     c._ns_f1_age3#c._ns_tvc1 |  -3.389762    .565698    -5.99   0.000    -4.498509   -2.281014\n                              |\n     c._ns_f1_age3#c._ns_tvc2 |  -2.109922   .5190539    -4.06   0.000    -3.127249   -1.092595\n                              |\nmale#c._ns_f1_age1#c._ns_tvc1 |\n                           1  |   1.102057   3.237953     0.34   0.734    -5.244215    7.448329\n                              |\nmale#c._ns_f1_age1#c._ns_tvc2 |\n                           1  |  -2.844073   1.856685    -1.53   0.126    -6.483108    .7949625\n                              |\nmale#c._ns_f1_age2#c._ns_tvc1 |\n                           1  |  -2.353453   1.906681    -1.23   0.217     -6.09048    1.383573\n                              |\nmale#c._ns_f1_age2#c._ns_tvc2 |\n                           1  |  -.2610123   .7417512    -0.35   0.725    -1.714818    1.192793\n                              |\nmale#c._ns_f1_age3#c._ns_tvc1 |\n                           1  |  -.2141621   .9766446    -0.22   0.826     -2.12835    1.700026\n                              |\nmale#c._ns_f1_age3#c._ns_tvc2 |\n                           1  |  -2.073735    .944128    -2.20   0.028    -3.924192   -.2232782\n                              |\n                        _cons |  -.1063001   .1227919    -0.87   0.387    -.3469678    .1343676\n-----------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3) winsor(2 98))\nThe use of bhazard(rate) makes this a relative survival model. This means that relative survival will be predicted when using the survival option of the predict command. Similarly, the excess mortality (hazard) rate will be predicted when uing the hazard option of the predict command.\nSome predictions require use of the expsurv() option to merge in the expected mortality rates.\nThe various predictions will be for males and females aged 70.\n\nRelative Survival\nFirst I will predict relative survival and the difference between males and females.\n. predict Rm Rf, at1(male 1 age 70)         ///\n&gt;                at2(male 0 age 70)         ///\n&gt;                surv  ci                   ///\n&gt;                timevar(0 10, step(0.1))   ///\n&gt;                contrast(difference)       ///\n&gt;                contrastvar(Rdiff)         ///\n&gt;                frame(f1)\nPredictions are stored in frame - f1\nThe predictions are saved in frame f1, and can be plotted.\n. frame f1 {\n.   line Rm Rf tt, name(RS, replace)    ///\n&gt;        xtitle(\"Time since diagnosis\") ///\n&gt;        ytitle(R(t))\n.   twoway (rarea Rdiff_lci Rdiff_uci tt, color(red%30)) ///\n&gt;          (line Rdiff tt, color(red)),                 ///\n&gt;          xtitle(\"Time since diagnosis\")                ///\n&gt;          ytitle(Difference in R(t))                    /// \n&gt;          legend(off)                                   ///\n&gt;          name(RSdiff, replace)\n. }\n \n\n\nAll-cause survival\nUsing the expsurv() option allows all-cause survival to be calculated.\n\\[\nS(t|X) = S^*(t|X)R(t|X)\n\\]\n. predict Sm Sf, surv  ci ///\n&gt;                at1(male 1 age 70)   ///\n&gt;                at2(male 0 age 70)   ///\n&gt;                contrast(difference) ///\n&gt;                contrastvar(Sdiff)   ///               \n&gt;                frame(f1, merge)     ///\n&gt;                expsurv(using(\"https://www.pclambert.net/data/popmort\") ///  Popmort file\n&gt;                        agediag(70)        ///  Age at diagnosis in the dataset\n&gt;                        datediag(1990-1-1) ///  Date of diagnosis in the dataset\n&gt;                        pmother(sex)       ///  Other variables included in the popmort file\n&gt;                        pmrate(rate)       ///  Rate variable in the popmort file  \n&gt;                        at1(sex 1)         ///\n&gt;                        at2(sex 2)         ///\n&gt;                        )                \nPredictions are stored in frame - f1\n\n. frame f1 {\n.   line Sm Sf tt, name(S, replace)     ///\n&gt;        xtitle(\"Time since diagnosis\") ///\n&gt;        ytitle(S(t))\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red)),                 ///\n&gt;          xtitle(\"Time since diagnosis\")                ///\n&gt;          ytitle(Difference in S(t))                    /// \n&gt;          legend(off)                                   ///\n&gt;          name(Sdiff, replace)  \n. }\n \n\n\nMarginal all-cause hazard\nThis is the same as above, but replace the survival' option withhazard`.\n. predict hm hf, hazard  ci ///\n&gt;                at1(male 1 age 70)   ///\n&gt;                at2(male 0 age 70)   ///\n&gt;                contrast(difference) ///\n&gt;                contrastvar(hdiff)   ///               \n&gt;                frame(f1, merge)     ///\n&gt;                expsurv(using(\"https://www.pclambert.net/data/popmort\") ///  Popmort file\n&gt;                        agediag(70)        ///  Age at diagnosis in the dataset\n&gt;                        datediag(1990-1-1) ///  Date of diagnosis in the dataset\n&gt;                        pmother(sex)       ///  Other variables included in the popmort file\n&gt;                        pmrate(rate)       ///  Rate variable in the popmort file  \n&gt;                        at1(sex 1)         ///\n&gt;                        at2(sex 2)         ///\n&gt;                        )                \nPredictions are stored in frame - f1\n\n. frame f1 {\n.   line hm hf tt, name(S, replace)     ///\n&gt;        xtitle(\"Time since diagnosis\") ///\n&gt;        ytitle(h(t))\n.   twoway (rarea hdiff_lci hdiff_uci tt, color(red%30)) ///\n&gt;          (line hdiff tt, color(red)),                 ///\n&gt;          xtitle(\"Time since diagnosis\")                ///\n&gt;          ytitle(Difference in h(t))                    /// \n&gt;          legend(off)                                   ///\n&gt;          name(Sdiff, replace)    \n.   line hm hf tt, name(h, replace)\n.   line hdiff* tt, name(hdiff, replace)\n. }\n \n\n\nCrude Probabilities\nThe default is to only give crude probability of death due to cancer. You can use the expvar option to option crude probablities of death due to other causes.\n. predict Ccm Ccf, crudeprob ci ///\n&gt;                at1(male 1 age 70)  ///\n&gt;                at2(male 0 age 70)  ///\n&gt;                contrast(difference) ///\n&gt;                contrastvar(Ccdiff)   ///               \n&gt;                frame(f1, merge)    ///\n&gt;                expsurv(using(\"https://www.pclambert.net/data/popmort\") ///  Popmort file\n&gt;                        agediag(70)      ///  Age at diagnosis in the dataset\n&gt;                        datediag(1990-1-1)      ///  Date of diagnosis in the dataset\n&gt;                        pmother(sex)       ///  Other variables included in the popmort file\n&gt;                        pmrate(rate)       ///  Rate variable in the popmort file  \n&gt;                        at1(sex 1)         ///\n&gt;                        at2(sex 2)         ///\n&gt;                        expvar(Com Cof) ///\n&gt;                        )                      \nPredictions are stored in frame - f1\n\n\nLife expectancy\nThis is obtained through separate extrpolation of the relative and expected survival.\n. gen t80 = 80 in 1\n(15,563 missing values generated)\n\n. predict LEf LEm, rmst ci            ///\n&gt;                at1(male 1 age 70)   ///\n&gt;                at2(male 0 age 70)   ///\n&gt;                contrast(difference) ///\n&gt;                contrastvar(Ccdiff)  /// \n&gt;                timevar(t80)         ///\n&gt;                frame(f2)            ///\n&gt;                expsurv(using(\"https://www.pclambert.net/data/popmort\") ///  Popmort file\n&gt;                        agediag(70)      ///  Age at diagnosis in the dataset\n&gt;                        datediag(1990-1-1)      ///  Date of diagnosis in the dataset\n&gt;                        pmother(sex)       ///  Other variables included in the popmort file\n&gt;                        pmrate(rate)       ///  Rate variable in the popmort file  \n&gt;                        pmmaxyear(2000)    ///\n&gt;                        at1(sex 1)         ///\n&gt;                        at2(sex 2)         ///\n&gt;                        expvar(ELEm ELEf) ///\n&gt;                        )\nPredictions are stored in frame - f2\n\n.                        \n. frame f2: {\n.   list LEf* ELEf                       \n\n     +---------------------------------------------+\n     |      LEf     LEf_lci    LEf_uci        ELEf |\n     |---------------------------------------------|\n  1. | 5.652845   5.3925576   5.925696   14.658482 |\n     +---------------------------------------------+\n.   list LEm* ELEm                       \n\n     +-----------------------------------------------+\n     |       LEm     LEm_lci     LEm_uci        ELEm |\n     |-----------------------------------------------|\n  1. | 7.0845352   6.8264632   7.3523635   11.328775 |\n     +-----------------------------------------------+\n. }                \n\n\nLife expectancy over a range of ages\nThe code below creates a frame with a range of ages to predict life expectencty.\n. capture frame drop ageLEL\n\n. frame create ageLEL\n\n. frame ageLEL {\n.   range age 50 99 50\nNumber of observations (_N) was 0, now 50.\n.   gen male = .\n(50 missing values generated)\n.   gen sex = .\n(50 missing values generated)\n.   predict LEm LEf, rmst ci                ///\n&gt;                  at1(male 1, obsvalues)   ///\n&gt;                  at2(male 0, obsvalues)   ///\n&gt;                  timevar(80)              ///\n&gt;                  merge                    ///\n&gt;                  expsurv(using(\"https://www.pclambert.net/data/popmort\") ///  Popmort file\n&gt;                          agediag(age)       ///  Age at diagnosis in the dataset\n&gt;                          datediag(1990-1-1) ///  Date of diagnosis in the dataset\n&gt;                          pmother(sex)       ///  Other variables included in the popmort file\n&gt;                          pmrate(rate)       ///  Rate variable in the popmort file  \n&gt;                          pmmaxyear(2000)    ///\n&gt;                          at1(sex 1)         ///\n&gt;                          at2(sex 2)         ///\n&gt;                          expvar(ELEm ELEf)  ///\n&gt;                          )\n.  gen LELm = ELEm - LEm                         \n.  gen LELf = ELEf - LEf                         \n. }\nThe predicted values can now be plotted.\n. frame ageLEL {\n.   line LEf ELEf LELf age,                             ///\n&gt;        xtitle(\"Age at diagnosis\")                 ///\n&gt;        ytitle(Life Expectency)                        ///\n&gt;        legend(order(1 \"Life Expectancy\"               ///\n&gt;                     2 \"Expected Life Expectancy\"      ///\n&gt;                     3 \"Reduction in Life Expectancy\")  ///\n&gt;               ring(0) cols(1) pos(1))\n. }"
  },
  {
    "objectID": "software/stpm3/factor_variables.html",
    "href": "software/stpm3/factor_variables.html",
    "title": "Factor Variables",
    "section": "",
    "text": "stpm3 fully supports factor variables\nIn stpm3 there is now full support for factor variables including for time-dependent effects. This makes predictions much easier. In addition, standsurv has been updated to be compatible with stpm3 making marginal predictions also much easier.\nWe first load the Rotterdam breast cancer data and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nThe scale(12) option converts the times recorded in months to years.\nTo fit an stpm3 model with a binary covariate we could use,\n. stpm3 hormon, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2929.2995  \nIteration 1:  Log likelihood = -2928.2998  \nIteration 2:  Log likelihood = -2928.2966  \nIteration 3:  Log likelihood = -2928.2966  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  25.19\nLog likelihood = -2928.2966                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |   .4321954   .0861189     5.02   0.000     .2634054    .6009854\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |   -23.9834    1.92113   -12.48   0.000    -27.74874   -20.21805\n        _ns2 |   6.695765   1.027919     6.51   0.000     4.681082    8.710449\n        _ns3 |  -1.214676   .0497438   -24.42   0.000    -1.312172    -1.11718\n        _ns4 |  -.8095755   .0387379   -20.90   0.000    -.8855004   -.7336505\n        _ns5 |  -.4994385   .0418591   -11.93   0.000    -.5814808   -.4173963\n       _cons |  -.5713643   .0332128   -17.20   0.000    -.6364603   -.5062684\n------------------------------------------------------------------------------\nThe equivalent model using factor variables is,\n. stpm3 i.hormon, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2929.2995  \nIteration 1:  Log likelihood = -2928.2998  \nIteration 2:  Log likelihood = -2928.2966  \nIteration 3:  Log likelihood = -2928.2966  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  25.19\nLog likelihood = -2928.2966                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .4321954   .0861189     5.02   0.000     .2634054    .6009854\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |   -23.9834    1.92113   -12.48   0.000    -27.74874   -20.21805\n        _ns2 |   6.695765   1.027919     6.51   0.000     4.681082    8.710449\n        _ns3 |  -1.214676   .0497438   -24.42   0.000    -1.312172    -1.11718\n        _ns4 |  -.8095755   .0387379   -20.90   0.000    -.8855004   -.7336505\n        _ns5 |  -.4994385   .0418591   -11.93   0.000    -.5814808   -.4173963\n       _cons |  -.5713643   .0332128   -17.20   0.000    -.6364603   -.5062684\n------------------------------------------------------------------------------\nYou can also include factor variables as a time-dependent effect.\n. stpm3 i.hormon, scale(lncumhazard) df(5) ///\n&gt;                 tvc(i.hormon) dftvc(3)\n\nIteration 0:  Log likelihood = -2928.8322  \nIteration 1:  Log likelihood = -2926.8607  \nIteration 2:  Log likelihood = -2926.8409  \nIteration 3:  Log likelihood = -2926.8409  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  20.88\nLog likelihood = -2926.8409                             Prob &gt; chi2   = 0.0000\n\n-----------------------------------------------------------------------------------\n                  | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------+----------------------------------------------------------------\nxb                |\n           hormon |\n             yes  |   .4766542   .1043107     4.57   0.000     .2722089    .6810995\n------------------+----------------------------------------------------------------\ntime              |\n             _ns1 |  -25.11479   2.156221   -11.65   0.000     -29.3409   -20.88867\n             _ns2 |   7.297905    1.13577     6.43   0.000     5.071836    9.523974\n             _ns3 |  -1.195295   .0516705   -23.13   0.000    -1.296567   -1.094023\n             _ns4 |  -.7997134   .0402802   -19.85   0.000    -.8786612   -.7207657\n             _ns5 |  -.4954146   .0427173   -11.60   0.000    -.5791388   -.4116903\n                  |\nhormon#c._ns_tvc1 |\n             yes  |   4.943174   3.778547     1.31   0.191    -2.462642    12.34899\n                  |\nhormon#c._ns_tvc2 |\n             yes  |  -2.952286   1.995084    -1.48   0.139    -6.862579    .9580062\n                  |\nhormon#c._ns_tvc3 |\n             yes  |  -.0773513   .1778044    -0.44   0.664    -.4258415    .2711389\n                  |\n            _cons |  -.5740705   .0333738   -17.20   0.000    -.6394819   -.5086591\n-----------------------------------------------------------------------------------\nYou can incorporate interactions into both the main effect and interactions with time using tvc().\n. stpm3 i.hormon##i.grade, scale(lncumhazard) df(5) ///\n&gt;                 tvc(i.hormon##i.grade) dftvc(3) baselevels\n\nIteration 0:  Log likelihood = -2901.3265  \nIteration 1:  Log likelihood = -2895.1769  \nIteration 2:  Log likelihood = -2895.0066  \nIteration 3:  Log likelihood = -2895.0059  \nIteration 4:  Log likelihood = -2895.0059  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(3)  =  60.61\nLog likelihood = -2895.0059                             Prob &gt; chi2   = 0.0000\n\n-----------------------------------------------------------------------------------------\n                        | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------------+----------------------------------------------------------------\nxb                      |\n                 hormon |\n                    no  |          0  (base)\n                   yes  |   .4135919   .2951852     1.40   0.161    -.1649605    .9921443\n                        |\n                  grade |\n                     2  |          0  (base)\n                     3  |    .483797   .0805037     6.01   0.000     .3260126    .6415814\n                        |\n           hormon#grade |\n                 yes#3  |   .0284316    .315761     0.09   0.928    -.5904485    .6473117\n------------------------+----------------------------------------------------------------\ntime                    |\n                   _ns1 |  -27.62422   5.730659    -4.82   0.000    -38.85611   -16.39234\n                   _ns2 |   7.583979   2.721378     2.79   0.005     2.250176    12.91778\n                   _ns3 |  -1.385614   .1121938   -12.35   0.000     -1.60551   -1.165718\n                   _ns4 |  -.8489422   .0796837   -10.65   0.000    -1.005119   -.6927651\n                   _ns5 |  -.4786468   .0735986    -6.50   0.000    -.6228974   -.3343963\n                        |\n      hormon#c._ns_tvc1 |\n                   yes  |  -2.771489   16.45089    -0.17   0.866    -35.01463    29.47165\n                        |\n      hormon#c._ns_tvc2 |\n                   yes  |   2.425308   8.628728     0.28   0.779    -14.48669     19.3373\n                        |\n      hormon#c._ns_tvc3 |\n                   yes  |  -.7069334    .573263    -1.23   0.218    -1.830508    .4166415\n                        |\n       grade#c._ns_tvc1 |\n                     3  |   2.757887   5.847325     0.47   0.637    -8.702659    14.21843\n                        |\n       grade#c._ns_tvc2 |\n                     3  |   -.285027   3.030253    -0.09   0.925    -6.224213    5.654159\n                        |\n       grade#c._ns_tvc3 |\n                     3  |  -.0467859   .1288623    -0.36   0.717    -.2993512    .2057795\n                        |\nhormon#grade#c._ns_tvc1 |\n                 yes#3  |   8.162556   16.89039     0.48   0.629      -24.942    41.26711\n                        |\nhormon#grade#c._ns_tvc2 |\n                 yes#3  |  -5.885373   8.860398    -0.66   0.507    -23.25143    11.48069\n                        |\nhormon#grade#c._ns_tvc3 |\n                 yes#3  |   .7162528   .6030515     1.19   0.235    -.4657065    1.898212\n                        |\n                  _cons |  -.9320134   .0710511   -13.12   0.000    -1.071271   -.7927559\n-----------------------------------------------------------------------------------------\nI strongly recommend using factor variables. When the model becomes complex, with interactions, time-dependent effects etc, then predictions usinff predict or standsurv become much simpler."
  },
  {
    "objectID": "software/stpm3/contrasts.html",
    "href": "software/stpm3/contrasts.html",
    "title": "Contrasts",
    "section": "",
    "text": "If you have more than one at option then you can perform contrasts. For example, if you predict survival curves for more than one covariate pattern you can take differences or ratios of these predictions.\nThis is best shown through example. I first load the Rotterdam breast cancer data.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 60)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 60\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n        753  failures in single-record/single-failure data\n 13,038.968  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nI will fit a simple model including the effect of hormon and use a natural spline for age.\n. stpm3 i.hormon @ns(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n _ns_f1_age1 |  -1.769774   1.089136    -1.62   0.104    -3.904441    .3648924\n _ns_f1_age2 |  -1.233782   .4602279    -2.68   0.007    -2.135812   -.3317519\n _ns_f1_age3 |  -1.709216   .4899396    -3.49   0.000     -2.66948   -.7489521\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |  -.1364105   .2354592    -0.58   0.562     -.597902     .325081\n------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n\n. estimates store stpm3_ns\nI will now predict the survival function for a 70 year woman with and without hormonal treatment.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1)\nPredictions are stored in frame - f1\nThe predicted survival functions are plotted below.\n. frame f1 {\n.   twoway (line S70h0 S70h1 tt) ///\n&gt;          , xtitle(\"Years since surgery\") ///\n&gt;          ytitle(\"S(t)\")                  ///\n&gt;          legend(order(1 \"hormon=0\" 2 \"hormon=1\") ring(0) pos(1) cols(1))\n. }\n\nVisually we can see the difference in the lines which is over 10 percentage points at 5 years. We can calculate the difference using the contrast(difference) option. We can name the contrast variable using the contrastvar() option rather than rely on the default names.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               contrast(difference)        ///\n&gt;               contrastvar(Sdiff)          ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1, replace)\nPredictions are stored in frame - f1\nOnce the contrast is stored, it can be plotted together with a 95% confidence interval.\n. frame f1 {\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red))                   ///\n&gt;          , xtitle(\"Years since surgery\")               ///\n&gt;          ytitle(\"Difference in S(t)\")                  ///\n&gt;          ylabel(,format(%3.2f))                        ///\n&gt;          legend(off)\n. }\n\nBy default at1() is the reference, so the difference is at2() - at1(). The reference level can be changed using the atreference() option.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               atreference(2)              ///\n&gt;               contrast(difference)        ///\n&gt;               contrastvar(Sdiff)          ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1, replace)\nPredictions are stored in frame - f1\nOnce the contrast is stored, it can be plotted together with a 95% confidence interval.\n. frame f1 {\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red))                   ///\n&gt;          , xtitle(\"Years since surgery\")               ///\n&gt;          ytitle(\"Difference in S(t)\")                  ///\n&gt;          ylabel(,format(%3.2f))                        ///\n&gt;          legend(off)\n. }"
  },
  {
    "objectID": "software/stpm3/contrasts.html#multiple-at-options",
    "href": "software/stpm3/contrasts.html#multiple-at-options",
    "title": "Contrasts",
    "section": "",
    "text": "If you have more than one at option then you can perform contrasts. For example, if you predict survival curves for more than one covariate pattern you can take differences or ratios of these predictions.\nThis is best shown through example. I first load the Rotterdam breast cancer data.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 60)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 60\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n        753  failures in single-record/single-failure data\n 13,038.968  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nI will fit a simple model including the effect of hormon and use a natural spline for age.\n. stpm3 i.hormon @ns(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n _ns_f1_age1 |  -1.769774   1.089136    -1.62   0.104    -3.904441    .3648924\n _ns_f1_age2 |  -1.233782   .4602279    -2.68   0.007    -2.135812   -.3317519\n _ns_f1_age3 |  -1.709216   .4899396    -3.49   0.000     -2.66948   -.7489521\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |  -.1364105   .2354592    -0.58   0.562     -.597902     .325081\n------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n\n. estimates store stpm3_ns\nI will now predict the survival function for a 70 year woman with and without hormonal treatment.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1)\nPredictions are stored in frame - f1\nThe predicted survival functions are plotted below.\n. frame f1 {\n.   twoway (line S70h0 S70h1 tt) ///\n&gt;          , xtitle(\"Years since surgery\") ///\n&gt;          ytitle(\"S(t)\")                  ///\n&gt;          legend(order(1 \"hormon=0\" 2 \"hormon=1\") ring(0) pos(1) cols(1))\n. }\n\nVisually we can see the difference in the lines which is over 10 percentage points at 5 years. We can calculate the difference using the contrast(difference) option. We can name the contrast variable using the contrastvar() option rather than rely on the default names.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               contrast(difference)        ///\n&gt;               contrastvar(Sdiff)          ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1, replace)\nPredictions are stored in frame - f1\nOnce the contrast is stored, it can be plotted together with a 95% confidence interval.\n. frame f1 {\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red))                   ///\n&gt;          , xtitle(\"Years since surgery\")               ///\n&gt;          ytitle(\"Difference in S(t)\")                  ///\n&gt;          ylabel(,format(%3.2f))                        ///\n&gt;          legend(off)\n. }\n\nBy default at1() is the reference, so the difference is at2() - at1(). The reference level can be changed using the atreference() option.\n. predict S70h0 S70h1, survival ci          ///\n&gt;               at1(age 70 hormon 0)        ///\n&gt;               at2(age 70 hormon 1)        ///\n&gt;               atreference(2)              ///\n&gt;               contrast(difference)        ///\n&gt;               contrastvar(Sdiff)          ///\n&gt;               timevar(0 5, step(0.1))     ///\n&gt;               frame(f1, replace)\nPredictions are stored in frame - f1\nOnce the contrast is stored, it can be plotted together with a 95% confidence interval.\n. frame f1 {\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%30)) ///\n&gt;          (line Sdiff tt, color(red))                   ///\n&gt;          , xtitle(\"Years since surgery\")               ///\n&gt;          ytitle(\"Difference in S(t)\")                  ///\n&gt;          ylabel(,format(%3.2f))                        ///\n&gt;          legend(off)\n. }"
  },
  {
    "objectID": "software/stpm3/contrasts.html#more-than-two-at-options",
    "href": "software/stpm3/contrasts.html#more-than-two-at-options",
    "title": "Contrasts",
    "section": "More than two at options",
    "text": "More than two at options\nYou can have as many at options as you want. The following predicts survival at 10 year intervals between 40 and 90 years at diagnosis.\n. local j 1\n\n. foreach a of numlist  40(10)90 {\n  2.   local atlist `atlist' at`j'(age `a' hormon 0)\n  3.   local ++j\n  4. } \n\n. predict S*, survival ci              ///\n&gt;             `atlist'                 ///\n&gt;             timevar(0 5, step(0.1))  ///\n&gt;             frame(f2, replace)\nPredictions are stored in frame - f2\n. frame f2 {\n.   twoway (line S? tt, ) ///\n&gt;          , xtitle(\"Years since surgery\")                         ///\n&gt;          ytitle(\"S(t)\")                                          ///\n&gt;          ylabel(,format(%3.2f))                                  ///\n&gt;          legend(order(1 \"40\" 2 \"50\" 3 \"60\" 4 \"70\" 5 \"80\" 6 \"90\") ///\n&gt;                 ring(0) pos(7) cols(1))\n. }\n\nIf you want to make contrasts between the different ages then we need to make one of the at options the reference. Below I make the 2nd at option the reference, which is for 50 year olds (they have the best survival).\n. local atlist\n\n. local j 1\n\n. foreach a of numlist  40(10)90 {\n  2.   local atlist `atlist' at`j'(age `a' hormon 0)\n  3.   local ++j\n  4. } \n\n. predict S*, survival ci                 ///\n&gt;             `atlist'                    ///\n&gt;             contrast(difference)        ///\n&gt;             contrastvar(Sdiff*)         ///\n&gt;             atreference(2)              ///\n&gt;             timevar(0 5, step(0.1))     ///\n&gt;             frame(f2, replace)\nPredictions are stored in frame - f2\n. frame f2 {\n.   twoway (line Sdiff? tt, ) ///\n&gt;          , xtitle(\"Years since surgery\")                         ///\n&gt;          ytitle(\"S(t)\")                                          ///\n&gt;          ylabel(,format(%3.2f))                                  ///\n&gt;          title(\"Difference in survival compared to 50 year old\") ///\n&gt;          legend(order(1 \"40\" 2 \"60\" 3 \"70\" 4 \"80\" 5 \"90\")        ///\n&gt;                 ring(0) pos(7) cols(1))\n. }"
  },
  {
    "objectID": "software/stpm2.html",
    "href": "software/stpm2.html",
    "title": "stpm2",
    "section": "",
    "text": "stpm2 fits flexible parametric survival models. These pages are rather old and will not be updated. I recommend you look at `stpm3’"
  },
  {
    "objectID": "software/stpm2.html#examples",
    "href": "software/stpm2.html#examples",
    "title": "stpm2",
    "section": "Examples",
    "text": "Examples\n\nProportional hazards models\n\nComparison with a Cox model\nPredicting hazard and survival functions (use of the timevar() option)\nSensitivity analysis for the number of knots\nThe default knot positions - are they sensible?\nOut of sample predictions (by Sarah Booth)\n\n\n\nPrognostic Models\n\nTemporal Recalibration (by Sarah Booth)"
  },
  {
    "objectID": "software/stpm2/stpm2_timevar.html",
    "href": "software/stpm2/stpm2_timevar.html",
    "title": "Use of the timevar() option",
    "section": "",
    "text": "In this tutorial I will describe some simple use of the timevar() option when obtaining predictions after fitting a model using stpm2. When using Stata’s survival models, such as streg and stcox, predictions are made at the values of _t, which is each record’s event or censoring time. This is the default behaviour of stpm2.\nOne of the advantages of parametric survival models is that we can predict various quantities (hazard, survival functions etc etc) at any value of time and for any covariate pattern as we have an equation which is a function of time and any covariates we have modelled.\nBefore I show some examples I should explain that we need to be a bit cautious when making such predictions. In Stata it is only possible to have one data set in memory. When we make predictions at specific values of time using the timevar() option we effectively want a second data set that we can use for predictions, and then use for producing graphs and tabulations.\nWe have found it easiest to think of two data sets side by side as shown below.\n------------------  --------------\n|                |  |            |\n|                |  | Prediction |\n| Analysis Data  |  |    Data    |\n|                |  |            |\n|                |  --------------\n|                |\n------------------\nThis means that we have our analysis data and our prediction data stored in the same data set. We have to remember that there are actually two (or more) data sets and that row 1 or the analysis data does not have a relationship with row 1 of the prediction data.\nI now will illustrate the use of the timevar() option."
  },
  {
    "objectID": "software/stpm2/stpm2_timevar.html#background",
    "href": "software/stpm2/stpm2_timevar.html#background",
    "title": "Use of the timevar() option",
    "section": "",
    "text": "In this tutorial I will describe some simple use of the timevar() option when obtaining predictions after fitting a model using stpm2. When using Stata’s survival models, such as streg and stcox, predictions are made at the values of _t, which is each record’s event or censoring time. This is the default behaviour of stpm2.\nOne of the advantages of parametric survival models is that we can predict various quantities (hazard, survival functions etc etc) at any value of time and for any covariate pattern as we have an equation which is a function of time and any covariates we have modelled.\nBefore I show some examples I should explain that we need to be a bit cautious when making such predictions. In Stata it is only possible to have one data set in memory. When we make predictions at specific values of time using the timevar() option we effectively want a second data set that we can use for predictions, and then use for producing graphs and tabulations.\nWe have found it easiest to think of two data sets side by side as shown below.\n------------------  --------------\n|                |  |            |\n|                |  | Prediction |\n| Analysis Data  |  |    Data    |\n|                |  |            |\n|                |  --------------\n|                |\n------------------\nThis means that we have our analysis data and our prediction data stored in the same data set. We have to remember that there are actually two (or more) data sets and that row 1 or the analysis data does not have a relationship with row 1 of the prediction data.\nI now will illustrate the use of the timevar() option."
  },
  {
    "objectID": "software/stpm2/stpm2_timevar.html#example",
    "href": "software/stpm2/stpm2_timevar.html#example",
    "title": "Use of the timevar() option",
    "section": "Example",
    "text": "Example\nI first load and stset the rott2b data.\n. use https://www.pclambert.net/data/rott2b, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset rf, f(rfi==1) scale(12) exit(time 60)\n\n     failure event:  rfi == 1\nobs. time interval:  (0, rf]\n exit on or before:  time 60\n    t for analysis:  time/12\n\n------------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n------------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,181  failures in single-record/single-failure data\n 11,130.825  total analysis time at risk and under observation\n                                                at risk from t =         0\n                                     earliest observed entry t =         0\n                                          last observed exit t =         5\nI will model the effect of age using restricted cubic splines. These can be generated using the rcsgen command. I make use of the center option make the created spline variables all equal 0 at the specified value, in this case at age 60. I then fit an stpm2 model including the effect of hormonal therapy (hormon), progesterone receptor (transformed using \\(\\log(pr+1)\\)), and age (using the 3 created restricted cubic spline variables).\n. rcsgen age, df(3) gen(agercs) center(60)\nVariables agercs1 to agercs3 were created\n\n. stpm2 hormon agercs* pr_1, scale(hazard) df(4) eform\n\nIteration 0:   log likelihood = -3065.3989  \nIteration 1:   log likelihood = -3065.2479  \nIteration 2:   log likelihood = -3065.2478  \n\nLog likelihood = -3065.2478                     Number of obs     =      2,982\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |   1.253481    .112407     2.52   0.012     1.051442    1.494342\n     agercs1 |   .9678468   .0119668    -2.64   0.008     .9446742    .9915879\n     agercs2 |    .999971   .0000315    -0.92   0.357     .9999092    1.000033\n     agercs3 |   1.000014   .0000304     0.46   0.648     .9999543    1.000074\n        pr_1 |   .9080251   .0118154    -7.41   0.000     .8851601    .9314808\n       _rcs1 |   2.464395   .0655981    33.88   0.000     2.339121    2.596377\n       _rcs2 |   1.227705   .0289332     8.70   0.000     1.172287    1.285744\n       _rcs3 |   1.013422   .0117182     1.15   0.249     .9907135    1.036652\n       _rcs4 |   1.005574   .0050256     1.11   0.266      .995772    1.015472\n       _cons |   .3891571   .0248262   -14.79   0.000     .3434176    .4409885\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nI now create some values of time that I want to predict at. I use the range command to give 100 values between 0 and 5 in a new variable tt.\n. range tt 0 5 100\n(2,882 missing values generated)\nAfter creating the new variable I can use it in the timevar() option when using stpm2’s predict command.\n. predict s0, survival timevar(tt) zeros ci\nThis will predict the baseline survival function at the time values in the variable tt. The zeros option sets all covarites equal to zero, i.e. the baseline. The ci option asks for the upper and lower bounds of the 95% confidence interval to be calculated. The function can now be plotted.\n. twoway (rarea s0_lci s0_uci tt, color(blue%25)) ///\n&gt;                 (line s0 tt, lcolor(red)) ///\n&gt;                 , legend(off) ///\n&gt;                 ylabel(,angle(h) format(%3.1f)) ///\n&gt;                 xtitle(\"Years from surgery\") ///\n&gt;                 ytitle(\"S(t)\")"
  },
  {
    "objectID": "software/stpm2/stpm2_timevar.html#combining-with-the-at-option.",
    "href": "software/stpm2/stpm2_timevar.html#combining-with-the-at-option.",
    "title": "Use of the timevar() option",
    "section": "Combining with the at() option.",
    "text": "Combining with the at() option.\nIt is possible to make predictions at any values the covariates included in the model using the at() option. The two lines below predict the hazard functions for women using and not using hormonal treatment at the reference age (60) and the mean value of log progesterone receptor (3.43).\n. predict h0, hazard timevar(tt) at(hormon 0 pr_1 3.43) zeros per(1000) ci\n\n. predict h1, hazard timevar(tt) at(hormon 1 pr_1 3.43) zeros per(1000) ci\nI have used the timevar(tt) option again and so predictions will be at the 100 value of tt (actually at 99 values as the hazard is not defined at t=0). The at() option gives the values of the covariates that we want to predict at. The zeros option will set any remaining covariates equal to zero, i.e. the age spline variables are set to zero which is the reference age of 60. The per(1000) option multiplies the hazard rate by 1000 as it is easier to interpret the rate per 1000 years than per person per year.\nThe resulting predictions are then plotted,\n. twoway  (rarea h0_lci h0_uci tt, color(red%25)) ///             \n&gt;                 (rarea h1_lci h1_uci tt, color(blue%25)) ///\n&gt;                 (line h0 tt, lcolor(red) lwidth(thick)) ///\n&gt;                 (line h1 tt, lcolor(blue) lwidth(thick)) ///\n&gt;                 ,xtitle(\"Years from surgery\") ///\n&gt;                 ytitle(\"Recrurrence rate (per 1000 py)\") ///\n&gt;                 legend(order( 3 \"hormon=0\" 4 \"hormon=1\") ring(0) pos(1) cols(1))\n\nAs the model assumes proportional hazards the predicted hazard functions are perfectly proportional."
  },
  {
    "objectID": "software/stpm2/stpm2_timevar.html#predictions-at-single-values-of-time.",
    "href": "software/stpm2/stpm2_timevar.html#predictions-at-single-values-of-time.",
    "title": "Use of the timevar() option",
    "section": "Predictions at single values of time.",
    "text": "Predictions at single values of time.\nIt can be useful to see the variation in survival at specific values of time, for example at one and five years. The followig code predicts the survival at one year for all subjects in the dataset.\n. gen t1 = 1 \n\n. predict s_time1, survival timevar(t1) \nThis can then be plotted in a histogram.\n. hist s_time1, width(0.02) xlab(0.3(0.1)1) name(t1, replace)             \n(bin=7, start=.81623113, width=.02)\n\nWe can compare this to the variation at 5 years.\n. gen t5 = 5 \n\n. predict s_time5, survival timevar(t5) \n\n. hist s_time5, width(0.02) xlab(0.3(0.1)1)  name(t5, replace)\n(bin=22, start=.30392122, width=.02)\n\nIf we are interested in specific covariates then we can look at 1 and 5 year survival as a function of that covariate. For example, we can plot the 1 and 5 year survival as a function of age at diagnosis. As this will also depend on the values of the other covariate I will fix these at specific values (not on hormonal treatment and at the mean level of log progesterone receptor).\nFirst the one year survival as a function of age,\n. predict t1_age, surv at(hormon 0 pr_1 3.43) ci timevar(t1)\n\n. twoway  (rarea t1_age_lci t1_age_uci age, sort color(blue%25))  ///\n&gt;                 (line t1_age age, sort lcolor(red)) ///\n&gt;                 ,ytitle(\"1 year survival\") legend(off) ///\n&gt;                 ylabel(,angle(h) format(%3.1f)) name(age_t1, replace)\n\nAnd now the 5 year survival….\n. predict t5_age, surv at(hormon 0 pr_1 3.43) ci timevar(t5)\n\n. twoway  (rarea t5_age_lci t5_age_uci age, sort color(blue%25))  ///\n&gt;                 (line t5_age age, sort lcolor(red)) ///\n&gt;                 ,ytitle(\"5 year survival\") legend(off) ///\n&gt;                 ylabel(,angle(h) format(%3.1f)) name(age_t5, replace)"
  },
  {
    "objectID": "software/stpm2/out_of_sample_predictions.html",
    "href": "software/stpm2/out_of_sample_predictions.html",
    "title": "Producing out-of-sample predictions from a flexible parametric survival model",
    "section": "",
    "text": "Download Stata Do file here\n\n\nBy Sarah Booth (sarah.booth@le.ac.uk)\n\n\nBackground\nAfter fitting a flexible parametric survival model (FPM) it is easy to produce out-of-sample predictions in a new dataset as the model is stored in memory. However, what if you didn’t have access to the original dataset? For example, you may want to test how well a published prognostic model works in your own dataset.\nThe easiest way to reproduce an FPM is if you have access to the saved Stata model estimates in an .ster file. This file doesn’t include anything about the original data used to fit the model and can therefore be shared freely. The required predictions can then be produced after using estimates use to load the model.\nHowever, as this file may not be available, in this tutorial I’ll also show how an FPM can be reconstructed using only the model coefficients and knot locations.\n\n\nFitting an example model\nAs an example, I’ll use a simulated dataset that is loosely based on survival following a diagnosis of cancer. It includes the following variables: ID number (id), year of diagnosis (yydx, 2009-2019), date of diagnosis (dx), date of death/censoring (exit), survival status (status, 0 = Alive, 1 = Dead), age at diagnosis (age, 44-93), sex (sex, 0 = Male, 1 = Female) and stage of tumour at diagnosis (stage, 1-3).\nI’ll start by creating some dummy variables for sex and stage of tumour at diagnosis and fit a model that includes age, sex and stage of tumour as covariates. I’ll centre age on 70 so that the baseline has a meaningful interpretation.\nuse https://www.pclambert.net/data/simulated_survival, clear\ntab stage, gen(stage)\ngen female = sex == 1 \ngen age_centre = age - 70\nWhen fitting the model, I’ll use the noorthog option so that the baseline splines won’t be orthogonalized which makes it easier to re-construct the FPM without the need for any matrix algebra.\n. stset exit, origin(dx) fail(status==1) scale(365.25) ///\n&gt; exit(time dx+10*365.25)\n\nSurvival-time data settings\n\n         Failure event: status==1\nObserved time interval: (origin, exit]\n     Exit on or before: time dx+10*365.25\n     Time for analysis: (time-origin)/365.25\n                Origin: time dx\n\n--------------------------------------------------------------------------\n     55,050  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     55,050  observations remaining, representing\n     22,180  failures in single-record/single-failure data\n 397,922.36  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. \n. stpm2 age_centre female stage2 stage3, df(5) scale(hazard) noorthog\n\nIteration 0:  Log likelihood = -58450.715  \nIteration 1:  Log likelihood = -58447.706  \nIteration 2:  Log likelihood = -58447.701  \n\nLog likelihood = -58447.701                             Number of obs = 55,050\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n  age_centre |   .0288174   .0011243    25.63   0.000     .0266138    .0310211\n      female |   -.077212   .0134341    -5.75   0.000    -.1035424   -.0508816\n      stage2 |   1.211915   .0217077    55.83   0.000     1.169368    1.254461\n      stage3 |   3.078478   .0214495   143.52   0.000     3.036438    3.120519\n       _rcs1 |   .8072818   .0240466    33.57   0.000     .7601513    .8544123\n       _rcs2 |   .0093188   .0062436     1.49   0.136    -.0029184     .021556\n       _rcs3 |  -.0225463   .0219503    -1.03   0.304    -.0655681    .0204754\n       _rcs4 |   .0177935   .0393819     0.45   0.651    -.0593935    .0949805\n       _rcs5 |   -.003851   .0377596    -0.10   0.919    -.0778584    .0701564\n       _cons |  -3.654475   .0716417   -51.01   0.000     -3.79489    -3.51406\n------------------------------------------------------------------------------\n\n\nProducing the predictions using the model stored in memory\nI’ll now use the model stored in memory to produce 10-year survival curves for the following covariate patterns:\n\n70 years old (age_centre = 70 - 70 = 0) male with a stage 1 tumour (baseline)\n80 years old (age_centre = 80 - 70 = 10) female with a stage 2 tumour\n85 years old (age_centre = 85 - 70 = 15) male with a stage 3 tumour\n\nrange timevar10 0 10 100\npredict s0, zeros surv timevar(timevar10)\npredict s1, at(age_centre 10 female 1 stage2 1) zeros surv timevar(timevar10)\npredict s2, at(age_centre 15 stage3 1) zeros surv timevar(timevar10)\n\n\nProducing the predictions using an .ster file\nIf the .ster file is available, this can be loaded in to Stata in order to produce the predictions.\n. estimates use https://www.pclambert.net/data/oosmodel.ster\n\n. predict s0_ster, zeros surv timevar(timevar10)\n\n. predict s1_ster, at(age_centre 10 female 1 stage2 1) zeros surv timevar(timevar10)\n\n. predict s2_ster, at(age_centre 15 stage3 1) zeros surv timevar(timevar10)\n\n\nProducing the predictions using the model coefficients\nA PH flexible parametric survival model is fitted on the log cumulative hazard scale where a restricted cubic spline function \\(\\zeta (\\ln(t)|\\gamma,k_0)\\) is used to model the baseline. Here, \\(k_0\\) is the vector of knot locations, the \\(z\\) terms are the derived variables (basis functions) and the \\(\\gamma\\) terms are the model coefficients for these derived variables. The linear predictor \\(\\beta x_i\\) contains the log hazard ratios. Using this information, I’ll now show how these predictions can be produced when the model is not stored in memory.\n\\[ \\ln[H(t|x_i)] = \\ln[H_0(t)] + \\beta x_i = \\zeta (\\ln(t)|\\gamma,k_0) + \\beta x_i \\]\n\\[ \\zeta (\\ln(t)|\\gamma,k_0) = \\gamma_0 + \\gamma_1 z_{1} + \\gamma_2 z_{2} + ... + \\gamma_{K-1} z_{K-1} \\]\nThe table below displays the model coefficients (log hazard ratios) from the model. The knot locations on the log time scale (stored in e(ln_bhknots)) are also required to produce the predictions. For this model the knots are positioned at: -5.875508413078693 -0.6125073943959456 0.4430906852086161 1.156903994968461 1.750977782183514 2.302560494813347 on the log time scale.\n\n\n\nVariable\nCoefficient\n\n\n\n\nAge (centred)\n0.02881744\n\n\nFemale\n-0.07721197\n\n\nStage 2\n1.21191450\n\n\nStage 3\n3.07847830\n\n\n\\(\\gamma_0\\) (_cons)\n-3.65447470\n\n\n\\(\\gamma_1\\) (_rcs1)\n0.80728180\n\n\n\\(\\gamma_2\\) (_rcs2)\n0.00931881\n\n\n\\(\\gamma_3\\) (_rcs3)\n-0.02254634\n\n\n\\(\\gamma_4\\) (_rcs4)\n0.01779351\n\n\n\\(\\gamma_5\\) (_rcs5)\n-0.00385097\n\n\n\nThe first step is to generate the restricted cubic spline functions of log time which can be achieved using rcsgen and specifying the list of knot locations.\ngen double lntime = ln(timevar10)\nrcsgen lntime, gen(z) knots(-5.875508413078693 -0.6125073943959456 ///\n               0.4430906852086161 1.156903994968461 1.750977782183514 2.302560494813347)\nThe log cumulative hazard can then be calculated for each of the covariate patterns using the above equations. These can then be transformed to the survival scale using the following equation:\n\\[ S(t|x_i) =  \\exp \\left[ - [H(t|x_i)] \\right]   = \\exp \\left[ - \\exp \\left[\\ln[H(t|x_i)] \\right] \\right]  \\]\nThe survival predictions for time zero will be undefined as the log of zero is required in this calculation. However, by definition S(0) = 1, and therefore this can be added manually.\n// Calculate the log cumulative hazard\ngen double logCH_0 = -3.6544747 + 0.8072818*z1 + 0.00931881*z2 + -0.02254634*z3 + ///\n                     0.01779351*z4 + -0.00385097*z5\ngen double logCH_1 = logCH_0 + 10*0.02881744 + -0.07721197 + 1.2119145  \ngen double logCH_2 = logCH_0 + 15*0.02881744 + 3.0784783 \n\n// Transform to the survival scale\ngen double s0_rcs = exp(-exp(logCH_0))\ngen double s1_rcs = exp(-exp(logCH_1))\ngen double s2_rcs = exp(-exp(logCH_2))\n\n// S(0) = 1\nforvalues i = 0/2 {\n    replace s`i'_rcs = 1 in 1\n}\nFinally, we can check that the survival predictions match those that we originally calculated when the model was stored in memory. Here there is agreement to at least 5 decimal places but the predictions that were produced using the model coefficients are slightly different due to the precision that the model coefficients, knots and variables were stored to.\n. summ s0* s1* s2*\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n          s0 |        100     .922136    .0380317   .8633618          1\n     s0_ster |        100     .922136    .0380317   .8633618          1\n      s0_rcs |        100     .922136    .0380316   .8633618          1\n          s1 |        100    .7223094    .1249454   .5435774          1\n     s1_ster |        100    .7223094    .1249454   .5435774          1\n-------------+---------------------------------------------------------\n      s1_rcs |        100    .7223094    .1249453   .5435776          1\n          s2 |        100    .1542438    .2111177   .0073144          1\n     s2_ster |        100    .1542438    .2111177   .0073144          1\n      s2_rcs |        100    .1542438    .2111177   .0073144          1\n\n\nReferences\nRoyston, P. & Lambert, P. C. Flexible Parametric Survival Analysis Using Stata: Beyond the Cox Model, 2011"
  },
  {
    "objectID": "software/stpm2/comparewithcox.html",
    "href": "software/stpm2/comparewithcox.html",
    "title": "Proportional hazards models in stpm2",
    "section": "",
    "text": "Proportional hazards model\nWe first load the example breast cancer data data using webuse and then use stset to declare the survival time and event indicator.\n. webuse brcancer, clear\n(German breast cancer data)\n\n. stset rectime, f(censrec==1) scale(365.24)\n\n     failure event:  censrec == 1\nobs. time interval:  (0, rectime]\n exit on or before:  failure\n    t for analysis:  time/365.24\n\n------------------------------------------------------------------------------\n        686  total observations\n          0  exclusions\n------------------------------------------------------------------------------\n        686  observations remaining, representing\n        299  failures in single-record/single-failure data\n  2,112.036  total analysis time at risk and under observation\n                                                at risk from t =         0\n                                     earliest observed entry t =         0\n                                          last observed exit t =  7.280145\nThe scale(365.25) option converts the times recorded in days to years.\nA standard Cox proportional hazards model can be defined as follows,\n\\[\nh_i(t|\\mathbf{x}_i)=h_0(t)\\exp\\left(\\mathbf{x}_i\\boldsymbol{\\beta}\\right)\n\\]\nA key point about the Cox model is that we do not estimate the baseline hazard, \\(h\\_0(t)\\), as this cancels out in the partial likelihood, so we only estimate the relative effects, i.e. hazard ratios.\nWe can now fit a Cox model in Stata with hormon as the only covariate.\n. stcox hormon, \n\n         failure _d:  censrec == 1\n   analysis time _t:  rectime/365.24\n\nIteration 0:   log likelihood = -1788.1731\nIteration 1:   log likelihood =  -1783.774\nIteration 2:   log likelihood =  -1783.765\nIteration 3:   log likelihood =  -1783.765\nRefining estimates:\nIteration 0:   log likelihood =  -1783.765\n\nCox regression -- Breslow method for ties\n\nNo. of subjects =          686                  Number of obs    =         686\nNo. of failures =          299\nTime at risk    =  2112.035922\n                                                LR chi2(1)       =        8.82\nLog likelihood  =    -1783.765                  Prob &gt; chi2      =      0.0030\n\n------------------------------------------------------------------------------\n          _t | Haz. Ratio   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n      hormon |   .6949616   .0869009    -2.91   0.004      .543905    .8879705\n------------------------------------------------------------------------------\nWe will now fit a flexible parametric survival model. Here are model is on the log cumulative hazard scale, so our model is defined using uppercase H rather than lowercase h.\n\\[\nH_i(t|\\mathbf{x}_i)=H_0(t)\\exp\\left(\\mathbf{x}_i\\boldsymbol{\\beta}\\right)\n\\]\nDo we have to worry about the switch from hazard function to cumulative hazard function? Well, the answer is “No” as if we have proportional hazards we also have proportional cumulative hazards.\nIn the flexible parametric survival model we estimate the baseline using restriced cubic splines. So we need additional parameters to estimate the baseline (the log cumulative hazard in this case). The linear predictor is,\n\\[\n\\ln[H(t|\\mathbf{x}_i)] = \\eta_i(t) = s\\left(\\ln(t)|\\boldsymbol{\\gamma}, \\mathbf{k}_{0}\\right) + \\mathbf{x}_i \\boldsymbol{\\beta}\n\\]\nwhere \\(s\\left(\\ln(t)|\\boldsymbol{\\gamma}, \\mathbf{k}_{0}\\right)\\) is a restricted cubic spline function of log(time).\nWe now fit this model in Stata using stpm2.\n. stpm2 hormon, df(3) scale(hazard) eform\n\nIteration 0:   log likelihood = -671.75275  \nIteration 1:   log likelihood = -670.39949  \nIteration 2:   log likelihood = -670.39239  \nIteration 3:   log likelihood = -670.39239  \n\nLog likelihood = -670.39239                     Number of obs     =        686\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |   .6966754   .0870015    -2.89   0.004     .5454206    .8898757\n       _rcs1 |   4.931928   .6329089    12.43   0.000     3.835156    6.342354\n       _rcs2 |   1.786812   .2092654     4.96   0.000     1.420329    2.247857\n       _rcs3 |   .9519031     .03275    -1.43   0.152     .8898306    1.018306\n       _cons |   .3032836   .0247012   -14.65   0.000     .2585366    .3557753\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nI have used three options. The df(3) option requests there to be 3 restricted cubic spline parameters (4 knots). These are at the default knot locations, which are at evenly spaced centiles of the uncensored event times. The scale() option defines the link function and scale(hazard) asks for a log(-log) link function, i.e. our linear predictor is on the log cumulative hazard scale. The eform option means that the coefficients will be exponentiated.\nThe key point here is the similarity between the hazard ratios form the two models. This is nearly always the case. I will try to convince anyone who does not believe this in future posts.\nA sensible question is, if we get the same anwers, why not just fit a Cox model? Well, if all you want is a single hazard ratio and proportional hazards is a reasonable assumption then I agree with you. However, as I will show in other examples, there are many advantages of the parametric approach.\nThere are a number of issues that people may raise. This include how many knots to use and where to put the knots. I will cover these in future tutorials."
  },
  {
    "objectID": "software/stcrprep/stpm3_to_model_CIFs.html",
    "href": "software/stcrprep/stpm3_to_model_CIFs.html",
    "title": "stcrprep - using `stpm3’ to model cause-specific CIFs",
    "section": "",
    "text": "The ideas of Geskus (2011) to expand the data and then the Cox modelling framework to fit a subhazard model can be also applied to parametric models. When fitting a parametric model for the CIF using weighted maximum likelihood, the censoring distribution is a continuous function of time, so rather than using the Kaplan-Meier estimate a (flexible) parametric model is used to obtain the weights.\nThe likelihood involves a non-tractible integral and so an approximation is used by splitting the time scale into a number of intervals. See out paper on this where we show that these intervals can be fairly wide, which is useful in large datasets (Lambert et al. 2016).\nWith this approach then, after restructuring the data and calculating the weights, we can use standard parametric survival models to estimate the cause-specific CIF. I now use stpm3 to fit a flexible parametric survival model.\nFirst I load and stset the data.\nI use stcrprep as I wantted to fit a Cox model, but now I ask that the time-dependent weights are calculated using stpm2 with 4 d.f. to model the baseline. Note that stcrprep was written before I released stpm3, which is why the options is wtstpm2. The every(0.25) option requests that the time scale is split every 0.25 years. This means that the weights are updated every quarter of a year in the expanded dataset.\nWe can the predict command to obtain estimates of the CIFs.\nI have predicted the CIFs for each of the 3 risk groups together with 95% confidence intervals. In addition, I have calculated the difference in CIFs (with score group 1 as the reference).\nI can plot the baseline CIF with 95% CI.\nI can plot all three predicted CIFs.\nI can plot the difference in CIFs between the high and low risk group."
  },
  {
    "objectID": "software/stcrprep/stpm3_to_model_CIFs.html#references",
    "href": "software/stcrprep/stpm3_to_model_CIFs.html#references",
    "title": "stcrprep - using `stpm3’ to model cause-specific CIFs",
    "section": "References",
    "text": "References\nGeskus, R. B. Cause-specific cumulative incidence estimation and the Fine and Gray model under both left truncation and right censoring. Biometrics 2011; 67:39–49.\nLambert, P.C., S.R. Wilkes, and M.J. Crowther. Flexible parametric modelling of the cause-specific cumulative incidence function. Statistics in Medicine 2016;36:1429-1446."
  },
  {
    "objectID": "software/stcrprep/nonparametriccif.html",
    "href": "software/stcrprep/nonparametriccif.html",
    "title": "stcrprep - non parametric cause-specific CIFs",
    "section": "",
    "text": ". clear frames\n\n. set scheme fpsaus_c\nI will use the same data set I use in the Stata Journal article on stcrprep. This comprises of 1977 patients from the European Blood and Marrow Transplantation (EBMT) registry who received an allogeneic bone marrow transplantation. Time is measured in days from transplantation to either relapse or death. There is only one covariate of interest, the EBMT risk score, which has been categorized into 3 groups (low, medium and high risk). The data is available as part of the mstate R package (de Wreede et al. 2011).\nFirst I load the data,\nThe tabulation shows that of the 1,977 subjects, 836 were censored, 456 had a relapse and 686 had a death before relapse. Now we can stset the data declaring both relapse and death as an event in the failure() option.\nIn order to show how stcrprep expands the data and calculates the probability of censoring weights for those with a competing event, I will list the data of a single individual before and after using stcrprep. The listing is for subject 17 (patid==17).\nThis subject died after 2.29 years and before using stcrprep has just has one row of data.\nNext I use stcrprep to restructure the data. The events() option requires the variable defining all possible events and the censored value. The trans() option gives the transitions of the events of interest; here we are interested in the transitions to both relapse(status=1) and death (status=2); this is actually the default, but is shown here for clarity. The keep() option is used to list variables to retain in the expanded data; usually any covariates that will be later analysed are included here. The byg() option requests the censoring distribution to be estimated separately for the given groups. Since we are first going to obtain a separate non-parametric estimate of the cause-specific CIF in each group, the byg() option will estimate the censoring distribution separately in each group.\nAfter using stcrprep the number of rows has increased from 1977 to 70262. The rows have been divided based on the failure of the newly created variable failcode. This variable will be used to fit different models depending on the event of interest. The variables patid and status are the same as in the non expanded data. The variables tstart and tstop give the times an individual starts and stops being at risk. They change within an individual when their weight, defined by variable weight_c, changes value. The weight_t gives the weights when there is left trunction. As there is no left truncation in this data, it takes the value 1 for all subjects at all times.\nWhen failcode==1 this corresponds to when a relapse is the event of interest. As the subject with patid==17 died after 2.29 years (i.e. had a competing event), they are initially at risk until this time and they should receive a weight of 1 in the analysis. After their death they are still kept in the risk set, but their weight decreases. The decrease is based on the conditional probability of being censored which is estimated using a non-parametric (Kaplan-Meier) estimate of the censoring distribution. The weights only change at times when there is a failure for the event of interest and the value of censoring distribution has changed.\nWhen failcode==2 this corresponds to when death is the event of interest. Since this patient experienced the event of interest (i.e. they died) rather than the competing event, they only require one row of data.\nWe can use sts graph to give a plot of the cause-specific CIF. We first need to stset the data utilizing the information on the weights contained in variable weights_c by specifiying iweights.\nWe first create the variable, event. This is defined as 1 if the event of interest occurs and zero otherwise. As we have split time data, we need to give information on the start time (tstart) and stop time (tstop) of each row of data. We use sts graph in the usual way, but use the failure option as we are interested in the probability of relapse as opposed to the probability of not having a relapse (which includes the probability of death). For example, the cause-specific CIF for relapse can be plotted as follows,\nNote that the lines are extended to the maximum censoring time in each group, rather than the maximum event time. Alternatively, sts gen can be used to generate the cause-specific CIF and this can be plotted with appropriate if statements to control the maximum follow-up time for each line.\nIt is also possible to list the CIF at specific time points using sts list. For example, the cause-specific CIF at 1 and 5 years by risk group and for each cause can be obtained as follows,\nNow, we can test for differences in the cause-specific CIF using sts test. Note that is slightly different to the modified log rank test defined by Gray (1988)."
  },
  {
    "objectID": "software/stcrprep/nonparametriccif.html#references",
    "href": "software/stcrprep/nonparametriccif.html#references",
    "title": "stcrprep - non parametric cause-specific CIFs",
    "section": "References",
    "text": "References\nde Wreede, L.; Fiocco, M. & Putter, H. mstate: An R package for the analysis of competing risks and multi-state models. Journal of Statistical Software 2011;38.\nGray, R. A class of K-sample tests for comparing the cumulative incidence of a competing risk. The Annals of Statistics 1988;16:1141-1154."
  },
  {
    "objectID": "software/standsurv.html",
    "href": "software/standsurv.html",
    "title": "standsurv",
    "section": "",
    "text": "The standsurv command estimates standardized survival curves and related measures. It also allows various contrasts between the standardized functions. It is a post-estimation command and can be used after fitting a wide range of survival models. These include streg models (except generalized gamma), stpm2 models, stpm3models and strcs models.\nNote that I previously developed stpm2_standsurv, which only works with stpm2 models, but standsurv superceeds that. You can do the same things with standsurv and much, much more.\nSo some of the examples are the same as stpm2_standsurv.\nYou can install standsurv within Stata using"
  },
  {
    "objectID": "software/standsurv.html#using-standsurv",
    "href": "software/standsurv.html#using-standsurv",
    "title": "standsurv",
    "section": "Using standsurv",
    "text": "Using standsurv\n\nStandard Survival Models\n\nStandardized survival functions and contrasts.\nCentiles of the standardized survival function.\nRestricted mean survival using standardized survival functions.\nThe hazard function of the standardized survival curve.\nEstimating attributable fractions in cohort studies\nSome comments on why I am not so keen on stteffects\nWhy just not use margins?\n\n\n\nCompeting Risk Models\n\nStandardized cause-specific cumulative incidence functions.\nOther useful standardized measures in competing risks\n\n\n\nRelative/Net Survival Models\n\nStandardized Relative Survival.\n\nExternal age-standardization\nLoss in Expectation of Life\nStandardized Crude Probabilities of death."
  },
  {
    "objectID": "software/standsurv.html#general",
    "href": "software/standsurv.html#general",
    "title": "standsurv",
    "section": "General",
    "text": "General\n\nComparing models fitted in different countries"
  },
  {
    "objectID": "software/standsurv.html#releases",
    "href": "software/standsurv.html#releases",
    "title": "standsurv",
    "section": "Releases",
    "text": "Releases\nSee standsurv_releases.txt"
  },
  {
    "objectID": "software/standsurv/standardized_survival_rmst.html",
    "href": "software/standsurv/standardized_survival_rmst.html",
    "title": "RMST of Standardized Survival Functions",
    "section": "",
    "text": "Here I will show another useful measure from standardized survival functions. There have been several papers promoting the use of restricted mean survival time (RMST) in clinical trials. The arguments are (i) ease of interpretation (though I am not convinced a restricted mean is that easy to explain) and (ii) providing a simple summary in the presence of non-proportional hazards. See Royston and Parmar (2013) for a description of the use of the measure in RCTs.\nThe restricted mean survival time at time \\(t^*\\) is defined as, \\[\nE\\left[min(t,t^*)\\right]\n\\] i.e. it is the mean up to some point \\(t^*\\). The treatment effect in a RCT can be defined as the difference in RMST between the randomized arms at time \\(t^*\\). The RMST can be estimated by calculating the area under the survival curve between 0 and \\(t^*\\). In an observational study where we need to take account of potential confounders, we can define the RMST of the standardized survival function as\n\\[\nRMST(t^*|X=x,Z) = \\int_0^{t^*} E\\left[S(t|X=x,Z)\\right]\n\\]\nand is estimated by\n\\[\n\\widehat{RMST}(t^*|X=x,Z) = \\int_0^{t^*} \\frac{1}{N}\\sum\\_{i=1}^{N}S(t|X=x,Z=z_i)]\n\\]\nContrasts between exposure groups can either be differences or ratios,\n\\[\n\\widehat{RMST}(t^*|X=1,Z) - \\widehat{RMST}(t^*|X=0,Z)\n\\]\n\\[\n\\frac{\\widehat{RMST}(t^*|X=1,Z)}{\\widehat{RMST}(t^*|X=0,Z)}\n\\]\nStandardized RMST and contrasts is implemented in standsurv using the rmst option."
  },
  {
    "objectID": "software/standsurv/standardized_survival_rmst.html#example",
    "href": "software/standsurv/standardized_survival_rmst.html#example",
    "title": "RMST of Standardized Survival Functions",
    "section": "Example",
    "text": "Example\nI will use the Rotterdam Breast cancer data. The code below loads and stset’s the data and then fits a model using stpm3.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm3 i.hormon age enodes pr_1, scale(lncumhazard) df(4) eform nolog tvc(i.hormon) dftvc(3)\n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  = 615.95\nLog likelihood = -2666.5968                             Prob &gt; chi2   = 0.0000\n\n-----------------------------------------------------------------------------------\n                  |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------+----------------------------------------------------------------\nxb                |\n           hormon |\n             yes  |   .8499802   .0963501    -1.43   0.152     .6806444    1.061445\n              age |   1.013249   .0024115     5.53   0.000     1.008534    1.017987\n           enodes |   .1132408    .011008   -22.41   0.000     .0935963    .1370084\n             pr_1 |   .9061179   .0119267    -7.49   0.000     .8830411    .9297979\n------------------+----------------------------------------------------------------\ntime              |\n             _ns1 |  -27.09524   2.109681   -12.84   0.000    -31.23014   -22.96034\n             _ns2 |   8.647725   1.122097     7.71   0.000     6.448455    10.84699\n             _ns3 |  -1.072205   .0477674   -22.45   0.000    -1.165827   -.9785823\n             _ns4 |  -.6930019   .0518048   -13.38   0.000    -.7945373   -.5914664\n                  |\nhormon#c._ns_tvc1 |\n             yes  |   5.425507    3.92237     1.38   0.167    -2.262197    13.11321\n                  |\nhormon#c._ns_tvc2 |\n             yes  |  -3.309698   2.096769    -1.58   0.114    -7.419291    .7998943\n                  |\nhormon#c._ns_tvc3 |\n             yes  |  -.1256484    .195217    -0.64   0.520    -.5082667      .25697\n                  |\n            _cons |   .7984459   .1615956     4.94   0.000     .4817244    1.115168\n-----------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nI have made the effect of our exposure, hormon, time-dependent using the tvc option to illustrate that we can have interactions etc with our exposure in our model. This is an interaction with time, i.e. non proportional hazards.\nI first calculate the standardized survival curves where everyone is forced to be exposed and then unexposed.\n. range timevar 0 10 100\n(2,882 missing values generated)\n\n. standsurv, surv timevar(timevar) ci frame(surv, replace)          ///\n&gt;            at1(hormon 0) at2(hormon 1) atvar(S_hormon0 S_hormon1)\n\n. \n. frame surv {\n.   twoway (area S_hormon0 timevar, sort fcolor(%30)) ///\n&gt;          , legend(off)                              ///\n&gt;          ylabel(0(0.1)1, format(%3.1f))             ///\n&gt;          ytitle(\"S(t)\")                             ///\n&gt;          xtitle(\"Years from surgery\")               ///\n&gt;          title(\"No treatment\")                      ///\n&gt;          name(hormon0, replace)\n.   \n.   twoway (area S_hormon1 timevar, sort pstyle(p2line) fcolor(%30)) ///\n&gt;          , legend(off)                                             ///\n&gt;          ylabel(0(0.1)1, format(%3.1f))                            ///\n&gt;          ytitle(\"S(t)\")                                            ///\n&gt;          xtitle(\"Years from surgery\")                              ///\n&gt;          title(\"Treatment\")                                        ///\n&gt;          name(hormon1, replace)\n.                 \n.   graph combine hormon0 hormon1, nocopies               \n. }\n\nThe RMST at 10 years for each of the standardized survival functions is the area under the standardized survival curve, shown by the shaded areas in the graphs above.\nI will now run standsurv again with the rmst option to estimate these togther with the difference in RMST. I only want the RMST at 10 years so create a variable t_rmst10 with only one observation, equal to 10.\n. gen t10 = 10 in 1\n(2,981 missing values generated)\n\n. standsurv, rmst timevar(t10) ci frame(rmst, replace)          ///\n&gt;            at1(hormon 0) at2(hormon 1) atvar(rmst_h0 rmst_h1) ///\n&gt;            contrast(difference) contrastvar(rmstdiff)\nI will first list the standardized RMST in both treatment groups.\n. frame rmst: list t10 rmst_h0* rmst_h1* in 1, noobs abb(12) \n\n  +-------------------------------------------------------------------------------------+\n  | t10     rmst_h0   rmst_h0_lci   rmst_h0_uci     rmst_h1   rmst_h1_lci   rmst_h1_uci |\n  |-------------------------------------------------------------------------------------|\n  |  10   7.5444253     7.4318217      7.658735   7.9386172      7.687098      8.198366 |\n  +-------------------------------------------------------------------------------------+\nThe RMST at 10 years is 7.54 years in those not taking treatment and 7.94 years in those taking treatment. The 95% confidence intervals are also shown. As I used the contrast(difference) option I can look at the difference in RMST at 10 years.\n. frame rmst: list t10    rmstdiff* in 1, noobs abb(12)\n\n  +-----------------------------------------------+\n  | t10    rmstdiff   rmstdiff_lci   rmstdiff_uci |\n  |-----------------------------------------------|\n  |  10   .39419189        .116234      .67214979 |\n  +-----------------------------------------------+\nThe difference is 0.39 years (95% CI 0.12 to 0.67).\nThe RMST will vary by the choice of \\(t^*\\). A range of values of \\(t^*\\) can be given and then plotted.\n. range t_rmst 0 10 50\n(2,932 missing values generated)\n\n. standsurv, rmst timevar(t_rmst) ci frame(rmst2, replace)      ///\n&gt;            at1(hormon 0) at2(hormon 1) atvar(rmst_h0 rmst_h1) ///\n&gt;            contrast(difference) contrastvar(rmstdiff)\nWe can plot how the RMST changes and the difference in RMST changes as a function of \\(t^\\*\\).\n. frame rmst2 {\n.   twoway (line rmst_h0 rmst_h1 t_rmst) ///\n&gt;          , legend(order(1 \"No treatment\" 2 \"Treatment\") cols(1) pos(11)) ///\n&gt;          ytitle(\"RMST (years)\") ///\n&gt;          xtitle(\"Years from surgery\") ///\n&gt;          name(RMST,replace)\n.   \n.   twoway (rarea rmstdiff_lci rmstdiff_uci t_rmst, color(blue%20)) ///\n&gt;          (line rmstdiff t_rmst, lcolor(blue))                     ///\n&gt;          , legend(off)                                            ///\n&gt;          ylabel(, format(%3.1f))                                  ///\n&gt;          ytitle(\"Difference in RMST (years)\")                     ///\n&gt;          xtitle(\"Years from surgery\")                             ///\n&gt;                    name(RMSTdiff, replace)\n.                 \n.   graph combine RMST RMSTdiff, nocopies\n. }"
  },
  {
    "objectID": "software/standsurv/standardized_survival_rmst.html#references",
    "href": "software/standsurv/standardized_survival_rmst.html#references",
    "title": "RMST of Standardized Survival Functions",
    "section": "References",
    "text": "References\nRoyston, P. Parmar, M. K. B. Restricted mean survival time: an alternative to the hazard ratio for the design and analysis of randomized trials with a time-to-event outcome. BMC medical research methodology 2013;13:152"
  },
  {
    "objectID": "software/standsurv/standardized_survival_centiles.html",
    "href": "software/standsurv/standardized_survival_centiles.html",
    "title": "Centiles of Standardized Survival Functions",
    "section": "",
    "text": "In a previous tutorial I used standsurv to obtain standardized survival functions. In this tutorial I show the first of a number of different measures of the standardized survival function where I obtain centiles of the standardized survival function.\nAs a reminder a centile of a survival function can be obtained by solving \\(S(t) = \\alpha\\) for \\(t\\). For example, for the median survival time we set \\(\\alpha = 0.5\\), i.e. the 50th (per)centile. For simple parametric distributions, such as the Weibull, we can solve for \\(t\\) analytically, but for more complex models the centile is obtained through iterative root finding techniques. In stpm2 I have used Brent’s root finder when evaluating centiles.\nThe centile of a standardized survival function is obtained by solving the following equation for t.\n\\[\nE\\left(S(t | X=x,Z\\right) = \\alpha\n\\]\nThis is done through root finding (using Brent’s root finder) by solving,\n\\[\n\\frac{1}{N}\\sum_{i=1}^N {S(t | X=x,Z)} - \\alpha = 0\n\\]\nVariances can be obtained using M-estimation ."
  },
  {
    "objectID": "software/standsurv/standardized_survival_centiles.html#background",
    "href": "software/standsurv/standardized_survival_centiles.html#background",
    "title": "Centiles of Standardized Survival Functions",
    "section": "",
    "text": "In a previous tutorial I used standsurv to obtain standardized survival functions. In this tutorial I show the first of a number of different measures of the standardized survival function where I obtain centiles of the standardized survival function.\nAs a reminder a centile of a survival function can be obtained by solving \\(S(t) = \\alpha\\) for \\(t\\). For example, for the median survival time we set \\(\\alpha = 0.5\\), i.e. the 50th (per)centile. For simple parametric distributions, such as the Weibull, we can solve for \\(t\\) analytically, but for more complex models the centile is obtained through iterative root finding techniques. In stpm2 I have used Brent’s root finder when evaluating centiles.\nThe centile of a standardized survival function is obtained by solving the following equation for t.\n\\[\nE\\left(S(t | X=x,Z\\right) = \\alpha\n\\]\nThis is done through root finding (using Brent’s root finder) by solving,\n\\[\n\\frac{1}{N}\\sum_{i=1}^N {S(t | X=x,Z)} - \\alpha = 0\n\\]\nVariances can be obtained using M-estimation ."
  },
  {
    "objectID": "software/standsurv/standardized_survival_centiles.html#example",
    "href": "software/standsurv/standardized_survival_centiles.html#example",
    "title": "Centiles of Standardized Survival Functions",
    "section": "Example",
    "text": "Example\nI use a colon cancer example. I first load and stset the data\n. use https://www.pclambert.net/data/colon if stage!=0, clear\n(Colon carcinoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm, f(status=1,2) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: status==1 2\nObserved time interval: (0, surv_mm]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n     13,208  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     13,208  observations remaining, representing\n      8,866  failures in single-record/single-failure data\n 43,950.667  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nI drop those with missing stage information (stage == 0). I am investigating all cause survival (status=1,2).\nI fit a model that includes stage, sex and age (using a natural spline). I assume proportional hazards, but if I relax this assusmption the syntax for standsurv would be identical. Stage is classified as localised, regional and distant and is modelled as a factor variable with localised as the reference category.\n. gen female = sex==2\n\n. stpm3 i.stage i.female @ns(age,df(3)), scale(lncumhazard) df(4) nolog eform\n\n                                                       Number of obs =  13,208\n                                                       Wald chi2(6)  = 6155.27\nLog likelihood = -19665.932                            Prob &gt; chi2   =  0.0000\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n       stage |\n   Regional  |   1.758926   .0617187    16.09   0.000     1.642026    1.884149\n    Distant  |   5.656322   .1390555    70.48   0.000      5.39024    5.935539\n             |\n    1.female |   .8634681     .01891    -6.70   0.000     .8271894     .901338\n _ns_f1_age1 |   .0019791   .0012531    -9.83   0.000     .0005722    .0068455\n _ns_f1_age2 |   .7897475   .2383663    -0.78   0.434     .4370927    1.426931\n _ns_f1_age3 |   .1506021    .025846   -11.03   0.000     .1075845    .2108204\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -14.64251   .1616785   -90.57   0.000    -14.95939   -14.32563\n        _ns2 |   3.188902   .0786506    40.55   0.000     3.034749    3.343054\n        _ns3 |   -1.66889   .0227393   -73.39   0.000    -1.713459   -1.624322\n        _ns4 |  -1.036622   .0267331   -38.78   0.000    -1.089018    -.984226\n       _cons |   1.441705   .0983651    14.66   0.000     1.248912    1.634497\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nExtended functions\n (1) @ns(age, df(3))\nThere is a clear effect of stage with a hazard ratio of 5.66 for distant stage versus localised stage. Remember that I am modelling all cause survival and one would expect a cause-specific hazard ratio to be higher. The all-cause mortality rate for females is 14% lower than males.\nI will now predict two standardized survival functions, one where I force all subjects to be male and one where I force everyone to be female.\n. range tt 0 10 100\n(13,108 missing values generated)\n\n. standsurv, surv timevar(tt) ci frame(surv, replace)  ///\n&gt;            at1(female 0) at2(female 1)               ///\n&gt;            atvar(ms_male ms_female)      \n\n. frame surv {           \n.   twoway (line ms_male ms_female tt, sort)           ///\n&gt;          , yline(0.5, lpattern(dash) lcolor(black))  ///\n&gt;          yline(0.5, lpattern(dash) lcolor(black))    ///\n&gt;          xtitle(\"Years since diagnosis\")             ///\n&gt;          ytitle(\"S(t)\", angle(h))                    ///\n&gt;          ylabel(0(0.2)1, format(%3.1f) angle(h))     ///\n&gt;          legend(order(1 \"Male\" 2 \"Female\") pos(1) )\n. }         \nThe graph of the two standardised survival functions can be seen below.\n\nAs expected (given the hazard ratio) females have better survival than males. I have added a horizontal reference line at \\(S(t)=0.5\\). Where this line crosses the survival curves gives the median survival time. Reading from the graph, this is just under 2 years for the males and just under 2.5 years for females. Using the centile option of standsurv will estimate these values more accurately with 95% confidence intervals. We are also interested in contrasts of the centiles, so use of the contrast option will calculate either a difference or ratio of the median survival times with a 95% confidence interval.\n. standsurv, centile(50) ci frame(median)              ///\n&gt;           at1(female 0) at2(female 1)                ///\n&gt;                       atvar(med_male med_female)                 ///\n&gt;           contrast(difference) contrastvar(med_diff)\n\n. frame median {\n.   list med_male* med_female*,  ab(15) noobs     \n\n  +----------------------------------------------------------------------------------------+\n  |  med_male   med_male_lci   med_male_uci   med_female   med_female_lci   med_female_uci |\n  |----------------------------------------------------------------------------------------|\n  | 1.9801987      1.8875488      2.0773963    2.4249751        2.3197847        2.5349353 |\n  +----------------------------------------------------------------------------------------+\n.   list med_diff* in 1, ab(18) noobs\n\n  +-----------------------------------------+\n  |  med_diff   med_diff_lci   med_diff_uci |\n  |-----------------------------------------|\n  | .44477636      .31389716      .57565556 |\n  +-----------------------------------------+\n. }\nThe median survival time is 1.98 years for males with a 95% CI (1.87 to 2.09). The median for females is 2.42 years (95% CI, 2.30 to 2.56). As I used the contrast option I also get the difference in the median of the standardised survival curves with a 95% CI. Thus the time at which 50% of females have died is 0.44 years more than the time at which 50% of males have died, 95% CI (0.30 to 0.59).\nIt is possible to predict for multiple centiles by passing a numlist to the centiles option. For example, the code below calculates centiles between 10 and 60 at 10 unit intervals.\n. standsurv, centile(10(10)60) ci frame(cenrange) centvar(centiles)   ///\n&gt;            at1(female 0) at2(female 1)                              ///\n&gt;                        atvar(cen_males cen_females)                             ///\n&gt;            contrast(difference) contrastvar(cendiff) \n\n. frame cenrange {\n.   list centiles cen_males cen_females cendiff, sep(0) noobs ab(12)\n\n  +------------------------------------------------+\n  | centiles   cen_males   cen_females     cendiff |\n  |------------------------------------------------|\n  |       10   .14919254     .16940399   .02021145 |\n  |       20   .32365079     .38459929    .0609485 |\n  |       30   .63821705     .78393263   .14571558 |\n  |       40   1.1648032     1.4192444   .25444124 |\n  |       50   1.9801987     2.4249751   .44477636 |\n  |       60   3.4239223      4.277573   .85365069 |\n  +------------------------------------------------+\n. }\nWe can then plot the difference in these various centiles.\n. frame cenrange {\n.   twoway (rarea cendiff_lci cendiff_uci centile, sort color(%30))  ///\n&gt;          (line cendiff centile, pstyle(p1line))                    ///\n&gt;              , xtitle(centile) xlabel(,format(%3.0f))                  ///\n&gt;              ytitle(\"Difference in centile\")                           ///\n&gt;          ylabel(0(0.2)1.2,format(%3.1f) angle(h))                  ///\n&gt;              legend(off)\n. }\n\nThere are probably more innovative ways of presenting such data."
  },
  {
    "objectID": "software/standsurv/standardized_survival_centiles.html#acknowledgement",
    "href": "software/standsurv/standardized_survival_centiles.html#acknowledgement",
    "title": "Centiles of Standardized Survival Functions",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nI would like to acknowledge David Druker of StataCorp who I discussed these ideas with at two Nordic Stata User group meetings. David wrote a command that estimates centiles of standardized distributions using a two parameter gamma distribution which is available here."
  },
  {
    "objectID": "software/standsurv/standardized_survival_centiles.html#references",
    "href": "software/standsurv/standardized_survival_centiles.html#references",
    "title": "Centiles of Standardized Survival Functions",
    "section": "References",
    "text": "References\nStefanski, L. & Boos, D. The Calculus of M-Estimation. The American Statistician 2002;56:29-38"
  },
  {
    "objectID": "software/standsurv/standardized_survival.html",
    "href": "software/standsurv/standardized_survival.html",
    "title": "Standardized survival functions using standsurv",
    "section": "",
    "text": "When we are performing data exploration on survival data we usually start with plotting Kaplan-Meier curves. In clinical trials with a survival outcome, one would nearly always expect to see a Kaplan-Meier curve plotted. They are simple to interpret (though there can be confusion when there are competing risks).\nIn observational studies, we expect that there will be confounding and we would usually adjust for these confounders in a Cox model. If you have read my other tutorials then you will know that I prefer fitting parametric models, but the choice is that not that important if all you want is an adjusted hazard ratio and that you are (i) happy with the proportional hazards assumption, (ii) believe you have included all relevant counfounders and (iii) made sensible modelling assumptions (non-linear effect, interactions etc).\nGiven we are happy with the model, an adjusted hazard ratio is reported. This is fine, but hazard ratios are more difficult to interpret and there are further problems when using hazard ratios as causal effects (Hernan 2010, Aaalen et al. 2015). Risks are much easier to interpret than rates and so quantifying the difference on the survival scale can be desirable.\nSome statistical software implements something called “adjusted” survival curves, but it is not always clear what this means. For example, in Stata stcurve gives survival curves where certain covariates can be given specific values, but those not specified are given as mean values. Thus it gives a prediction for an individual who happens to have the mean values of each covariate. This is a prediction for an individual and may not reflect the average in the population. A more appropriate way is to average over the survival curves. For example, if we have 1000 individuals in our study we can predict a survival curve for each individual and then take the average of these 1000 curves. This is essentially what standsurv does."
  },
  {
    "objectID": "software/standsurv/standardized_survival.html#background",
    "href": "software/standsurv/standardized_survival.html#background",
    "title": "Standardized survival functions using standsurv",
    "section": "",
    "text": "When we are performing data exploration on survival data we usually start with plotting Kaplan-Meier curves. In clinical trials with a survival outcome, one would nearly always expect to see a Kaplan-Meier curve plotted. They are simple to interpret (though there can be confusion when there are competing risks).\nIn observational studies, we expect that there will be confounding and we would usually adjust for these confounders in a Cox model. If you have read my other tutorials then you will know that I prefer fitting parametric models, but the choice is that not that important if all you want is an adjusted hazard ratio and that you are (i) happy with the proportional hazards assumption, (ii) believe you have included all relevant counfounders and (iii) made sensible modelling assumptions (non-linear effect, interactions etc).\nGiven we are happy with the model, an adjusted hazard ratio is reported. This is fine, but hazard ratios are more difficult to interpret and there are further problems when using hazard ratios as causal effects (Hernan 2010, Aaalen et al. 2015). Risks are much easier to interpret than rates and so quantifying the difference on the survival scale can be desirable.\nSome statistical software implements something called “adjusted” survival curves, but it is not always clear what this means. For example, in Stata stcurve gives survival curves where certain covariates can be given specific values, but those not specified are given as mean values. Thus it gives a prediction for an individual who happens to have the mean values of each covariate. This is a prediction for an individual and may not reflect the average in the population. A more appropriate way is to average over the survival curves. For example, if we have 1000 individuals in our study we can predict a survival curve for each individual and then take the average of these 1000 curves. This is essentially what standsurv does."
  },
  {
    "objectID": "software/standsurv/standardized_survival.html#example",
    "href": "software/standsurv/standardized_survival.html#example",
    "title": "Standardized survival functions using standsurv",
    "section": "Example",
    "text": "Example\nI use the Rotterdam breast cancer data and use all cause survival as the outcome. I restrict follow-up to 10 years after diagnosis using the option exit(time 10).\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120) \n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nThe scale(12) option converts the times recorded in months to years.\nI will explore differences between women who received hormonal treatment and those who did not. This is our exposure, but as this is observational study we know that any association we see may be due to confounding. But.. it is always good to start with a Kaplan-Meier plot\n. sts graph, by(hormon) risktable ///\n&gt;         legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ring(0) cols(1) pos(1)) ///\n&gt;         ylabel(0(0.2)1,angle(h) format(%3.1f)) ///\n&gt;     ytitle(\"S(t)\") xtitle(\"Time since surgery\") \n\n         Failure _d: osi==1\n   Analysis time _t: os/12\n  Exit on or before: time 120\n\nThis plot shows that those receiving hormal treatment had worse survival. If we fit a proportional hazards model with hormon as the only covariate we get the following,\n. stpm3 i.hormon, df(4) scale(lncumhazard) eform nolog    \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  25.19\nLog likelihood = -2930.4853                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   1.540779   .1326967     5.02   0.000     1.301464    1.824099\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -25.45166   1.863924   -13.65   0.000    -29.10488   -21.79844\n        _ns2 |   8.063828   .9957355     8.10   0.000     6.112222    10.01543\n        _ns3 |   -.997684   .0432372   -23.07   0.000    -1.082427   -.9129407\n        _ns4 |  -.6392856   .0466345   -13.71   0.000    -.7306874   -.5478837\n       _cons |  -.5692268    .033194   -17.15   0.000    -.6342858   -.5041679\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nThe hazard ratio indicates that there is a 54% higher mortality rate in those receiving hormonal therapy.\nAs this is an observational study we should not stop there and conclude that hormonal therapy is bad for you. We do not know if there are differences between women taking or not taking the hormonal therapy. If those who took teh treatment tended to be older and have more severe disease then we do not have a fair comparison.\nIn fact a simple tabulation shows this to be the case,\n. tabstat age nodes, by(hormon)\n\nSummary statistics: Mean\nGroup variable: hormon (Hormonal therapy)\n\n  hormon |       age     nodes\n---------+--------------------\n      no |  54.09762  2.326523\n     yes |  62.54867  5.719764\n---------+--------------------\n   Total |  55.05835  2.712274\n------------------------------\nThose who received the hormonal therapy tended to be older and have more lymph node involvment. Thus, even if hormonal treatment did not have any effect on survival, we would expect to see a difference in such a simplistic analysis due to the type of people who receieved the treatment.\nSo, we now adjust for some covariates. To simplify things, I will assume proportional hazards and include the covariates age, nodes and progesterone receptor. Previous analyses of this data have found that transformation of the nodes variable (exp(-0.12*nodes)) and the progesterone variable (log(pr + 1)) model the non-linear effects of these variables fairly well and so I will use these transformed variables. The model is fitted below.\n. stpm3 i.hormon age enodes pr_1, scale(lncumhazard) df(4) eform nolog\n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  = 619.62\nLog likelihood = -2668.4925                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .7906432   .0715077    -2.60   0.009       .66221    .9439854\n         age |   1.013244   .0024119     5.53   0.000     1.008528    1.017983\n      enodes |   .1132534   .0110135   -22.40   0.000     .0935998    .1370337\n        pr_1 |   .9064855   .0119282    -7.46   0.000     .8834055    .9301685\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -25.90082   1.871965   -13.84   0.000     -29.5698   -22.23184\n        _ns2 |   7.980587   1.003724     7.95   0.000     6.013324    9.947851\n        _ns3 |  -1.091126   .0461407   -23.65   0.000     -1.18156   -1.000691\n        _ns4 |    -.70103   .0504635   -13.89   0.000    -.7999366   -.6021234\n       _cons |    .801967    .161537     4.96   0.000     .4853603    1.118574\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nThings have now changed, the adjusted hazard ratio for hormon is 0.79 (95% CI 0.66 to 0.94) indicating a benficial effect. There is strong confounding here as we have gone from a significant harmful effect to a significant beneficial effect when adjusting for age, number of positive lymph nodes and progesterone receptor.\nWe could stop here, but would the fun be in that. Instead we will try to understand what this hazard ratio means in terms of survival. First I will replicate what stcurve does and then obtain the standardized survival functions.\nThe code below obtains the mean of the covariates age, enodes and pr_1 and puts these into a macro which can then be passed to the at options of stpm3’s predict command when predicting survival.\n. foreach var in age enodes pr_1 {\n  2.         summ `var', meanonly\n  3.         local atopt `atopt' `var' `r(mean)'\n  4. }\n\n. predict s0_covave s1_covave, surv ci timevar(0 10, step(0.1)) ///\n&gt;                              frame(f1, replace)               ///\n&gt;                              at1(hormon 0 `atopt')            ///\n&gt;                              at2(hormon 1 `atopt')\nPredictions are stored in frame - f1\nI will then plot these curves\n. frame f1 {\n.   twoway (line s0_covave tt, sort)                                        ///\n&gt;          (line s1_covave tt, sort)                                        ///\n&gt;          , legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ///\n&gt;                     ring(0) cols(1) pos(1))                               ///\n&gt;          ylabel(0(0.2)1,angle(h) format(%3.1f))                           ///\n&gt;          ytitle(\"S(t)\")                                                   ///\n&gt;          xtitle(\"Years since surgery\")\n. }\n\nThese are the survival functions for two “average” women (i.e. who had the average values of each covariate) with one receiving hormonal treatment and the other not receiving it. We can see that for such women the difference is in the way we expect, given the hazard ratio, with those on hormonal treatment having better survival. If I had categorial covariates then interpretation is awkward. For example, if we modelled sex (not appropriate for this data) then the prediction would be for someone who was part male and part female as we would be taking the average of a binary variable."
  },
  {
    "objectID": "software/standsurv/standardized_survival.html#standardized-survival-curves",
    "href": "software/standsurv/standardized_survival.html#standardized-survival-curves",
    "title": "Standardized survival functions using standsurv",
    "section": "Standardized survival curves",
    "text": "Standardized survival curves\nWe want to calculate the expected survival under two counterfactuals. One where everyone has hormonal treatment and one where everybody does not take it. See (Sjölander 2016) for a nice description of these issues and implementation in an R package, stdreg. We also want contrasts of these standardized curves, for example a difference in standardized survival curves.\n\\[\nE\\left(S(t | X=1,Z\\right) - E\\left(S(t | X=0,Z\\right)\n\\]\nIn the above, \\(X\\) is the exposure of interest and \\(Z\\) are the confounders. We are interested in the expectation over the distribution of \\(Z\\), with the key point being this distribution is forced to be the same for \\(X=0\\) and \\(X=1\\). If our model is sufficent for confounding control then the above formula gives an average causal effect.\nTo estimate the difference in the standardized curves we need to generate the two standardized survival curves. In each of these we predict as many survival curves as there are observations in the data set and then take the average of these curves. The only difference is that in one we make everyone be exposed (hormon=1) and in the other we make everybody be unexposed (hormon=0).\n\\[\\frac{1}{N}\\sum_{i=1}^{N}S(t|\\mbox{hormon=1},\\mbox{age}_i,\\mbox{enodes}_i,\\mbox{pr\\_1}_i) - \\frac{1}{N}\\sum_{i=1}^{N}S(t|\\mbox{hormon=0},\\mbox{age}_i,\\mbox{enodes}_i,\\mbox{pr\\_1}_i)\\]\nThere are 2982 observation in the dataset (and in the model). Thus for each of the two standardized curves we need to predict 2982 survival curves and then take the average of these curves. We can make some computational efficiency savings by only estimating the survival curves a small number of time points. This could be a single time point, e.g. the survival at 5 years, or over a range. We often want to plot survival curves and about 50-100 time points is usually sufficient for plotting purposes.\nTo do all this (and more) we use the standsurv command. I will run the command and the explain the syntax.\n. range tt 0 10 101\n(2,881 missing values generated)\n\n. standsurv S0 S1, surv timevar(tt) ci                     ///\n&gt;                  frame(f2, replace)                      ///\n&gt;                  at1(hormon 0) at2(hormon 1)             ///\n&gt;                  contrast(difference) contrastvar(Sdiff)\nEach of the at() options creates a standardized survival curve. Here a covariate (or covariates) can be set to take specific values. Any covariates not specified keep their observed values. Thus we are just implementing the equation above. The timevar() option gives the name of the variable that gives the survival times in which to evaluate the survival function. I have defined a variable tt above to be 101 rows ranging from 0 to 10, i.e. in steps of 0.1 years. The ci option requests that confidence intervals be calculated. Standard errors are either obtained using the delta-method or M-estimation. The default is the delta-method (for standardized survival). The frame() options saves the predictions to a new frame. The standardized estmates will be named S0 and S1. The contrast() option asks for a comparison of the two survival curves with the difference argument asking to take differences in the standardized survival curves. By default at1() is the reference, i.e. the contrast will be at2()-at1(), but this can be changed using the atref() option. The contrast will be stored in the new variable Sdiff.\nYou do not have to specify the names of the new variables and if you do not, standsurv will create new variables, _at1, _at2, _contrast2_1. However, in general it is more useful to create sensible names for these varables. As the ci option was specified there will be lower and upper for the confidence intervals (95% by deafult) for each estimate.\nBelow I list the standardized curves at 10 years, followed by their difference.\n. frame f2 {\n.   list S0* S1* if tt==10, noobs\n\n  +---------------------------------------------------------------------+\n  |        S0      S0_lci      S0_uci          S1      S1_lci    S1_uci |\n  |---------------------------------------------------------------------|\n  | .54380594   .52512603   .56315034   .60749077   .56414068   .654172 |\n  +---------------------------------------------------------------------+\n.   list Sdiff*  if tt==10, noobs \n\n  +-----------------------------------+\n  |     Sdiff   Sdiff_lci   Sdiff_uci |\n  |-----------------------------------|\n  | .06368483   .01748572   .10988394 |\n  +-----------------------------------+\n. }  \nThus the average survival at 10 years when everyone is forced to be unexposed (not on hormonal treatment) is 0.54 and when everyone is exposed it is 0.61. The difference is 0.064. We have actually evaluated each function at 101 time points and so we can plot the estimates together with 95% confidence intervals.\n. frame f2 {\n.   twoway (rarea S0_lci S0_uci tt, color(red%25))                          ///\n&gt;          (rarea S1_lci S1_uci tt, color(blue%25))                         ///\n&gt;          (line S0 tt, sort lcolor(red))                                   ///\n&gt;          (line S1  tt, sort lcolor(blue))                                 ///\n&gt;          , legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ///\n&gt;                   ring(0) cols(1) pos(1))                                 ///\n&gt;          ylabel(0.5(0.1)1,angle(h) format(%3.1f))                         ///\n&gt;          ytitle(\"S(t)\") ///\n&gt;          xtitle(\"Years from surgery\")\n. }\n\nAnd now we can plot the difference in standardized curves together with a 95% confidence interval.\n. frame f2 {\n. twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%25)) ///\n&gt;        (line Sdiff tt, sort lcolor(red))             ///\n&gt;        , legend(off)                                 ///\n&gt;        ylabel(,angle(h) format(%3.2f))               ///\n&gt;        ytitle(\"Difference in S(t)\")                  ///\n&gt;        xtitle(\"Years from surgery\")\n. }\n\nThe covariate distribution we are averaging over is a combination of those on and not on hormon treatment. It may also be of interest to restrict to the covariate distribution of the exposed or the unexposed. Assuming our model has controlled for confounding this will give the average causal effect (difference) in the exposed. All we need to do is to add an if statement.\n. standsurv S0 S1 if hormon==1,  surv timevar(tt) ci                     ///\n&gt;                                frame(f3, replace)                      ///\n&gt;                                at1(hormon 0) at2(hormon 1)             ///\n&gt;                                contrast(difference) contrastvar(Sdiff)\nThe resulting standardized curves can then be plotted.\n. frame f3 {\n.   twoway (rarea S0_lci S0_uci tt, color(red%25))                          ///\n&gt;          (rarea S1_lci S1_uci tt, color(blue%25))                         ///\n&gt;          (line S0 tt, sort lcolor(red))                                   ///\n&gt;          (line S1  tt, sort lcolor(blue))                                 ///\n&gt;          , legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ///\n&gt;                   ring(0) cols(1) pos(1))                                 ///\n&gt;          ylabel(0.5(0.1)1,angle(h) format(%3.1f))                         ///\n&gt;          ytitle(\"S(t)\")                                                   ///\n&gt;          xtitle(\"Years from surgery\")\n.   }       \n\nNote that these curves give higher survival. This is because on average those who received hormonal treatment were younger and had less severe disease.\nWe can also plot the difference in these standardized curves together with a 95% confidence interval.\n. frame f3 {\n.   twoway (rarea Sdiff_lci Sdiff_uci tt, color(red%25)) ///\n&gt;          (line Sdiff tt, sort lcolor(red))           ///\n&gt;          , legend(off)                                 ///\n&gt;          ylabel(,angle(h) format(%3.2f))               ///\n&gt;          ytitle(\"Difference in S(t)\")                  ///\n&gt;          xtitle(\"Years from surgery\")\n. }"
  },
  {
    "objectID": "software/standsurv/standardized_survival.html#references",
    "href": "software/standsurv/standardized_survival.html#references",
    "title": "Standardized survival functions using standsurv",
    "section": "References",
    "text": "References\nAalen O.O., Cook R.J. Røysland K. Does Cox analysis of a randomized survival study yield a causal treatment effect? Lifetime data analysis 2015;21:579-593.\nHernán M.A. The hazards of hazard ratios. Epidemiology 2010;21:13-15\nSjölander A. Regression standardization with the R package stdReg. European Journal of Epidemiology 2016;31:563–574"
  },
  {
    "objectID": "software/standsurv/standardized_crude_probabilities_of_death.html",
    "href": "software/standsurv/standardized_crude_probabilities_of_death.html",
    "title": "Standardized Crude Probabilities of Death",
    "section": "",
    "text": "Download Stata Do file here\n\n\nYou will need to install standsurv to run the example. Details here"
  },
  {
    "objectID": "software/standsurv/standardized_crude_probabilities_of_death.html#background",
    "href": "software/standsurv/standardized_crude_probabilities_of_death.html#background",
    "title": "Standardized Crude Probabilities of Death",
    "section": "Background",
    "text": "Background\nThe standardized relative survival tutorial introduced the concept of relative survival and illustrated how flexible parametric survival models can be fitted in this framework. Under certain conditions, relative survival can be interpreted as net survival, the survival in a hypothetical world where it is not possible to die from other causes. This measure is often used to make fair comparisons of cancer survival between different countries or populations as only the excess mortality related to the cancer diagnosis is analysed and differences in other cause mortality are ignored.\nHowever, measures of survival in the “real world” can be more useful for clinical decision making as they consider the competing risk of dying from causes other than cancer. This tutorial demonstrates how standsurv can be used to estimate the probabilities of dying from cancer and other causes after flexible parametric survival models are fitted in the relative survival setting. In the relative survival framework, these are known as crude probabilities of death, whereas in a cause-specific setting, they are referred to as cause-specific cumulative incidence functions (CIF). Further details on how to calculate these measures in the cause-specific setting can be found here."
  },
  {
    "objectID": "software/standsurv/standardized_crude_probabilities_of_death.html#methods",
    "href": "software/standsurv/standardized_crude_probabilities_of_death.html#methods",
    "title": "Standardized Crude Probabilities of Death",
    "section": "Methods",
    "text": "Methods\n\\(F_{cancer}(t|x_i)\\) denotes the probability of death due to cancer and can be calculated using the following equation where the relative survival function \\(R(u|x_{1i})\\) and the excess hazard due to cancer \\(\\lambda(u|x_{1i})\\) can both be obtained from the relative survival model. \\(S^*(u|x_{2i})\\) is the expected survival of a similar group of people in the general population without cancer and can be obtained from the population life tables (also known as a “popmort” file). The life tables used in this particular example correspond to the expected survival in England and are stratified by calendar year, age, sex and deprivation group.\n\\(x_{1}\\) is a subset of \\(x\\) and includes the covariates relating to the excess mortality such as age at diagnosis, sex, deprivation group and stage at diagnosis. \\(x_{2}\\) is a different subset of \\(x\\) and contains the factors that the life tables are stratified by, which in this particular example, are age, calendar year, sex and deprivation group.\n\\[\nF_{cancer}(t|x_i) = \\int_0^t S(u|x_i) \\lambda(u|x_{1i}) du = \\int_0^t S^*(u|x_{2i}) R(u|x_{1i}) \\lambda(u|x_{1i}) du\n\\]\n\\(F_{other}(t|x_i)\\) is the probability of dying from causes other than cancer, where \\(h^*(t|x_{2i})\\) is the expected hazard function and can be obtained from the population life tables.\n\\[\nF_{other}(t|x_i) = \\int_0^t S(u|x_i) h^*(u|x_{2i}) du = \\int_0^t S^*(u|x_{2i}) R(u|x_{1i}) h^*(u|x_{2i}) du\n\\]\nThe crude probabilities of death due to each cause sum to the all cause probability of death.\n\\[\nF_{all cause}(t|x_i) = F_{cancer}(t|x_i) + F_{other}(t|x_i)\n\\]"
  },
  {
    "objectID": "software/standsurv/standardized_crude_probabilities_of_death.html#example-simulated-colon-cancer-data",
    "href": "software/standsurv/standardized_crude_probabilities_of_death.html#example-simulated-colon-cancer-data",
    "title": "Standardized Crude Probabilities of Death",
    "section": "Example (simulated colon cancer data)",
    "text": "Example (simulated colon cancer data)\n\nPrepare data\nThis tutorial uses simulated data from a paper by Syriopoulou et al. It is based on colon cancer survival in England and is restricted to only include the most and least deprived quintile of the population.\nThis dataset contains the following variables: ID number (id), age at diagnosis (agediag, 16-104), stage of tumour at diagnosis (stage, stages 1-4), year of diagnosis (yeardiag, 2011-2013), month of diagnosis (diagmonth), date of diagnosis (datediag), sex (sex, 0 = Male, 1 = Female), survival time in years (t, 0.0027 - 10), survival status (dead, 0 = Alive, 1 = Dead) and deprivation quintile (dep, 1 = Least deprived, 5 = Most Deprived).\nAs computation is slow I have taken a 20% sample of the original data, which leads to 3,061. individuals.\nTo prepare the data, I first format the date of diagnosis variable and restrict the analysis to individuals who were diagnosed with colon cancer between the ages of 18 and 99. I also need to recode the variable relating to sex as currently, 0 = Male and 1 = Female, whereas in the life tables (popmort file), 1 = Male and 2 = Female. Recoding this variable means that the life tables will be correctly merged in.\n. set seed 128763\n\n. use https://www.pclambert.net/data/colonsim_stage if runiform()&lt;0.2, clear\n\n. // Format datediag to display as a date\n. format datediag %td\n\n. // Restrict analysis to patients aged 18-99 at diagnosis\n. keep if agediag&gt;=18 & agediag&lt;=99\n(0 observations deleted)\n\n. // Recode the sex variable to match the popmort file\n. replace sex = sex+1\n(3,061 real changes made)\n\n. label define label_sex 1 \"Male\" 2 \"Female\" \n\n. label values sex label_sex \n\n. gen female = sex==2\nstset can then be used to calculate the survival time of each of the 15,627 individuals and to censor any individuals who were still alive 5 years after their diagnosis.\n. stset t, failure(dead=1) id(id) exit(time 5)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: dead==1\nObserved time interval: (t[_n-1], t]\n     Exit on or before: time 5\n\n--------------------------------------------------------------------------\n      3,061  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      3,061  observations remaining, representing\n      3,061  subjects\n      1,581  failures in single-failure-per-subject data\n  9,926.831  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nIn order to fit a relative survival model, the expected mortality rate of each individual at their event time is required. To identify the correct expected mortality rates, I first calculate the attained age (age of the individual at their event time) and attained year (calendar year when the event or censoring occurs). I name these variables age and year to match the variable names in the life tables. As the maximum age included in the life tables is 100, I force the maximum attained age to be set as 100. Similarly, as the life tables only go up to 2016, I also make the maximum attained year to be 2016. This makes the assumption that the expected rates in 2018 for each combination of age, sex and deprivation group are the same as they were in 2016. The expected mortality rates can then be merged in by matching for attained age, attained year, sex and deprivation quintile.\n. // Attained age\n. gen age = min(floor(agediag + _t),100)\n\n. // Attained calendar year\n. gen year = min(floor(yeardiag + _t),2016)\n\n. // Merge in life tables\n. merge m:1 age year dep sex using https://www.pclambert.net/data/popmort_uk_2017, ///\n&gt; keep(match master) keepusing(rate)\n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                             3,061  (_merge==3)\n    -----------------------------------------\n\n. drop age year\nI drop the attained age (age) and attained year (year) variables now that the expected rates have been merged in.\nPreviously, when using stpm2 various variables needed to be created. This included restricted cubic spline variables for the effect of age, dummy variables for stage and various interactions. For the spline variables, the knot positions and projection matrix for orthogonalization needed to be save. Using stpm3 makes things much easier, as all these can be included in the commands itself.\n\n\nFitting the model\nNow I fit the flexible parametric survival model used by Syriopoulou et al (2021) that includes age at diagnosis (using natural splines), sex, deprivation group and stage at diagnosis as covariates, along with interaction terms between stage and deprivation group. It also includes time-dependent effects for the main effects of deprivation group, stage and age (using natural splines). It uses 5 degrees of freedom for the baseline and 3 degrees of freedom to model the time-dependent effects.\n. stpm3 i.female i.dep i.stage i.stage#dep @ns(agediag,df(3)), scale(lncumhazard) df(5) ///\n&gt;                tvc(i.dep i.stage @ns(agediag,df(3))) dftvc(3) bhazard(rate) vsquish\n\nIteration 0:  Log likelihood = -3104.5329  \nIteration 1:  Log likelihood =  -3019.487  \nIteration 2:  Log likelihood = -3008.7321  \nIteration 3:  Log likelihood = -3007.9984  \nIteration 4:  Log likelihood = -3007.8399  \nIteration 5:  Log likelihood = -3007.7991  \nIteration 6:  Log likelihood = -3007.7894  \nIteration 7:  Log likelihood = -3007.7867  \nIteration 8:  Log likelihood = -3007.7859  \nIteration 9:  Log likelihood = -3007.7857  \nIteration 10: Log likelihood = -3007.7856  \nIteration 11: Log likelihood = -3007.7856  \n\n                                                        Number of obs =  3,061\n                                                        Wald chi2(11) = 541.45\nLog likelihood = -3007.7856                             Prob &gt; chi2   = 0.0000\n\n----------------------------------------------------------------------------------------------\n                             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-----------------------------+----------------------------------------------------------------\nxb                           |\n                    1.female |   .0258002   .0611239     0.42   0.673    -.0940004    .1456009\n                       5.dep |   11.33406   610.7999     0.02   0.985    -1185.812     1208.48\n                       stage |\n                          2  |   11.77162   610.8012     0.02   0.985    -1185.377     1208.92\n                          3  |   13.63744   610.8011     0.02   0.982    -1183.511    1210.786\n                          4  |   14.87865   610.8011     0.02   0.981     -1182.27    1212.027\n                   stage#dep |\n                        2 5  |  -11.34975   610.7999    -0.02   0.985    -1208.496    1185.796\n                        3 5  |  -11.19332   610.7999    -0.02   0.985    -1208.339    1185.952\n                        4 5  |  -11.26091   610.7999    -0.02   0.985    -1208.407    1185.885\n             _ns_f1_agediag1 |   .8547894   1.699503     0.50   0.615    -2.476176    4.185755\n             _ns_f1_agediag2 |  -1.255521   .6266172    -2.00   0.045    -2.483668   -.0273739\n             _ns_f1_agediag3 |   .1428389   .6831001     0.21   0.834    -1.196013    1.481691\n-----------------------------+----------------------------------------------------------------\ntime                         |\n                        _ns1 |  -46.59876   30.73218    -1.52   0.129    -106.8327    13.63522\n                        _ns2 |   18.43374   12.93551     1.43   0.154    -6.919398    43.78689\n                        _ns3 |  -.1336661   1.018261    -0.13   0.896    -2.129421    1.862089\n                        _ns4 |   .2966349   .6233048     0.48   0.634    -.9250201     1.51829\n                        _ns5 |   .3442934   .4569246     0.75   0.451    -.5512623    1.239849\n              dep#c._ns_tvc1 |\n                          5  |   -1.05234   1.780841    -0.59   0.555    -4.542724    2.438045\n              dep#c._ns_tvc2 |\n                          5  |    1.22833    1.00034     1.23   0.219       -.7323    3.188959\n              dep#c._ns_tvc3 |\n                          5  |   .3265529   .1202818     2.71   0.007      .090805    .5623008\n            stage#c._ns_tvc1 |\n                          2  |   15.54094   31.12577     0.50   0.618    -45.46444    76.54632\n                          3  |   20.29633   30.75615     0.66   0.509    -39.98462    80.57727\n                          4  |   22.62941   30.67119     0.74   0.461    -37.48501    82.74383\n            stage#c._ns_tvc2 |\n                          2  |  -4.520576   15.57263    -0.29   0.772    -35.04238    26.00122\n                          3  |  -9.567492    15.3728    -0.62   0.534    -39.69763    20.56265\n                          4  |  -9.400435   15.31143    -0.61   0.539    -39.41028    20.60941\n            stage#c._ns_tvc3 |\n                          2  |  -.3308294   .7373107    -0.45   0.654    -1.775932    1.114273\n                          3  |  -1.137763   .7047464    -1.61   0.106    -2.519041    .2435142\n                          4  |   -.448099   .6956624    -0.64   0.519    -1.811572    .9153742\nc._ns_f1_agediag1#c._ns_tvc1 |   20.12228   34.46616     0.58   0.559    -47.43015     87.6747\nc._ns_f1_agediag1#c._ns_tvc2 |   -30.2422   19.20078    -1.58   0.115    -67.87503    7.390637\nc._ns_f1_agediag1#c._ns_tvc3 |  -4.893479   2.803528    -1.75   0.081    -10.38829    .6013342\nc._ns_f1_agediag2#c._ns_tvc1 |  -6.719063    18.2678    -0.37   0.713    -42.52329    29.08517\nc._ns_f1_agediag2#c._ns_tvc2 |   7.470501   10.16327     0.74   0.462    -12.44915    27.39015\nc._ns_f1_agediag2#c._ns_tvc3 |  -.0054526   1.219612    -0.00   0.996    -2.395848    2.384942\nc._ns_f1_agediag3#c._ns_tvc1 |   9.465698   9.075787     1.04   0.297    -8.322518    27.25391\nc._ns_f1_agediag3#c._ns_tvc2 |  -10.82306   5.100466    -2.12   0.034    -20.81979   -.8263326\nc._ns_f1_agediag3#c._ns_tvc3 |  -1.067077   .9595113    -1.11   0.266    -2.947684    .8135306\n                       _cons |  -14.02936   610.8006    -0.02   0.982    -1211.176    1183.118\n----------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(agediag, df(3))\n\n\nMarginal crude probabilities\nNow that the relative survival model is fitted, the crude probabilities of death can be estimated. The marginal crude probabilities of death are an average measure that can be used to summarise the mortality of the \\(N\\) individuals used to develop the model. Each individual’s predicted probability of death from each cause is calculated at a particular time point and then averaged.\n\\[ \\widehat{F}_{M,cancer}(t) = \\frac{1}{N} \\sum{i=1}^{N} {\\widehat{F}_{cancer}(t|x_i)} \\]\n\\[ \\widehat{F}_{M,other}(t)  = \\frac{1}{N} \\sum{i=1}^{N} {\\widehat{F}_{other}(t|x_i)} \\]\nIn standsurv this can be achieved by specifying the crudeprob option. Including at1(.) means that the predictions for each individual will be made based on their observed covariate values in the dataset. Using the timevar() option means that the marginal crude probabilities will be calculated at a particular time point or a series of time points. Here t5 allows these probabilities to be estimated at 51 time points so that a smooth curve across the 5 year follow-up period can be produced.\nAs this calculation requires the expected mortality rates, the population life tables need to be specified using expsurv() which links the age of the individuals in the dataset to their attained age and calendar year at each time point. As the population life tables are stratified by sex and deprivation these are specified using pmother(). As the maximum age in the life tables is 100 and the maximum year is 2016, I specify these options using pmmaxage() and pmmaxyear() respectively so that any values greater than these will be set to the maximum value. The atvar() option is used to name the variables where the predictions will be stored. By calling this “marg”, by default it will create a variable called marg_disease and another named marg_other to save the crude probabilities of death due to cancer and other causes respectively.\n. range t5 0 5 51\n(3,010 missing values generated)\n\n. standsurv, crudeprob               ///  Crude probabilities of death\n&gt;            timevar(t5)             ///  Time points used for predictions\n&gt;            frame(f1, replace)      ///  Frame to save results\n&gt;            at1(.)                  ///  Use observed covariate values            \n&gt;            atvar(marg)             ///  New variable containing the predictions\n&gt;            expsurv(using(https://www.pclambert.net/data/popmort_uk_2017) ///  Popmort file\n&gt;              agediag(agediag)      ///  Age at diagnosis in the dataset\n&gt;              datediag(datediag)    ///  Date of diagnosis in the dataset\n&gt;              pmage(age)            ///  Age variable in the popmort file\n&gt;              pmyear(year)          ///  Year variable in the popmort file                     \n&gt;              pmother(dep sex)      ///  Other variables included in the popmort file\n&gt;              pmrate(rate)          ///  Rate variable in the popmort file\n&gt;              pmmaxage(100)         ///  Maximum age in the popmort file\n&gt;              pmmaxyear(2016)       ///  Maximum year in the popmort file\n&gt;              ) \nWe now plot the results.\n. frame f1 {\n.   twoway (line marg_disease t5),               ///\n&gt;          xtitle(\"Years since Diagnosis\")       ///\n&gt;          ytitle(\"Probability of Death\")        ///\n&gt;          ylabel(,format(%3.1f))                ///\n&gt;          title(\"Cancer\")                       /// \n&gt;          name(marg_disease,replace)\n.   twoway (line marg_other t5, pstyle(p2line)), /// \n&gt;          xtitle(\"Years since Diagnosis\")       ///\n&gt;          ytitle(\"Probability of Death\")        ///\n&gt;          ylabel(0(0.1)0.4,format(%3.1f))       ///\n&gt;          title(\"Other Causes\")                 ///\n&gt;          name(marg_other,replace) \n. \n. graph combine marg_disease marg_other\n. }\n\nHere we can see that within this group of people, the probability of dying from cancer is over 3 times larger than dying from other causes by 5 years after diagnosis. An alternative way to present these predictions is to produce a stacked graph by adding the crude probabilities of death from each cause together. The blue line then indicates the all-cause probability of death and each coloured region indicates the probability of being alive, dying from cancer and dying from other causes.\n. frame f1 {\n.   gen alive = 1\n.   gen marg_all = marg_disease + marg_other\n.   twoway (area alive t5, fintensity(30))           ///\n&gt;          (area marg_all t5, fintensity(30))        ///\n&gt;          (area marg_other t5,  fintensity(30)),    ///\n&gt;          ytitle(\"Probability\")                     ///\n&gt;          xtitle(\"Time from diagnosis\")             ///\n&gt;          ylabel(,format(%3.1f))                    /// \n&gt;          legend(order(1 \"Alive\"                    ///\n&gt;                       2 \"Death from Cancer\"        ///\n&gt;                       3 \"Death from Other Causes\") ///\n&gt;                          rows(1) ring(1) pos(6)) \n. }\n\n\n\nStandardization using contrasts\nThe contrast() option can be used to investigate differences between subgroups in the population. As shown in the standardized relative survival tutorial, we might be interested in the effect of deprivation.\nWe cannot fairly compare these groups using their observed covariate values since this would mean we would be averaging over different covariate patterns within each deprivation group. For example, in the most deprived group there is a greater proportion of individuals diagnosed with Stage 4 tumours so we wouldn’t know whether the differences in the marginal crude probabilities of death were due to the effect of deprivation or other factors such as stage.\nTo account for this we can first make predictions for all individuals by supposing that they are all in the most deprived group (i.e. setting dep5=1 for everyone regardless of their true deprivation group but keeping the observed values of all other covariates in the dataset). We can then make a second set of predictions where all individuals are assumed to be in the least deprived group (dep5=0). This is called standardization and further examples can be found in the standardized relative survival tutorial.\nThis approach allows us to investigate the differences in the marginal crude probabilities of death for this hypothetical population. Mathematically, it can be written as the following where \\(Z\\) is the binary covariate dep5 (\\(Z=1\\) is the most deprived group and \\(Z=0\\) is the least deprived group).\n\\[ \\frac{1}{N}\\sum_{i=1}^N{\\widehat{F}_{cancer}(t|Z=1,x_i)} - \\frac{1}{N}\\sum_{i=1}^N{\\widehat{F}_{cancer}(t|Z=0,x_i)} \\]\n\\[ \\frac{1}{N}\\sum_{i=1}^N{\\widehat{F}_{other}(t|Z=1,x_i)} - \\frac{1}{N}\\sum_{i=1}^N{\\widehat{F}_{other}(t|Z=0,x_i)} \\]\nI specify this in standsurv using the at1() and at2() options to estimate the marginal predictions for the least and most deprived group respectively.\nI also use the at1() and at2() within the expsurv() function to ensure that the correct expected mortality rates are used in each calculation. I then use the contrast() option to calculate the absolute difference in the marginal crude probabilities between the deprivation groups.\n. standsurv, crudeprob               ///  Crude probabilities of death\n&gt;            timevar(t5)             ///  Time points used for predictions\n&gt;            frame(f2, replace)      ///  frame to save results to\n&gt;            at1(dep 1)              ///  Least deprived\n&gt;            at2(dep 5)              ///  Most deprived\n&gt;            atvar(dep_1 dep_5)      ///  New variables containing the predictions\n&gt;            contrast(difference)    ///  Calculate the difference between groups\n&gt;            contrastvar(diff_dep)   ///  New variables containing the difference \n&gt;            ci                      ///  Calculate confidence intervals\n&gt;            expsurv(using(https://www.pclambert.net/data/popmort_uk_2017) ///  Popmort file\n&gt;              agediag(agediag)      ///  Age at diagnosis in the dataset\n&gt;              datediag(datediag)    ///  Date of diagnosis in the dataset\n&gt;              pmage(age)            ///  Age variable in the popmort file\n&gt;              pmyear(year)          ///  Year variable in the popmort file                    \n&gt;              pmother(dep sex)      ///  Other variables included in the popmort file\n&gt;              pmrate(rate)          ///  Rate variable in the popmort file\n&gt;              pmmaxage(100)         ///  Maximum age in the popmort file\n&gt;              pmmaxyear(2016)       ///  Maximum year in the popmort file\n&gt;              at1(dep 1)            ///  Use expected rates for least deprived\n&gt;              at2(dep 5)            ///  Use expected rates for most deprived\n&gt;              )  \n\nWe can also plot the differences in the marginal probabilities.\n. frame f2 {\n.   twoway (rarea diff_dep_disease_lci diff_dep_disease_uci t5, col(%30)) ///\n&gt;          (line diff_dep_disease t5, pstyle(p1line)),                    ///\n&gt;          legend(off)                                                    ///\n&gt;          xtitle(\"Years since Diagnosis\")                                ///\n&gt;          ytitle(\"Difference in Probability of Death\")                   ///\n&gt;          ylabel(0(0.01)0.1, format(%3.2f))                              ///\n&gt;          title(\"Cancer\")                                                ///\n&gt;          name(diff_cancer,replace)\n.          \n.   twoway (rarea diff_dep_other_lci diff_dep_other_uci t5, col(%30))     ///\n&gt;          (line diff_dep_other t5, pstyle(p1line)),                      ///\n&gt;          legend(off)                                                    ///\n&gt;          xtitle(\"Years since Diagnosis\")                                ///\n&gt;          ytitle(\"Difference in Probability of Death\")                   ///\n&gt;          ylabel(0(0.01)0.1, format(%3.2f))                              ///\n&gt;          title(\"Other Causes\")                                          ///\n&gt;          name(diff_other,replace)\n. \n.   graph combine diff_cancer diff_other, ycommon\n. }\n\nHere we can see that the probability of death due to cancer and the probability of death due to other causes are both greater for the most deprived group.\n\n\n\nSpecific covariate patterns\nAlthough using marginal measures can be useful to summarise the mortality of a group of individuals, we may instead be interested in more personalised predictions for an individual with a particular covariate pattern.\nIf we are interested in making predictions for a particular individual in the dataset we could do this by using the predict command and specify the values of the covariates we want to predict for.\n. predict CPc, crudeprob                ///  Crude probabilities of death\n&gt;         timevar(0 5,step(0.1))        ///  Time points used for predictions\n&gt;         frame(CP, replace)            /// frame to save predictions\n&gt;         at1(agediag 85 stage 2 female 0 dep 1) /// covariate values \n&gt;         expsurv(using(https://www.pclambert.net/data/popmort_uk_2017) ///  Popmort file\n&gt;                 agediag(85)           ///  Age at diagnosis in the dataset\n&gt;                 datediag(2011-1-1)    ///  Date of diagnosis in the dataset\n&gt;                 pmage(age)            ///  Age variable in the popmort file\n&gt;                 pmyear(year)          ///  Year variable in the popmort file                       \n&gt;                 pmother(dep sex)      ///  Other variables included in the popmort file\n&gt;                 pmrate(rate)          ///  Rate variable in the popmort file\n&gt;                 pmmaxage(100)         ///  Maximum age in the popmort file\n&gt;                 pmmaxyear(2016)       ///  Maximum year in the popmort file\n&gt;                 expvar(CPo)           ///\n&gt;                 at1(dep 1 sex 2)      ///\n&gt;         )             \nPredictions are stored in frame - CP\n. \n. frame CP {     \n.   gen allcause = CPc + CPo\n.   gen alive = 1\n. \n.   twoway (area alive tt, col(%30))                                              ///\n&gt;          (area allcause tt,   col(%30))                                         ///\n&gt;          (area CPo tt, col(%30)),                                               ///\n&gt;          xtitle(\"Years since Diagnosis\")                                        ///\n&gt;          ytitle(\"Probability\")                                                  ///\n&gt;          title(\"Male, Stage 2, Deprivation Group 1, Diagnosed Aged 85 in 2011\", ///\n&gt;                 size(*0.8))                                                     ///\n&gt;          ylabel(,format(%3.1f))                                                 ///\n&gt;          legend(order(1 \"Alive\"                                                 ///\n&gt;                       2 \"Death from Cancer\"                                     ///\n&gt;                       3 \"Death from Other Causes\")                              ///\n&gt;                       rows(1) ring(1) pos(6)) \n.     \n. }\n\n\nEffect of age at diagnosis\nI now show how you can calculate the crude probabilities of death for individuals with a particular covariate pattern which may not exist in the dataset. Here I make predictions for the following covariate pattern: male, from the least deprived group, diagnosed on 1st January 2011 with a stage 2 tumour and aged either 60, 70, 80 or 90.\nThis is done in a loop. It could be done with 4 separate at options, but a loop may be preferable with many predictions. Note that I use the mergecreate as a suboption of the frame option. This creates the frame if it does not exist, and otherwise merges with the existing frame.\n. foreach age in 60 70 80 90 {             \n  2.   predict CPc`age',  crudeprob       ///  Crude probabilities of death\n&gt;           at1(agediag `age' female 0 dep 1 stage 2) ///  Specify covariate pattern\n&gt;           frame(CP_age, mergecreate) /// frame to save results\n&gt;           timevar(0 5, step(0.1))    ///  Time points used for predictions\n&gt;           expsurv(using(https://www.pclambert.net/data/popmort_uk_2017) /// Popmort file\n&gt;             agediag(`age')          ///  Age at diagnosis variable\n&gt;             datediag(2011-1-1)      ///  Temporary date of diagnosis variable\n&gt;             pmage(age)              ///  Age variable in the popmort file\n&gt;             pmyear(year)            ///  Year variable in the popmort file\n&gt;             pmother(dep sex)        ///  Other variables included in the popmort file\n&gt;             pmrate(rate)            ///  Rate variable in the popmort file\n&gt;             pmmaxage(100)           ///  Maximum age in the popmort file\n&gt;             pmmaxyear(2016)         ///  Maximum year in the popmort file\n&gt;             at1(dep 1 sex 1)        ///  Use expected rates for least deprived and male\n&gt;             expvar(CPo`age')        ///  crude probability (other causes)\n&gt;           ) \n  3. }\nPredictions are stored in frame - CP_age\nPredictions are stored in frame - CP_age\nPredictions are stored in frame - CP_age\nPredictions are stored in frame - CP_age\nA panel plot can be produced using a loop over the 4 selected ages.\n// All-cause probability of death\n. frame CP_age: gen alive = 1\n\n. frame CP_age {    \n.   foreach age in 60 70 80 90 {           \n  2.     gen allcause`age' = CPc`age' + CPo`age'\n  3.     twoway (area alive tt, col(%30))                    ///\n&gt;            (area allcause`age' tt, color(%30))          ///\n&gt;            (area CPo`age' tt, color(%30)),              ///\n&gt;            ylabel(,format(%3.1f))                       ///\n&gt;            legend(order(1 \"Alive\"                       ///\n&gt;                         2 \"Death from Cancer\"           ///\n&gt;                         3 \"Death from Other Causes\")    ///\n&gt;                         rows(1) ring(1) pos(6))         ///\n&gt;                         xtitle(\"Years since Diagnosis\") ///\n&gt;                         ytitle(\"Probability\")           ///\n&gt;                         title(\"Age `age'\")              ///\n&gt;            name(age`age',replace) \n  4.   }\n. }\n\n. grc1leg age60 age70 age80 age90, title(\"Male, Stage 2, Deprivation Group 1, Diagnosed in 2011\")\n\nHere we see that age at diagnosis has a large impact on the all-cause probability of death. These graphs also show how the all-cause probability of death breaks down into the probability of dying from each cause. For example, a 90 year old with this covariate pattern is much more likely to die from other causes than their cancer. Understanding the most likely cause of death is important as this can help with making treatment decisions.\n\n\nEffect of stage at diagnosis\nNow we look at the effect of stage at diagnosis on the risk predictions of a woman diagnosed aged 75 on 1st January 2011 from the most deprived group. We could also loop over stage here, but I will use 4 at options as an alternative to predictions for selected ages above.\n. predict CPc1 CPc2 CPc3 CPc4, crudeprob frame(CP_stage, replace)   ///\n&gt;              at1(agediag 75 female 1 dep 5 stage 1)  ///  Stage 1\n&gt;              at2(agediag 75 female 1 dep 5 stage 2)  ///  Stage 1\n&gt;              at3(agediag 75 female 1 dep 5 stage 3)  ///  Stage 1\n&gt;              at4(agediag 75 female 1 dep 5 stage 4)  ///  Stage 1\n&gt;              timevar(0 5, step(0.1))             ///  Time points\n&gt;              expsurv(using(https://www.pclambert.net/data/popmort_uk_2017) ///  Popmort file\n&gt;              agediag(75)                         ///  \n&gt;              datediag(2011-1-1)                 ///  \n&gt;              pmage(age)                          ///  Age variable in the popmort file\n&gt;              pmyear(year)                        ///  Year variable in the popmort file                    \n&gt;              pmother(dep sex)                    ///  Other variables in the popmort file\n&gt;              pmrate(rate)                        ///  Rate variable in the popmort file\n&gt;              pmmaxage(100)                       ///  Maximum age in the popmort file\n&gt;              pmmaxyear(2016)                     ///  Maximum year in the popmort file\n&gt;              at1(dep 5 sex 2)                    ///  Use expected rates \n&gt;              at2(dep 5 sex 2)                    ///  Use expected rates \n&gt;              at3(dep 5 sex 2)                    ///  Use expected rates \n&gt;              at4(dep 5 sex 2)                    ///  Use expected rates \n&gt;              expvar(CPo1 CPo2 CPo3 CPo4)         /// crud probs (other causes)\n&gt;              ) \nPredictions are stored in frame - CP_stage\n. frame CP_stage: gen alive = 1\n\n. frame CP_stage {\n.   forvalues stage = 1/4 {\n  2.     gen allcause`stage' = CPc`stage' + CPo`stage'\n  3.     twoway (area alive tt, color(%30))               ///\n&gt;            (area allcause`stage' tt, color(%30))   ///\n&gt;            (area CPo`stage' tt, color(%30)), ///\n&gt;             ylabel(,format(%3.1f))                   ///\n&gt;             legend(order(1 \"Alive\"                   ///\n&gt;                          2 \"Death from Cancer\"         ///\n&gt;                          3 \"Death from Other Causes\") ///\n&gt;                          rows(1) ring(1) pos(6))       ///\n&gt;                          xtitle(\"Years since Diagnosis\") ///\n&gt;                          ytitle(\"Probability\") ///\n&gt;                          title(\"Stage `stage'\") ///\n&gt;                          name(stage`stage',replace)     \n  4.   }\n. }\n\n. grc1leg stage1 stage2 stage3 stage4, title(\"Female, Age 75, Deprivation Group 5, Diagnosed in 2011\") \n\nHere we can see that if an individual with this covariate pattern is diagnosed with an early stage tumour, the all-cause probability of death is very low and mostly due to other causes. In contrast, for an individual diagnosed with advanced stage cancer, the all-cause probability of death by 5 years is very high and cancer is the most likely cause of death."
  },
  {
    "objectID": "software/standsurv/standardized_crude_probabilities_of_death.html#references",
    "href": "software/standsurv/standardized_crude_probabilities_of_death.html#references",
    "title": "Standardized Crude Probabilities of Death",
    "section": "References",
    "text": "References\nSyriopoulou, E.; Rutherford, M. J. & Lambert P. C. Understanding disparities in cancer prognosis: An extension of mediation analysis to the relative survival framework. Biometrical Journal 2021; 63(2): 341-353\nLambert, P. C.; Dickman, P. W.; Nelson, C. P.; Royston P. Estimating the crude probability of death due to cancer and other causes using relative survival models. Statistics in Medicine 2010; 29(7-8): 885-895"
  },
  {
    "objectID": "software/standsurv/models_different_countries.html",
    "href": "software/standsurv/models_different_countries.html",
    "title": "When data cannot cross borders",
    "section": "",
    "text": "This example is based on a presentation at the Association of Nordic Cancer Registries Conference 2024. The presentation can be found here\nInternational collaborative research using cancer registry data enables exploration of differences in cancer incidence, mortality, and survival. However, there is increasing difficulty in moving data across borders, which means that international comparisons are becomiong more challenging. This is particularly the case when an analysis requires fitting survival models, as individual level data is usually required.\nSeparate analyses can be performed in each country, but a consequence of this is analyses are often restricted to being descriptive and more simplistic than if data could be combined.\nFor common cancer sites data is often large enough to fit separate models for each country without a great loss in precision.\nThe aim of this tutorial is to describe a framework where separate models are fitted in each country and the Stata model object (i.e. a .ster file) is shared. This file contains the model parameters and other details of the model, but crucially no individual level data.\nThe example is based on entirely simulated (symthetic) data where the interest is to compare survival between two countries, Country A and Country B.\nThis is cancer registry data where the preferred method of analysis is relative survival, so relative survival models will be fitted. However, the approach of fitting separate models is general and also relevant for more standard (and more complex) survival models.\nThe data is stored in two files CountryA.dta and CountryB.dta. These data files will be analysed separately to mimic situations where data could not be shared between different countries."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#comparing-models-fitted-in-different-countries",
    "href": "software/standsurv/models_different_countries.html#comparing-models-fitted-in-different-countries",
    "title": "When data cannot cross borders",
    "section": "",
    "text": "This example is based on a presentation at the Association of Nordic Cancer Registries Conference 2024. The presentation can be found here\nInternational collaborative research using cancer registry data enables exploration of differences in cancer incidence, mortality, and survival. However, there is increasing difficulty in moving data across borders, which means that international comparisons are becomiong more challenging. This is particularly the case when an analysis requires fitting survival models, as individual level data is usually required.\nSeparate analyses can be performed in each country, but a consequence of this is analyses are often restricted to being descriptive and more simplistic than if data could be combined.\nFor common cancer sites data is often large enough to fit separate models for each country without a great loss in precision.\nThe aim of this tutorial is to describe a framework where separate models are fitted in each country and the Stata model object (i.e. a .ster file) is shared. This file contains the model parameters and other details of the model, but crucially no individual level data.\nThe example is based on entirely simulated (symthetic) data where the interest is to compare survival between two countries, Country A and Country B.\nThis is cancer registry data where the preferred method of analysis is relative survival, so relative survival models will be fitted. However, the approach of fitting separate models is general and also relevant for more standard (and more complex) survival models.\nThe data is stored in two files CountryA.dta and CountryB.dta. These data files will be analysed separately to mimic situations where data could not be shared between different countries."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#kaplan-meier-plots",
    "href": "software/standsurv/models_different_countries.html#kaplan-meier-plots",
    "title": "When data cannot cross borders",
    "section": "Kaplan-Meier plots",
    "text": "Kaplan-Meier plots\nThe following code loads each dataset in turn and produces Kaplan-Meier plots.\n. use https://www.pclambert.net/data/CountryA, clear\n\n. stset survtime, failure(dead=1) \n\nSurvival-time data settings\n\n         Failure event: dead==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n---------------------------------------------------------------------\n&gt; -----\n     20,997  total observations\n          0  exclusions\n---------------------------------------------------------------------\n&gt; -----\n     20,997  observations remaining, representing\n      7,854  failures in single-record/single-failure data\n 59,517.533  total analysis time at risk and under observation\n                                                At risk from t =     \n&gt;     0\n                                     Earliest observed entry t =     \n&gt;     0\n                                          Last observed exit t =     \n&gt;     5\n\n. sts graph, title(Country A) name(CountryA_km, replace)\n\n        Failure _d: dead==1\n  Analysis time _t: survtime\n\n. summ agediag\n\n    Variable |        Obs        Mean    Std. dev.       Min        M\n&gt; ax\n-------------+-------------------------------------------------------\n&gt; --\n     agediag |     20,997    74.78556    9.973784   18.12546   101.57\n&gt; 84\n\n. \n. use https://www.pclambert.net/data/CountryB, clear\n\n. stset survtime, failure(dead=1) \n\nSurvival-time data settings\n\n         Failure event: dead==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n---------------------------------------------------------------------\n&gt; -----\n     10,498  total observations\n          0  exclusions\n---------------------------------------------------------------------\n&gt; -----\n     10,498  observations remaining, representing\n      4,379  failures in single-record/single-failure data\n 28,253.044  total analysis time at risk and under observation\n                                                At risk from t =     \n&gt;     0\n                                     Earliest observed entry t =     \n&gt;     0\n                                          Last observed exit t =     \n&gt;     5\n\n. sts graph, title(Country B) name(CountryB_km, replace)\n\n        Failure _d: dead==1\n  Analysis time _t: survtime\n\n. summ agediag\n\n    Variable |        Obs        Mean    Std. dev.       Min        M\n&gt; ax\n-------------+-------------------------------------------------------\n&gt; --\n     agediag |     10,498    75.53747    10.05265   18.12765   102.46\n&gt; 85\n\n. \n. graph combine CountryA_km CountryB_km\n\nIt can be seen that survival appears slightly worse in Country B. The individuals in Country B are slightly older on average."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#fitting-a-model-to-country-a",
    "href": "software/standsurv/models_different_countries.html#fitting-a-model-to-country-a",
    "title": "When data cannot cross borders",
    "section": "Fitting a model to Country A",
    "text": "Fitting a model to Country A\nWe will first fit a model to data from Country A. We are assuming we have access to data from Country B, but have a colleague who will fit the model in Country A and then send the model .ster file.\nWe first load and stset the data.\n. use https://www.pclambert.net/data/CountryA, clear\n\n. stset survtime, failure(dead=1)\n\nSurvival-time data settings\n\n         Failure event: dead==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n---------------------------------------------------------------------\n&gt; -----\n     20,997  total observations\n          0  exclusions\n---------------------------------------------------------------------\n&gt; -----\n     20,997  observations remaining, representing\n      7,854  failures in single-record/single-failure data\n 59,517.533  total analysis time at risk and under observation\n                                                At risk from t =     \n&gt;     0\n                                     Earliest observed entry t =     \n&gt;     0\n                                          Last observed exit t =     \n&gt;     5\nAs we are fitting relative survial model we need to merge in the expected rates at the event/censoring times.\n. // merge in rates\n. gen _age  = min(floor(agediag + _t),99)                  \n\n. gen _year = year(diagdate + _t*365.25)\n\n. merge m:1 _age _year sex using https://www.pclambert.net/data/popmo\n&gt; rtA, ///\n&gt;           keep(match master)   \n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                            20,997  (_merge==3)\n    -----------------------------------------\nWe then fit a model that incorporates the expected mortality rates using then bhazard(rate) option. The model will include age at diagnosis (agediag) and sex (sex) as covariates. Natural splines will be used to model the effect of agediag with an interaction included with sex. In addition, both agediag and sex have time-dependent effects, i.e. we are allowing for non-proportional excess hazards.\n. stpm3 i.sex##@ns(agediag,df(3)), scale(lncumhazard) df(5) ///\n&gt;       tvc(i.sex @ns(agediag,df(3) winsor(1 99))) dftvc(3) ///\n&gt;       bhazard(rate) \n\nIteration 0:  Log likelihood = -18987.251  \nIteration 1:  Log likelihood = -18784.806  \nIteration 2:  Log likelihood = -18772.486  \nIteration 3:  Log likelihood = -18772.439  \nIteration 4:  Log likelihood = -18772.439  \n\n                                                        Number of obs\n&gt;  = 20,997\n                                                        Wald chi2(7) \n&gt;  = 408.23\nLog likelihood = -18772.439                             Prob &gt; chi2  \n&gt;  = 0.0000\n\n---------------------------------------------------------------------\n&gt; ---------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. \n&gt; interval]\n-------------+-------------------------------------------------------\n&gt; ---------\nxb           |\n       2.sex |  -1.074461   .2982228    -3.60   0.000    -1.658967   \n&gt; -.4899548\n_ns_f1_age~1 |  -10.73306   2.229922    -4.81   0.000    -15.10362   \n&gt; -6.362488\n_ns_f1_age~2 |   1.838314   1.074649     1.71   0.087    -.2679584   \n&gt;  3.944587\n_ns_f1_age~3 |  -1.328113   .4536643    -2.93   0.003    -2.217278   \n&gt; -.4389471\n             |\n         sex#|\n          c. |\n_ns_f1_age~1 |\n          2  |   7.430845    3.10376     2.39   0.017     1.347588   \n&gt;   13.5141\n             |\n         sex#|\n          c. |\n_ns_f1_age~2 |\n          2  |  -2.276144     1.5657    -1.45   0.146     -5.34486   \n&gt;  .7925727\n             |\n         sex#|\n          c. |\n_ns_f1_age~3 |\n          2  |   2.137709   .5439365     3.93   0.000     1.071613   \n&gt;  3.203805\n-------------+-------------------------------------------------------\n&gt; ---------\ntime         |\n        _ns1 |  -33.94606   3.820788    -8.88   0.000    -41.43466   \n&gt; -26.45745\n        _ns2 |   13.16497   1.857333     7.09   0.000     9.524664   \n&gt;  16.80527\n        _ns3 |  -.7336646   .1254783    -5.85   0.000    -.9795976   \n&gt; -.4877316\n        _ns4 |  -.4517587   .1236179    -3.65   0.000    -.6940453   \n&gt; -.2094721\n        _ns5 |  -.3260899   .1155413    -2.82   0.005    -.5525466   \n&gt; -.0996332\n             |\n         sex#|\n  c._ns_tvc1 |\n          2  |    4.06715   2.178313     1.87   0.062    -.2022648   \n&gt;  8.336565\n             |\n         sex#|\n  c._ns_tvc2 |\n          2  |  -1.092972   1.153449    -0.95   0.343    -3.353691   \n&gt;  1.167748\n             |\n         sex#|\n  c._ns_tvc3 |\n          2  |   .3388006   .0639397     5.30   0.000     .2134811   \n&gt;  .4641201\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc1 |  -10.87524   36.43505    -0.30   0.765    -82.28662   \n&gt;  60.53614\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc2 |  -2.683456   19.10172    -0.14   0.888    -40.12214   \n&gt;  34.75523\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc3 |  -.0657363   .8404523    -0.08   0.938    -1.712993   \n&gt;   1.58152\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc1 |      5.078   20.44475     0.25   0.804    -34.99297   \n&gt;  45.14897\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc2 |  -.6415725   10.72052    -0.06   0.952     -21.6534   \n&gt;  20.37026\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc3 |  -.6496364   .3865693    -1.68   0.093    -1.407298   \n&gt;  .1080254\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc1 |   2.506379   7.991825     0.31   0.754    -13.15731   \n&gt;  18.17007\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc2 |   -4.63819    4.24192    -1.09   0.274     -12.9522   \n&gt;   3.67582\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc3 |  -.2157422   .3409415    -0.63   0.527    -.8839752   \n&gt;  .4524909\n             |\n       _cons |    .233223   .2607551     0.89   0.371    -.2778476   \n&gt;  .7442937\n---------------------------------------------------------------------\n&gt; ---------\nExtended functions\n (1) @ns(agediag, df(3))\n (2) @ns(agediag, df(3) winsor(1 99))\nNow the model has been fitted, we can use estimates save to save the model estimates.\n. estimates save CountryA, replace\nfile CountryA.ster saved\nThe saves the file CountryA.ster. It is useful to understand what is stored in this file. Essentially, it is the information you see when you type ereturn list, the output of which is shown below.\n. ereturn list\n\nscalars:\n               e(rank) =  25\n                  e(N) =  20997\n                 e(ic) =  4\n                  e(k) =  29\n               e(k_eq) =  2\n               e(k_dv) =  0\n          e(converged) =  1\n                 e(rc) =  0\n                 e(ll) =  -18772.43865176562\n         e(k_eq_model) =  1\n               e(df_m) =  7\n               e(chi2) =  408.2254068442145\n                  e(p) =  4.10585674052e-84\n                e(dev) =  37544.87730353124\n                e(AIC) =  37594.87730353124\n                e(BIC) =  37769.09675940969\n\nmacros:\n            e(cmdline) : \"i.sex##@ns(agediag,df(3)), scale(lncumh..\"\n                e(cmd) : \"stpm3\"\n            e(predict) : \"stpm3_pred\"\n           e(ef_Nuser) : \"0\"\n  e(ef_agediag_winsor\n    2)                 : \"46.43008277735672 93.75740895924326\"\n  e(ef_agediag_knots2) : \"46.43008277735672 71.40992416203093 79...\"\n   e(ef_agediag_opts2) : \"df(3) winsor(1 99)\"\n     e(ef_agediag_fn2) : \"ns\"\n  e(ef_agediag_knots1) : \"18.12545708589547 71.40992416203093 79...\"\n   e(ef_agediag_opts1) : \"df(3)\"\n     e(ef_agediag_fn1) : \"ns\"\n     e(ef_agediag_Nfn) : \"2\"\n            e(bhazard) : \"rate\"\n         e(ef_varlist) : \"agediag\"\n         e(model_vars) : \"sex agediag\"\n              e(scale) : \"lncumhazard\"\n             e(degree) : \"3\"\n             e(ttrans) : \"lnt\"\n         e(splinetype) : \"ns\"\n          e(knots_tvc) : \"-6.536461339131925 -.4699117670703595 ...\"\n            e(tvcvars) : \"_ns_f2_agediag1 _ns_f2_agediag2 _ns_f2_..\"\n    e(sharedtvc_knots) : \"1\"\n             e(dfbase) : \"5\"\n              e(knots) : \"-6.536461339131925 -1.053905396170044 -..\"\n        e(dsplinevars) : \"_dns1 _dns2 _dns3 _dns4 _dns5 2.sex#c._..\"\n     e(splinevars_tvc) : \"_ns_tvc1 _ns_tvc2 _ns_tvc3\"\n     e(splinelist_tvc) : \"2.sex#c._ns_tvc1 2.sex#c._ns_tvc2 2.sex..\"\n         e(splinelist) : \"_ns1 _ns2 _ns3 _ns4 _ns5\"\n       e(tvc_included) : \"2.sex _ns_f2_agediag1 _ns_f2_agediag2 _..\"\n       e(tvc_original) : \"i.sex @ns(agediag,df(3) winsor(1 99))\"\n                e(tvc) : \"i.sex c.(_ns_f2_agediag1 _ns_f2_agediag..\"\n   e(varlist_original) : \"i.sex##@ns(agediag,df(3))\"\n            e(varlist) : \"i.sex##c.(_ns_f1_agediag1 _ns_f1_agedia..\"\n           e(chi2type) : \"Wald\"\n  e(deriv_useminbound) : \"off\"\n                e(opt) : \"moptimize\"\n                e(vce) : \"oim\"\n               e(user) : \"stpm3_gf2_lncumhazard_rs()\"\n          e(ml_method) : \"gf2\"\n          e(technique) : \"nr\"\n              e(which) : \"max\"\n         e(properties) : \"b V\"\n\nmatrices:\n                  e(b) :  1 x 29\n                  e(V) :  29 x 29\n                e(Cns) :  4 x 30\n               e(ilog) :  1 x 20\n           e(gradient) :  1 x 29\n\nfunctions:\n             e(sample)   \nIt contains summary information such as the log-likelihood (e(ll)), the knot locations for the baseline (e(knots)), the details of the natural spline for agediag including the location of the knots (e(ef_agediag_knots1)).\nThe parameter estimates are stored in e(b) and the variance matrix in e(V). The parameter estimates are listed below,\n. matrix list e(b)\n\ne(b)[1,29]\n               xb:            xb:            xb:            xb:\n               1b.             2.                              \n              sex            sex   _ns_f1_age~1   _ns_f1_age~2\ny1              0     -1.0744608     -10.733055      1.8383143\n\n               xb:            xb:            xb:            xb:\n                          1b.sex#         2.sex#        1b.sex#\n     _ns_f1_age~3   co._ns_f1_~1   c._ns_f1_a~1   co._ns_f1_~2\ny1     -1.3281127              0      7.4308452              0\n\n               xb:            xb:            xb:          time:\n            2.sex#        1b.sex#         2.sex#               \n     c._ns_f1_a~2   co._ns_f1_~3   c._ns_f1_a~3           _ns1\ny1     -2.2761439              0      2.1377088     -33.946056\n\n             time:          time:          time:          time:\n                                                               \n             _ns2           _ns3           _ns4           _ns5\ny1      13.164969     -.73366459     -.45175869      -.3260899\n\n             time:          time:          time:          time:\n            2.sex#         2.sex#         2.sex#  c._ns_f2_a~1#\n       c._ns_tvc1     c._ns_tvc2     c._ns_tvc3     c._ns_tvc1\ny1      4.0671502     -1.0929718      .33880061     -10.875241\n\n             time:          time:          time:          time:\n     c._ns_f2_a~1#  c._ns_f2_a~1#  c._ns_f2_a~2#  c._ns_f2_a~2#\n       c._ns_tvc2     c._ns_tvc3     c._ns_tvc1     c._ns_tvc2\ny1     -2.6834564     -.06573629          5.078     -.64157254\n\n             time:          time:          time:          time:\n     c._ns_f2_a~2#  c._ns_f2_a~3#  c._ns_f2_a~3#  c._ns_f2_a~3#\n       c._ns_tvc3     c._ns_tvc1     c._ns_tvc2     c._ns_tvc3\ny1      -.6496364      2.5063795     -4.6381903     -.21574216\n\n             time:\n                  \n            _cons\ny1      .23322305\nEssentially the information shown in the output of estimates list and saved in the CountryA.ster file contains all the information we need to make predictions from the model. We are able to predict survival and other measures for any covariate pattern for any point in time from diagnosis. Importantly, we do not need the original data to do this. It is important to stress again, that no individual level data is stored in the CountryA.ster file."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#fitting-a-model-to-country-b",
    "href": "software/standsurv/models_different_countries.html#fitting-a-model-to-country-b",
    "title": "When data cannot cross borders",
    "section": "Fitting a model to Country B",
    "text": "Fitting a model to Country B\nWe are assuming that we have access to the data in Country B, so we can load the data and fit the model. We use the same model as before for simplicity and consistency, but we could have fitted a model with different numbers/locations of knots or more/less interactions.\n. use https://www.pclambert.net/data/CountryB, clear\n\n. stset survtime, failure(dead=1)\n\nSurvival-time data settings\n\n         Failure event: dead==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n---------------------------------------------------------------------\n&gt; -----\n     10,498  total observations\n          0  exclusions\n---------------------------------------------------------------------\n&gt; -----\n     10,498  observations remaining, representing\n      4,379  failures in single-record/single-failure data\n 28,253.044  total analysis time at risk and under observation\n                                                At risk from t =     \n&gt;     0\n                                     Earliest observed entry t =     \n&gt;     0\n                                          Last observed exit t =     \n&gt;     5\n\n. \n. // merge in rates\n. gen _age  = min(floor(agediag + _t),99)                  \n\n. gen _year = year(diagdate + _t*365.25)\n\n. merge m:1 _age _year sex using https://www.pclambert.net/data/popmo\n&gt; rtA, ///\n&gt;           keep(match master)   \n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                            10,498  (_merge==3)\n    -----------------------------------------\n\n. \n. stpm3 i.sex##@ns(agediag,df(3)), scale(lncumhazard) df(5) ///\n&gt;       tvc(i.sex @ns(agediag,df(3) winsor(1 99))) dftvc(3) ///\n&gt;       bhazard(rate) \n\nIteration 0:  Log likelihood = -9934.4206  \nIteration 1:  Log likelihood =  -9869.628  \nIteration 2:  Log likelihood = -9844.5096  \nIteration 3:  Log likelihood =  -9844.268  \nIteration 4:  Log likelihood = -9844.2677  \n\n                                                        Number of obs\n&gt;  = 10,498\n                                                        Wald chi2(7) \n&gt;  = 281.55\nLog likelihood = -9844.2677                             Prob &gt; chi2  \n&gt;  = 0.0000\n\n---------------------------------------------------------------------\n&gt; ---------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. \n&gt; interval]\n-------------+-------------------------------------------------------\n&gt; ---------\nxb           |\n       2.sex |  -.5367956   .3572884    -1.50   0.133    -1.237068   \n&gt;  .1634767\n_ns_f1_age~1 |  -17.11178   3.507369    -4.88   0.000    -23.98609   \n&gt; -10.23746\n_ns_f1_age~2 |    4.56246   1.740491     2.62   0.009     1.151161   \n&gt;  7.973759\n_ns_f1_age~3 |  -2.074449   .5580852    -3.72   0.000    -3.168276   \n&gt; -.9806221\n             |\n         sex#|\n          c. |\n_ns_f1_age~1 |\n          2  |   10.21369   4.610953     2.22   0.027     1.176392   \n&gt;    19.251\n             |\n         sex#|\n          c. |\n_ns_f1_age~2 |\n          2  |  -4.779487   2.362219    -2.02   0.043     -9.40935   \n&gt; -.1496237\n             |\n         sex#|\n          c. |\n_ns_f1_age~3 |\n          2  |   1.155039   .6679121     1.73   0.084     -.154045   \n&gt;  2.464122\n-------------+-------------------------------------------------------\n&gt; ---------\ntime         |\n        _ns1 |  -26.61548   3.729184    -7.14   0.000    -33.92454   \n&gt; -19.30641\n        _ns2 |   9.032865   1.781381     5.07   0.000     5.541423   \n&gt;  12.52431\n        _ns3 |  -1.155737   .1753568    -6.59   0.000     -1.49943   \n&gt; -.8120444\n        _ns4 |  -.7050778   .1712158    -4.12   0.000    -1.040655   \n&gt; -.3695009\n        _ns5 |  -.5002046   .1657581    -3.02   0.003    -.8250844   \n&gt; -.1753247\n             |\n         sex#|\n  c._ns_tvc1 |\n          2  |   2.543556   1.996199     1.27   0.203    -1.368922   \n&gt;  6.456034\n             |\n         sex#|\n  c._ns_tvc2 |\n          2  |  -.4942632   1.061708    -0.47   0.642    -2.575173   \n&gt;  1.586647\n             |\n         sex#|\n  c._ns_tvc3 |\n          2  |   .3206083   .0887039     3.61   0.000     .1467518   \n&gt;  .4944648\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc1 |  -.3671341   29.36376    -0.01   0.990    -57.91905   \n&gt;  57.18478\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc2 |  -2.516029   15.62894    -0.16   0.872    -33.14818   \n&gt;  28.11612\n             |\n          c. |\n_ns_f2_age~1#|\n  c._ns_tvc3 |   1.186299   1.126176     1.05   0.292    -1.020966   \n&gt;  3.393564\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc1 |   3.057383   16.23862     0.19   0.851    -28.76972   \n&gt;  34.88449\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc2 |  -1.467367   8.623812    -0.17   0.865    -18.36973   \n&gt;  15.43499\n             |\n          c. |\n_ns_f2_age~2#|\n  c._ns_tvc3 |  -1.063785   .4957864    -2.15   0.032    -2.035508   \n&gt; -.0920615\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc1 |  -2.472087   7.672579    -0.32   0.747    -17.51006   \n&gt;  12.56589\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc2 |   .5907294   4.114411     0.14   0.886    -7.473367   \n&gt;  8.654826\n             |\n          c. |\n_ns_f2_age~3#|\n  c._ns_tvc3 |   .1797678   .4757156     0.38   0.706    -.7526177   \n&gt;  1.112153\n             |\n       _cons |   .9081922    .317337     2.86   0.004     .2862231   \n&gt;  1.530161\n---------------------------------------------------------------------\n&gt; ---------\nExtended functions\n (1) @ns(agediag, df(3))\n (2) @ns(agediag, df(3) winsor(1 99))\nWe save the model estimates as before,\n. estimates save CountryB, replace\nfile CountryB.ster saved"
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#obtaining-marginal-standardized-relative-survival",
    "href": "software/standsurv/models_different_countries.html#obtaining-marginal-standardized-relative-survival",
    "title": "When data cannot cross borders",
    "section": "Obtaining marginal (standardized) relative survival",
    "text": "Obtaining marginal (standardized) relative survival\nNow that we have the two .ster files. We can use them to obtain summary measures that will allow us to compare survival between Country A and Country B.\nAn overall summary measure is standardized marginal relative survival. As we assuming we are in Counrty B we will use this data to define the covariate (age/sex) distribution that we want to standardize to.\nWe load the data we have access to, i.e. Country B.\n. use https://www.pclambert.net/data/CountryB, clear\n\n. stset survtime, failure(dead=1)\n\nSurvival-time data settings\n\n         Failure event: dead==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n---------------------------------------------------------------------\n&gt; -----\n     10,498  total observations\n          0  exclusions\n---------------------------------------------------------------------\n&gt; -----\n     10,498  observations remaining, representing\n      4,379  failures in single-record/single-failure data\n 28,253.044  total analysis time at risk and under observation\n                                                At risk from t =     \n&gt;     0\n                                     Earliest observed entry t =     \n&gt;     0\n                                          Last observed exit t =     \n&gt;     5\nWe then load the model estimates for the model fitted to this data using estimates use.\n. estimate use CountryB\nWe can then use standsurv to obtain the estimated marginal relative survival function.\n. range tt 0 5 101\n(10,397 missing values generated)\n\n. standsurv RS_B, surv timevar(tt) ci frame(RS, replace)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nWe get a warning that we are averaging over observations not included in the model. This is not actually true as we fitted the model to Country B and have reloaded the data for Country B. However, when you use estimate use the e(sample) is set to zero, which means that Stata has not linked the data in memory to the data that was used to fit the model. See the Stata help file for why this is. We will get the same warning when we use standsurv for a model that was not fitted to the data in memory.\nAfter running standsurv we have the is the estimated internally age/sex standardized relative survival for Country B.\nWhen we standardize we want to standardize over the same covariate pattern so that comparisons between the population groups we are comparing are fair. Therefore to obtain standardized estimates for Country A, we keep the same data in memory, (i.e. the data for Country B), but the predictions are based on the model for Country A. To do this we load the model estimates for Country A from CountryA.ster\n. estimate use CountryA\nWe can then run standsurv as before, but we now use frame(RS, merge) so we store the predictions in the same frame as the predictions for Country B.\n. standsurv RS_A, surv frame(RS, merge) ci\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nWe can now plot the marginal relative survival.\n. frame RS {\n.   twoway (rarea RS_A_lci RS_A_uci tt, color(%30))                //\n&gt; /\n&gt;          (line RS_A tt, pstyle(p1line))                          //\n&gt; / \n&gt;          (rarea RS_B_lci RS_B_uci tt, pstyle(p2line) color(%30)) //\n&gt; /\n&gt;          (line RS_B tt, pstyle(p2line)),                         //\n&gt; /\n&gt;          xtitle(\"Years from diagnosis\")                          //\n&gt; /\n&gt;          ytitle(\"Marginal Relative Survival\")                    //\n&gt; /\n&gt;          ylabel(,format(%3.1f))                                  //\n&gt; /\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))       //\n&gt; /\n&gt;          name(RS, replace)\n. }\n\nNote that as we have standardized to the age/sex distribution of Country B, the relative survival function for country B is a model based estimate of the ‘observed’ marginal relative survival in Country B. The estimated relative survival function for Country A is an estimate of the marginal relative survival in Country A if it had the age/sex distribution of Country B."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#relative-survival-as-a-function-of-age-at-diagnosis",
    "href": "software/standsurv/models_different_countries.html#relative-survival-as-a-function-of-age-at-diagnosis",
    "title": "When data cannot cross borders",
    "section": "Relative survival as a function of age at diagnosis",
    "text": "Relative survival as a function of age at diagnosis\nWe can now do a more complicated prediction. The code below obtains the relative survival at 5 years as a function of age at diagnosis. We show the prediction for males (sex==1), but it would be simple to extend the code to obtain predictions for females.\n. frame create ageplot\n\n. frame ageplot {\n.   range agediag 50 80 31\nNumber of observations (_N) was 0, now 31.\n.   gen sex = 1\n.   estimates use CountryA\n.   gen t5 = 5\n.   predict RS5_A, surv at1(.) timevar(t5) ci merge\n.   \n.   estimates use CountryB\n.   predict RS5_B, surv at1(.) timevar(t5) ci merge\n. }\nNote the use of at1(.) which will predict at the observed values of covariates in the active frame (which we have have calculated). In addition, we use the merge option as we want the predictions to be returned to the current frame (ageplot) rather than a new frame.\nHaving generated the predictions, we can plot the results.\n. frame ageplot {\n.   twoway (rarea RS5_A_lci RS5_A_uci agediag, color(%30))           \n&gt;      ///\n&gt;          (line RS5_A agediag, pstyle(p1line))                      \n&gt;      ///\n&gt;          (rarea RS5_B_lci RS5_B_uci agediag, color(%30) pstyle(p2li\n&gt; ne)) ///\n&gt;          (line RS5_B agediag, pstyle(p2line)),                     \n&gt;      ///\n&gt;          xtitle(\"Years from diagnosis\")                            \n&gt;      ///\n&gt;          ytitle(\"Marginal 5-year Relative Survival\")               \n&gt;      ///\n&gt;          ylabel(,format(%3.1f))                                    \n&gt;      ///\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))         \n&gt;      ///\n&gt;          name(RS_age, replace)\n. }"
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#all-cause-survival",
    "href": "software/standsurv/models_different_countries.html#all-cause-survival",
    "title": "When data cannot cross borders",
    "section": "All cause survival",
    "text": "All cause survival\nRelative survival is awkward to interpret in that it attempts to estimate net survival, which is survival in the hypothetical situation where it is not possible to die from any cause other than the cancer under study.\nHowever, we can transform predictions to obtain all cause survival (\\(S_i(t)\\)) by incorporating the expected mortality survival, \\(S_i^*(t)\\), and combining with relative survival, \\(R_i(t)\\).\n\\[\n\\widehat{S}_i(t) = S_i^*(t) \\widehat{R}_i(t)\n\\]\nTo do this we use the expsurv() option of the standsurv command.\nFirst the predictions for Country A\n. estimates use CountryA\n\n. standsurv S_A, surv timevar(tt) ci frame(AC, replace)              \n&gt;       ///\n&gt;                   expsurv(datediag(diagdate)                       \n&gt;       ///\n&gt;                           agediag(agediag)                         \n&gt;       ///\n&gt;                           using(https://www.pclambert.net/data/popm\n&gt; ortA) ///\n&gt;                           pmrate(rate)                             \n&gt;       ///\n&gt;                           pmyear(_year)                            \n&gt;       ///\n&gt;                           pmage(_age)                              \n&gt;       ///\n&gt;                           pmother(sex)                             \n&gt;       ///\n&gt;                           pmmaxyear(2020))  \n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\n.. and then for Country B.\n. estimates use CountryB\n\n. standsurv S_B, surv ci frame(AC, merge)                            \n&gt;       ///\n&gt;                   expsurv(datediag(diagdate)                       \n&gt;       ///\n&gt;                           agediag(agediag)                         \n&gt;       ///\n&gt;                           using(https://www.pclambert.net/data/popm\n&gt; ortB) ///\n&gt;                           pmrate(rate)                             \n&gt;       ///\n&gt;                           pmyear(_year)                            \n&gt;       ///\n&gt;                           pmage(_age)                              \n&gt;       ///\n&gt;                           pmother(sex)                             \n&gt;       ///\n&gt;                           pmmaxyear(2020))  \n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nWe can now plot the model based estimate of all-cause survival.\n. frame AC {\n.   twoway (rarea S_A_lci S_A_uci tt, color(%30))                  //\n&gt; /\n&gt;          (line  S_A tt, pstyle(p1line))                          //\n&gt; / \n&gt;          (rarea S_B_lci S_B_uci tt, pstyle(p2line) color(%30))   //\n&gt; /\n&gt;          (line  S_B tt, pstyle(p2line)),                         //\n&gt; /\n&gt;          xtitle(\"Years from diagnosis\")                          //\n&gt; /\n&gt;          ytitle(\"Marginal All cause Survival\")                   //\n&gt; /\n&gt;          ylabel(,format(%3.1f))                                  //\n&gt; /\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))       //\n&gt; /\n&gt;          name(RS, replace)\n. }                        \n\nThere is a clear difference in all cause survival between Country A and Country B. However, although we have standardized to the same age/sex distribution, differences could be due to differential cancer (excess) mortality rates and/or differential other cause (expected) mortality rates. This is one reason why relative survival has been the preferred metric when quantifying cancer survival. We have developed reference adjusted measures that enables the reporting of all-cause survival in a way where the only differences should be due to differential cancer mortality rates as shown in the next section."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#reference-adjustment",
    "href": "software/standsurv/models_different_countries.html#reference-adjustment",
    "title": "When data cannot cross borders",
    "section": "Reference Adjustment",
    "text": "Reference Adjustment\nWith reference adjustment we define a reference expected survival, \\(S_i^{**}\\) that is the same between any groups we are comparing. We can then obtain reference adjusted all cause survival as follows, \\(\\widehat{S}_i^{REF}(t)\\).\n\\[\n\\widehat{S}_i^{REF}(t) = S_i^{**}(t) \\widehat{R}_i(t)\n\\]\nThis is for a particular individual, \\(i\\), but we can average of many individuals to obtain marginal (standardized) estimates using standsurv. Here will use the expected mortality rates for Country B as the reference. This means that the reference adjusted marginal estimates of all cause survival for Country B will be an estimate of the observed all cause survival in Country B. For Country A it will be an estimate of the marginal all cause survival in Country A if it had the expected mortality rates of Country B and the age/sex distribution of Country B. Note that the appropriate expected mortality rates for country A were used when fitting the model, but the reference rates are used when making predictions from the model.\nThe reason for doing this is that any differences we see in the marginal all cause survival will only be due to differential relative survival between the two countries, see Lambert et al. 2020.\nWe reload the estimates for the model fitted to Country B and then run standsurv\n. estimates use CountryB\n\n. standsurv Sref_B, surv timevar(tt) ci frame(RefAdj, replace)       \n&gt;       ///\n&gt;                   expsurv(datediag(diagdate)                       \n&gt;       ///\n&gt;                           agediag(agediag)                         \n&gt;       ///\n&gt;                           using(https://www.pclambert.net/data/popm\n&gt; ortB) ///\n&gt;                           pmrate(rate)                             \n&gt;       ///\n&gt;                           pmyear(_year)                            \n&gt;       ///\n&gt;                           pmage(_age)                              \n&gt;       ///\n&gt;                           pmother(sex)                             \n&gt;       ///\n&gt;                           pmmaxyear(2020))  \n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nWe then reload the estimates for the model fitted to Country A and run standsurv again.\n. estimates use CountryA\n\n. standsurv Sref_A, surv ci frame(RefAdj, merge)                     \n&gt;       ///\n&gt;                   expsurv(datediag(diagdate)                       \n&gt;       ///\n&gt;                           agediag(agediag)                         \n&gt;       ///\n&gt;                           using(https://www.pclambert.net/data/popm\n&gt; ortB) ///\n&gt;                           pmrate(rate)                             \n&gt;       ///\n&gt;                           pmyear(_year)                            \n&gt;       ///\n&gt;                           pmage(_age)                              \n&gt;       ///\n&gt;                           pmother(sex)                             \n&gt;       ///\n&gt;                           pmmaxyear(2020))  \n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nAnd finally plot the results.\n. frame RefAdj {\n.   twoway (rarea Sref_A_lci Sref_A_uci tt, color(%30))              \n&gt;   ///\n&gt;          (line  Sref_A tt, pstyle(p1line))                         \n&gt;   /// \n&gt;          (rarea Sref_B_lci Sref_B_uci tt, pstyle(p2line) color(%30)\n&gt; ) ///\n&gt;          (line  Sref_B tt, pstyle(p2line)),                        \n&gt;   ///\n&gt;          xtitle(\"Years from diagnosis\")                            \n&gt;   ///\n&gt;          ytitle(\"Reference Adjusted All cause Survival\")           \n&gt;   ///\n&gt;          ylabel(,format(%3.1f))                                    \n&gt;   ///\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))         \n&gt;   ///\n&gt;          name(RS, replace)\n. }                                   \n\nAs we have standardized over the age/sex distribution of Country B and used the expected mortality rates for Country B, this figure gives an estimate of the average all cause survival for Country B (it will be very similar the all cause Kaplan-Meier estimate).\nHowever, for Country A the estimate is hypothetical in two ways. Firstly, it is standardized over the age/sex distribution for Country B. Secondly, the reference expected mortality rates are for Country B, so it gives an estimate of what the all cause survival would be in Country A if it had the expected mortality rates seen in Country B and the age/sex distribution of Country B. We should remember that the reason for making the estimates Country A hypothetical are for reasons of comparability and we want to isolate differences that are only due to differences in cancer (excess) mortality rates."
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#reference-adjustment-with-external-age-standardization",
    "href": "software/standsurv/models_different_countries.html#reference-adjustment-with-external-age-standardization",
    "title": "When data cannot cross borders",
    "section": "Reference Adjustment with external age standardization",
    "text": "Reference Adjustment with external age standardization\nWhen it is of interest to make comparisons with other studies it is important to standardize to the same age/sex distribution. Many population-based cancer survival studies use the International Cancer Survival Standard as an external age distribution to standardise to.\nThe following code calcuates the ICSS age groups and associated weights.\n. //Define ICSS age groups and weights\n. recode agediag (min/44.999=1) (45/54.999=2) (55/64.999=3) (65/74.99\n&gt; 9=4) (75/max=5), gen(ICSSagegrp)\n(10,498 differences between agediag and ICSSagegrp)\n\n. recode ICSSagegrp (1=0.07) (2=0.12) (3=0.23) (4=0.29) (5=0.29), gen\n&gt; (ICSSwt)\n(10,498 differences between ICSSagegrp and ICSSwt)\nNext we calculate the proportion in our data (Country B) in each age group for each sex. We then calculate the ratio of the ICSS weights and the observed proportion in each age group, so that we can upweight or downweight individuals in each age group.\n. bysort sex: gen sextotal= _N\n\n. bysort ICSSagegrp sex:gen a_age = _N/sextotal\n\n. gen double wt_age = ICSSwt/a_age\n\n. \n. bysort sex ICSSagegrp: gen first = _n==1\n\n. list sex ICSSagegrp ICSSwt a_age wt_age if first, noobs ab(12)\n\n  +---------------------------------------------------+\n  | sex   ICSSagegrp   ICSSwt       a_age      wt_age |\n  |---------------------------------------------------|\n  |   1            1      .07   .00617443   11.337083 |\n  |   1            2      .12   .02405454   4.9886631 |\n  |   1            3      .23    .1039362    2.212896 |\n  |   1            4      .29   .32518652   .89179589 |\n  |   1            5      .29   .54064831   .53639305 |\n  |---------------------------------------------------|\n  |   2            1      .07   .00844347   8.2904348 |\n  |   2            2      .12    .0256975   4.6697143 |\n  |   2            3      .23   .10352423   2.2217021 |\n  |   2            4      .29   .30029369   .96572127 |\n  |   2            5      .29   .56204112   .51597649 |\n  +---------------------------------------------------+\n\n. sort tt\nNext we can use standsurv’ to obtain marginal estimates. Here we calculate marginal relative survival, but we could do this for reference adjusted measures as well.\nWe do this first for Country B,\n. estimates use CountryB\n\n. standsurv RS_B if sex==1, surv timevar(tt) ci frame(RS_ICSS, replac\n&gt; e) ///\n&gt;                               indweights(wt_age)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nand then for Country A.\n. estimates use CountryA\n\n. standsurv RS_A if sex==1, surv ci frame(RS_ICSS, merge)   ///\n&gt;                               indweights(wt_age)  \n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nFinally, we can plot the results.\n. frame RS_ICSS {\n.   twoway (rarea RS_A_lci RS_A_uci tt, color(%30))                //\n&gt; /\n&gt;          (line RS_A tt, pstyle(p1line))                          //\n&gt; / \n&gt;          (rarea RS_B_lci RS_B_uci tt, pstyle(p2line) color(%30)) //\n&gt; /\n&gt;          (line RS_B tt, pstyle(p2line)),                         //\n&gt; /\n&gt;          xtitle(\"Years from diagnosis\")                          //\n&gt; /\n&gt;          ytitle(\"Marginal Relative Survival\")                    //\n&gt; /\n&gt;          ylabel(,format(%3.1f))                                  //\n&gt; /\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))       //\n&gt; /\n&gt;          name(RS_ICSS, replace)\n. }"
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#standardizing-to-the-agesex-distribution-of-country-a",
    "href": "software/standsurv/models_different_countries.html#standardizing-to-the-agesex-distribution-of-country-a",
    "title": "When data cannot cross borders",
    "section": "Standardizing to the age/sex distribution of Country A",
    "text": "Standardizing to the age/sex distribution of Country A\nWe have been assuming that we are in, and have access to data from Country B. What if we want to standardize to the age/sex distribution of Country A? We could send the Country B.ster file to a colleague in Country A and they could repeat the analysis above, but now the standardization would be over the age/sex distribution in Country A (i.e. the data in memory).\nOne other option would be to obtain a summary of the age/sex distribution in Country A and use this to create a data set to standardize over. We show two ways of standardizing once we have this information.\nFirst we will assume that a colleague in Country A has produced a summary of the proportion in each age/sex combination, perhaps using code like the following.\n. use https://www.pclambert.net/data/CountryA, clear\n\n. gen ageint = floor(agediag)\n\n. collapse (percent) cellpercent=agediag, by(ageint sex)\n\n. list in 1/20, noobs ab(11)   \n\n  +----------------------------+\n  | sex   ageint   cellpercent |\n  |----------------------------|\n  |   1       18     .00476259 |\n  |   2       18     .00476259 |\n  |   1       19     .01428776 |\n  |   2       19     .00476259 |\n  |   1       20     .00476259 |\n  |----------------------------|\n  |   1       21     .01428776 |\n  |   2       21     .00476259 |\n  |   1       23     .00952517 |\n  |   2       23     .00476259 |\n  |   1       25     .00952517 |\n  |----------------------------|\n  |   1       26     .00476259 |\n  |   1       27     .00952517 |\n  |   2       27     .00476259 |\n  |   1       28     .00476259 |\n  |   1       29     .01428776 |\n  |----------------------------|\n  |   1       30     .02381293 |\n  |   1       31     .02857551 |\n  |   2       31     .00476259 |\n  |   1       32     .00476259 |\n  |   2       32     .01428776 |\n  +----------------------------+\n\n. rename ageint agediag\n\n. save CountryA_age_sex_summary, replace\nfile CountryA_age_sex_summary.dta saved\nThis given us the proportion in each age/sex comination in Country A\nWe can then calculate the weights.\n. use CountryA_age_sex_summary, clear\n\n. gen wt = (cellpercent/100)*_N\nThese weights need to sum to the total number of observations in the data, which is why the percentage is converted to a proportion and then multiplied by _N.\nWe can then use standsurv for each of the the model estimates passing the weights using the indweights() option. The code below shows for estimation of standardized relative survival, but this can easily be extended in a similar way to above for reference adjustment etc.\n. estimates use CountryA\n\n. range tt 0 10 101\n(52 missing values generated)\n\n. standsurv RS_A, surv timevar(tt) ci indweights(wt) ///\n&gt;                 frame(RS_standA1, replace)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\n\n. estimates use CountryB\n\n. standsurv RS_B, surv ci indweights(wt) ///\n&gt;                 frame(RS_standA1, merge)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nThis can be plotted.\n. frame RS_standA1 {\n.   twoway (rarea RS_A_lci RS_A_uci tt, color(%30))                //\n&gt; /\n&gt;          (line RS_A tt, pstyle(p1line))                          //\n&gt; / \n&gt;          (rarea RS_B_lci RS_B_uci tt, pstyle(p2line) color(%30)) //\n&gt; /\n&gt;          (line RS_B tt, pstyle(p2line)),                         //\n&gt; /\n&gt;          xtitle(\"Years from diagnosis\")                          //\n&gt; /\n&gt;          ytitle(\"Marginal Relative Survival\")                    //\n&gt; /\n&gt;          ylabel(,format(%3.1f))                                  //\n&gt; /\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))       //\n&gt; /\n&gt;          name(RS, replace)\n. }\n\nAn alternative way to get the same result is to expand the data to match the percentage for each cell. Here we make the sample size 20000.\n. use CountryA_age_sex_summary, clear\n\n. gen freq = round(20000*cellpercent/100)\n\n. expand freq\n(19,853 observations created)\n\n. estimates use CountryA\n\n. range tt 0 10 101\n(19,905 missing values generated)\n\n. standsurv RS_A, surv timevar(tt) ci ///\n&gt;                 frame(RS_standA2, replace)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\n\n. estimates use CountryB\n\n. standsurv RS_B, surv ci             ///\n&gt;                 frame(RS_standA2, merge)\n!!WARNING!! You are including observations not included in the model\nwhen calculating standardized estimates.\nEnsure this is what you intended.\nThis avoids having to use the indweights() option.\n. frame RS_standA2 {\n.   twoway (rarea RS_A_lci RS_A_uci tt, color(%30))                //\n&gt; /\n&gt;          (line RS_A tt, pstyle(p1line))                          //\n&gt; / \n&gt;          (rarea RS_B_lci RS_B_uci tt, pstyle(p2line) color(%30)) //\n&gt; /\n&gt;          (line RS_B tt, pstyle(p2line)),                         //\n&gt; /\n&gt;          xtitle(\"Years from diagnosis\")                          //\n&gt; /\n&gt;          ytitle(\"Marginal Relative Survival\")                    //\n&gt; /\n&gt;          ylabel(,format(%3.1f))                                  //\n&gt; /\n&gt;          legend(order(2 \"Country A\" 4 \"Country B\") pos(1))       //\n&gt; /\n&gt;          name(RS, replace)\n. }"
  },
  {
    "objectID": "software/standsurv/models_different_countries.html#references",
    "href": "software/standsurv/models_different_countries.html#references",
    "title": "When data cannot cross borders",
    "section": "References",
    "text": "References\nLambert PC, Andersson TM-L, Rutherford MJ, Myklebust TÅ, Møller B. Reference-adjusted and standardized all-cause and crude probabilities as an alternative to net survival in population-based cancer studies. International Journal of Epidemiology 2020;49:1614–23. https://doi.org/10.1093/ije/dyaa112\nRutherford MJ, Andersson TM-L, Myklebust TÅ, Møller B, Lambert PC. Non-parametric estimation of reference adjusted, standardised probabilities of all-cause death and death due to cancer for population group comparisons. BMC Medical Research Methodology 2022;22:2. https://doi.org/10.1186/s12874-021-01465-w"
  },
  {
    "objectID": "software/mrsprep/mrsprep_modelling_covariates.html#background",
    "href": "software/mrsprep/mrsprep_modelling_covariates.html#background",
    "title": "Modelling covariates in marginal relative survival models",
    "section": "Background",
    "text": "Background\nI have described how to fit a marginal relative survival moded to give an internally (age) standardized estimate and how this can be extended to give an externally age standardized estimate. This example shows how to incorporate covariates into the marginal model whilst, still age standardizing."
  },
  {
    "objectID": "software/mrsprep/mrsprep_modelling_covariates.html#example",
    "href": "software/mrsprep/mrsprep_modelling_covariates.html#example",
    "title": "Modelling covariates in marginal relative survival models",
    "section": "Example",
    "text": "Example\nI again use the Melanoma data, restricting to those diagnosed in the later calendar perdiod, 1985-1994, but will compare relative survival between males and females. I restrict follow-up to 10 years after diagnosis using the exit() option.\n. use https://pclambert.net/data/melanoma.dta if year8594 == 1 \n(Skin melanoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm, failure(status=1,2) id(id) exit(time 120.5) scale(12)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      4,744  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      4,744  observations remaining, representing\n      4,744  subjects\n      1,401  failures in single-failure-per-subject data\n 22,003.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\n\n. gen female = sex==2\nI will first estimate the non-parametric estimate of marginal relative survival using stpp. I will use the by(female) option to estimate separately for males and females. As the age distribution between males and females could potentially be different I need to age standardize. I will use the ICSS weights (Corazziari et al.).\n. // change age groups to those defined in ICSS\n. drop agegrp\n\n. egen agegrp=cut(age), at(0  45 55 65 75 200) icodes\n\n. replace agegrp = agegrp + 1\n(4,744 real changes made)\n\n. label variable agegrp \"Age group\"\n\n. label define agegrplab 1 \"0-44\" 2 \"45-54\" 3 \"55-64\" 4 \"65-74\" 5 \"75+\", replace\n\n. label values agegrp agegrplab\n\n. \n. recode agegrp (1=0.28) (2=0.17) (3=0.21) (4=0.20) (5=0.14), gen(ICSSwt)\n(4,744 differences between agegrp and ICSSwt)\nThe relative weights (explained in the example on external age standardization) have to been calculated separately for males and females. This can be done as follows.\n. //Proportion within each age group by sex to calculate weights\n. bysort female: egen totalsex = total(sex)\n\n. bysort agegrp female: gen a_age_sex = _N/totalsex\n\n. gen double wt_age_sex = ICSSwt/a_age_sex\nThe non-parametric Pohar estimator can be obtained using stpp.\n. stpp R_pp using https://pclambert.net/data/popmort.dta, /// \n&gt;                 agediag(age) datediag(dx) pmother(sex)  ///\n&gt;                 by(female)                              ///\n&gt;                 indweights(wt_age_sex)\n\n. frame put R_pp* female _t, into(PP)\nI have saved the Pohar Perme estimates in a frame, so I can plot them in after using mrsprep."
  },
  {
    "objectID": "software/mrsprep/mrsprep_modelling_covariates.html#using-mrsprep-to-enable-modelling-of-covariates",
    "href": "software/mrsprep/mrsprep_modelling_covariates.html#using-mrsprep-to-enable-modelling-of-covariates",
    "title": "Modelling covariates in marginal relative survival models",
    "section": "Using mrsprep to enable modelling of covariates",
    "text": "Using mrsprep to enable modelling of covariates\nAs the individual level weights have been calculated all that has to be added to mrsprep is the by(female) option. This will calculate the mean expected mortality rate needed to fit the model separately for males and females. The individual weights are incorporated into both the weighted mean expected mortality rate and the time-dependent weights.\n. mrsprep using https://pclambert.net/data/popmort.dta   ///\n&gt;               , pmother(sex) agediag(age) datediag(dx) ///\n&gt;                 breaks(0(0.2)10)                       ///\n&gt;                 indweights(wt_age_sex)                 ///\n&gt;                 by(female)\nModelling proceeds as before, but now we can model the effect of sex. A proportional excess hazards marginal model can be fitted as follows,\n. stset tstop [iweight=wt], enter(tstart) failure(event==1)                                          \n\nSurvival-time data settings\n\n         Failure event: event==1\nObserved time interval: (0, tstop]\n     Enter on or after: time tstart\n     Exit on or before: failure\n                Weight: [iweight=wt]\n\n--------------------------------------------------------------------------\n    112,229  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n    112,229  observations remaining, representing\n      1,401  failures in single-record/single-failure data\n 21,994.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm3 female, scale(lncumhazard) df(5) bhazard(meanhazard_wt) vce(cluster id) eform\n\nIteration 0:  Log pseudolikelihood = -7837.7029  \nIteration 1:  Log pseudolikelihood = -7733.1564  \nIteration 2:  Log pseudolikelihood = -7733.0105  \nIteration 3:  Log pseudolikelihood = -7733.0103  \n\n                                                       Number of obs = 112,229\n                                                       Wald chi2(1)  =   15.70\nLog pseudolikelihood = -7733.0103                      Prob &gt; chi2   =  0.0001\n\n                                 (Std. err. adjusted for 4,744 clusters in id)\n------------------------------------------------------------------------------\n             |               Robust\n             |     exp(b)   std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      female |   .7012648   .0628019    -3.96   0.000     .5883728    .8358176\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -17.60777   1.009002   -17.45   0.000    -19.58537   -15.63016\n        _ns2 |   4.485199   .5017806     8.94   0.000     3.501727    5.468671\n        _ns3 |  -1.051828   .0948416   -11.09   0.000    -1.237714   -.8659419\n        _ns4 |   -.610668   .0794981    -7.68   0.000    -.7664814   -.4548545\n        _ns5 |  -.1254523   .1242051    -1.01   0.312    -.3688897    .1179852\n       _cons |  -1.086839   .0893483   -12.16   0.000    -1.261959   -.9117199\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nThis gives a marginal excess hazard (mortality rate) ratio of 0.70. Note we would expect this be different from a standard (conditional) relative survival model adjusting for age due to the non collapsability of (excess) hazard ratios.\nThe proportionality assumption can be relaxed by incorporating an interaction between sex and the effect of time from diagnosis.\n. stpm3 female, scale(lncumhazard) df(5) bhazard(meanhazard_wt) vce(cluster id) ///\n&gt;        tvc(female) dftvc(3)\n\nIteration 0:  Log pseudolikelihood = -7840.0016  \nIteration 1:  Log pseudolikelihood = -7729.7635  \nIteration 2:  Log pseudolikelihood = -7729.2387  \nIteration 3:  Log pseudolikelihood = -7729.2339  \nIteration 4:  Log pseudolikelihood = -7729.2339  \n\n                                                       Number of obs = 112,229\n                                                       Wald chi2(1)  =    5.16\nLog pseudolikelihood = -7729.2339                      Prob &gt; chi2   =  0.0231\n\n                                        (Std. err. adjusted for 4,744 clusters in id)\n-------------------------------------------------------------------------------------\n                    |               Robust\n                    | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\nxb                  |\n             female |  -.3247996   .1430029    -2.27   0.023    -.6050802    -.044519\n--------------------+----------------------------------------------------------------\ntime                |\n               _ns1 |  -20.13637   2.235546    -9.01   0.000    -24.51796   -15.75478\n               _ns2 |   5.991217   1.097732     5.46   0.000     3.839702    8.142732\n               _ns3 |  -.9444574   .1238416    -7.63   0.000    -1.187183   -.7017323\n               _ns4 |  -.5818713   .1157506    -5.03   0.000    -.8087382   -.3550043\n               _ns5 |  -.1408935   .1529997    -0.92   0.357    -.4407674    .1589803\n                    |\nc.female#c._ns_tvc1 |   3.507369   2.594049     1.35   0.176    -1.576874    8.591612\n                    |\nc.female#c._ns_tvc2 |  -2.433839   1.310774    -1.86   0.063     -5.00291    .1352315\n                    |\nc.female#c._ns_tvc3 |   .0382472   .2393267     0.16   0.873    -.4308247     .507319\n                    |\n              _cons |  -1.107289   .1106139   -10.01   0.000    -1.324088   -.8904897\n-------------------------------------------------------------------------------------\n\n. predict s_mrs_male s_mrs_female, surv timevar(0 10, step(0.1)) ci frame(mrs) ///\n&gt;                                  at1(female 0) at2(female 1)\nPredictions are stored in frame - mrs\nI have predicted marginal relative survival separately for males and females. These can be shown in the plot below.\n. frame PP {\n.   twoway (rarea R_pp_lci R_pp_uci _t if !female, sort connect(stairstep) color(%30))      ///\n&gt;          (rarea R_pp_lci R_pp_uci _t if female,  sort connect(stairstep) color(%30))      ///\n&gt;          (line R_pp _t if !female, sort lpattern(dot) connect(stairstep) pstyle(p1line))  ///\n&gt;          (line R_pp _t if female,  sort lpattern(dot) connect(stairstep) pstyle(p2line)), ///\n&gt;          ylabel(0.6(0.1)1, format(%3.1f))                                                      ///\n&gt;          ytitle(\"Marginal relative survival\")                                                  ///\n&gt;          xtitle(\"Years from diagnosis\")                                                        ///\n&gt;          name(sex_compare, replace)      \n. }         \n\n. frame mrs: addplot: (line s_mrs_male* tt,   sort pstyle(p1line..) lpattern(solid dash dash)) \n\n. frame mrs: addplot: (line s_mrs_female* tt, sort pstyle(p2line..) lpattern(solid dash dash) ///\n&gt;                      legend(order(5 \"Males\" 8 \"Females\")                                     ///\n&gt;                             ring(0) cols(1) pos(7)))                 \n\nThus we have obtained externally age standardized estimates of marginal relative survival without the need to stratify or model the effect of age."
  },
  {
    "objectID": "software/mrsprep/mrsprep_modelling_covariates.html#references",
    "href": "software/mrsprep/mrsprep_modelling_covariates.html#references",
    "title": "Modelling covariates in marginal relative survival models",
    "section": "References",
    "text": "References\nLambert PC, Syriopoulou E, Rutherford MJ. Direct modelling of age standardized marginal relative survival through incorporation of time-dependent weights. BMC Medical Research Methodology 2021;21:84\nCorazziari I, Quinn M, Capocaccia R. Standard cancer patient population for age standardising survival ratios. European Journalo of Cancer 2004;40:2307-2316"
  },
  {
    "objectID": "software/mrsprep/mrsprep_external_age_standardization.html#background",
    "href": "software/mrsprep/mrsprep_external_age_standardization.html#background",
    "title": "External age standardization in marginal relative survival models",
    "section": "Background",
    "text": "Background\nI have described how to fit a marginal relative survival moded which gives an internally standardized estimate of marginal relative survival. This example shows how introducing inidvidual level weights can be used to standardize to an external population."
  },
  {
    "objectID": "software/mrsprep/mrsprep_external_age_standardization.html#example",
    "href": "software/mrsprep/mrsprep_external_age_standardization.html#example",
    "title": "External age standardization in marginal relative survival models",
    "section": "Example",
    "text": "Example\nI again use the Melanoma data, restricting to those diagnosed in the later calendar perdiod, 1985-1994. I restrict follow-up to 10 years after diagnosis using the exit() option.\n. use https://pclambert.net/data/melanoma.dta if year8594 == 1 \n(Skin melanoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm, failure(status=1,2) id(id) exit(time 120.5) scale(12)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      4,744  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      4,744  observations remaining, representing\n      4,744  subjects\n      1,401  failures in single-failure-per-subject data\n 22,003.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\nI will first estimate the non-parametric estimate of marginal relative survival using stpp, but externally age standardize to the age distribution defined in the International Cancer Survival Standard (ICSS) (Corazziari et al.). For melanoma the ICSS age distribution is\n\n\n\nAge Group\nProportion\n\n\n\n\n0-44\n0.28\n\n\n45-54\n0.17\n\n\n55-64\n0.21\n\n\n65-74\n0.20\n\n\n75+\n0.14\n\n\n\nWhen we age standardize we estimate what the marginal relative survival would be if the study population had the age distribution seen in the above table.\nThe following code calculates the ICSS age groups (agegrp) and a variable containing the ICSS weighs (ICSSwt).\n. // change age groups to those defined in ICSS\n. drop agegrp\n\n. egen agegrp=cut(age), at(0  45 55 65 75 200) icodes\n\n. replace agegrp = agegrp + 1\n(4,744 real changes made)\n\n. label variable agegrp \"Age group\"\n\n. label define agegrplab 1 \"0-44\" 2 \"45-54\" 3 \"55-64\" 4 \"65-74\" 5 \"75+\", replace\n\n. label values agegrp agegrplab\n\n. \n. recode agegrp (1=0.28) (2=0.17) (3=0.21) (4=0.20) (5=0.14), gen(ICSSwt)\n(4,744 differences between agegrp and ICSSwt)\nmrsprep calculates time-dependent weights based on the inverse of the expected survival. To standardize to an external population we need to up or down weight individuals relative to the reference population. Let \\(p^a_i\\) be the proportion in the age group to which the \\(i^{th}\\) individual belongs and \\(p^R_i\\) be the corresponding proportion in the reference population. Weights, \\(w_i^a\\) are defined as the ratio between these two proportions.\n\\[\nw_i^a = \\frac{p^R_i}{p^a_i}\n\\] These weights can then be combined with the inverse expected survival weights, \\[\nw_i(t) = \\frac{w_i^a}{S^*_i(t)}\n\\]\nmrsprep has an indweights() option where the individual level weights are passed to the command. These can be calculated as follows,\n. // Proportion within each age group\n. local total= _N\n\n. bysort agegrp: gen a_age = _N/`total'\n\n. gen double wt_age = ICSSwt/a_age\nThese same weights can also be used in the non-parametric Pohar Perme estimator (Rutherford et al 2020 ), as shown below.\n. stpp R_pp using https://pclambert.net/data/popmort.dta, /// \n&gt;                 agediag(age) datediag(dx) pmother(sex)  ///\n&gt;                 indweights(wt_age)\n\n. frame put R_pp* _t, into(PP)\nI have saved the Pohar Perme estimates in a frame, so I can plot them after using mrsprep.\nThe same option can be used with mrsprep. The code for mrsprep is shown below.\n. mrsprep using https://pclambert.net/data/popmort.dta   ///\n&gt;               , pmother(sex) agediag(age) datediag(dx) ///\n&gt;                 breaks(0(0.2)10)                       ///\n&gt;                 indweights(wt_age)                     \nThen a marginal model can be fitted in exactly the same way as when using internal age standardization.\n. stset tstop [iweight=wt], enter(tstart) failure(event==1)                                          \n\nSurvival-time data settings\n\n         Failure event: event==1\nObserved time interval: (0, tstop]\n     Enter on or after: time tstart\n     Exit on or before: failure\n                Weight: [iweight=wt]\n\n--------------------------------------------------------------------------\n    112,229  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n    112,229  observations remaining, representing\n      1,401  failures in single-record/single-failure data\n 21,994.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm3, scale(lncumhazard) df(5) bhazard(meanhazard_wt) vce(cluster id)\n\nIteration 0:  Log pseudolikelihood = -5385.7819  \nIteration 1:  Log pseudolikelihood =  -5311.682  \nIteration 2:  Log pseudolikelihood = -5311.5243  \nIteration 3:  Log pseudolikelihood = -5311.5239  \n\n                                                       Number of obs = 112,229\n                                                       Wald chi2(5)  =  631.15\nLog pseudolikelihood = -5311.5239                      Prob &gt; chi2   =  0.0000\n\n                                 (Std. err. adjusted for 4,744 clusters in id)\n------------------------------------------------------------------------------\n             |               Robust\n             | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -18.02865   1.035765   -17.41   0.000    -20.05872   -15.99859\n        _ns2 |   4.655575     .52232     8.91   0.000     3.631846    5.679303\n        _ns3 |   -1.05223   .0921339   -11.42   0.000    -1.232809    -.871651\n        _ns4 |  -.5956499   .0756741    -7.87   0.000    -.7439684   -.4473313\n        _ns5 |  -.1368423   .1214885    -1.13   0.260    -.3749555    .1012709\n       _cons |  -1.267081   .0773336   -16.38   0.000    -1.418652   -1.115509\n------------------------------------------------------------------------------\n\n. predict s_mrsprep, surv timevar(0 10, step(0.1)) ci frame(mrs)\nPredictions are stored in frame - mrs\nAfter fitting the model, the marginal relative survival has been predicted. This can now be compared to the Pohar Perme non-parametric estimate.\n. frame PP {\n.   twoway (rarea R_pp_lci R_pp_uci _t, sort connect(stairstep) color(%30))   ///\n&gt;          (line R_pp _t, sort connect(stairstep) pstyle(p1line))             ///\n&gt;          , ylabel(0.6(0.1)1, format(%3.1f))                                 ///\n&gt;            ytitle(\"Marginal relative survival\")                             ///\n&gt;            xtitle(\"Years from diagnosis\")                                   ///\n&gt;            name(int_stand_standsurv, replace)      \n. }           \n\n. frame mrs: addplot: (line s_mrsprep* tt, pstyle(p2line..)           ///\n&gt;                                          lpattern(solid dash dash)  ///\n&gt;                                          norescaling                ///\n&gt;                      legend(order(2 \"Pohar Perme\"                   ///\n&gt;                                   3 \"Marginal stpm3 model\")         ///\n&gt;                             ring(0) cols(1) pos(7)))\n\n.            \n\nThere is good agreement between the model based and the non parametric Pohar Perme estimtor.\nThe estimate here is an externally age standardized estimate, but is actually very similar to the internally age standardized estimate as the age distribution in the study population is similar to the age distribution in the reference population."
  },
  {
    "objectID": "software/mrsprep/mrsprep_external_age_standardization.html#references",
    "href": "software/mrsprep/mrsprep_external_age_standardization.html#references",
    "title": "External age standardization in marginal relative survival models",
    "section": "References",
    "text": "References\nLambert PC, Syriopoulou E, Rutherford MJ. Direct modelling of age standardized marginal relative survival through incorporation of time-dependent weights. BMC Medical Research Methodology 2021;21:84\nCorazziari I, Quinn M, Capocaccia R. Standard cancer patient population for age standardising survival ratios. European Journalo of Cancer 2004;40:2307-2316\nRutherford, M.J., Dickman, P.W., Coviello, E. & Lambert, P.C. Estimation of age-standardized net survival, even when age-specific data are sparse. Cancer Epidemiology 2020;67:101745."
  },
  {
    "objectID": "software/gensplines.html",
    "href": "software/gensplines.html",
    "title": "gensplines",
    "section": "",
    "text": "The genplines command calculates various types of spline basis functions. This includes splines based on truncated powers, restricted cubic splines, B-splines, M-splines, I-splines and, natural splines. Note that natural splines and restricted splines are two different ways to impose linearity constraints beyond the boundary knots and will result in the same fitted values in a regression model (with the same knots).\nFor the most part the methods are the same as those implemented in the spline2 package in R."
  },
  {
    "objectID": "software/gensplines.html#examples",
    "href": "software/gensplines.html#examples",
    "title": "gensplines",
    "section": "Examples",
    "text": "Examples\n\n[Various types of spline basis functions]\nDerivatives and integrals of spline functions\ngensplines compared to makespline"
  },
  {
    "objectID": "software/gensplines.html#reference",
    "href": "software/gensplines.html#reference",
    "title": "gensplines",
    "section": "Reference",
    "text": "Reference\nWang, Jiangdian, and Sujit K. Ghosh. Shape Restricted Nonparametric Regression with Bernstein Polynomials. Computational Statistics & Data Analysis 2012;56:2729–41."
  },
  {
    "objectID": "software/gensplines/derivatives_and_integrals_of_spline_functions.html",
    "href": "software/gensplines/derivatives_and_integrals_of_spline_functions.html",
    "title": "Derivatives and integrals of spline functions.",
    "section": "",
    "text": "One advantage of using spline functions is that we get analytical expressions for the derivative and integral of the spline function.\nI will illustrate this using B-splines. I first generate some data and plot it.\n. clear\n\n. set obs 1000\nNumber of observations (_N) was 0, now 1,000.\n\n. range x 0 5\n\n. gen y = 2 + sin(x) + rnormal(0,0.1)\n\n. scatter y x, color(%30) ylabel(0(0.5)3.5, format(%3.1f))\n\nWe use B-splines to fit a non-linear function to this data and then obtain the derivative and integral of this function.\nIf our spline function estimate \\(f(x)\\), we can generate the derivative, \\(f'(x)\\) by obtaining the derivative of each spline variable w.r.t. \\(x\\).\nIn gensplines this is done by including the dgen() option.\n. gensplines x, type(bs) df(4) gen(_bs) dgen(_dbs)\n\n. global knots `r(knots)'\n\n. regress y _bs*\n\n      Source |       SS           df       MS      Number of obs   =     1,000\n-------------+----------------------------------   F(4, 995)       =  12637.11\n       Model |  501.188667         4  125.297167   Prob &gt; F        =    0.0000\n    Residual |  9.86543954       995  .009915015   R-squared       =    0.9807\n-------------+----------------------------------   Adj R-squared   =    0.9806\n       Total |  511.054106       999  .511565672   Root MSE        =    .09957\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        _bs1 |   1.179382   .0307769    38.32   0.000     1.118987    1.239777\n        _bs2 |   1.422978   .0239687    59.37   0.000     1.375943    1.470013\n        _bs3 |  -1.309876   .0273988   -47.81   0.000    -1.363642    -1.25611\n        _bs4 |  -.8256583   .0198255   -41.65   0.000     -.864563   -.7867537\n       _cons |    1.92711   .0150208   128.30   0.000     1.897634    1.956586\n------------------------------------------------------------------------------\n\n. predict mu\n(option xb assumed; fitted values)\nBelow I add the fitted regression line to the scatter plot\n. twoway (scatter y x, color(%30))         ///\n&gt;        (line mu x, sort),                ///\n&gt;        ylabel(0(0.5)3.5, format(%3.1f))  ///\n&gt;        legend(off)\n\nTo generate the dervative of the fitted function we can multipy the coefficients by the variables created by the dgen() option, the derivative of each spline variable w.r.t. \\(x\\)..\n. gen double deriv1 = _b[_bs1]*_dbs1 + _b[_bs2]*_dbs2 + _b[_bs3]*_dbs3 + _b[_bs4]*_dbs4      \nAs a comparison I calculate the derivatives numerically using the dydx command.\n. dydx mu x, gen(deriv2) double\n\n. compare deriv1 deriv2\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\nderiv1&lt;deriv2                 514     -2.23e-06    -6.57e-09   -1.11e-16\nderiv1=deriv2                   1\nderiv1&gt;deriv2                 485      1.39e-17     2.21e-08    8.32e-06\n                       ----------\nJointly defined              1000     -2.23e-06     7.35e-09    8.32e-06\n                       ----------\nTotal                        1000\nWe can plot the function and can see that the derivative is zero at the turning points of the original function.\n. line deriv2 x\n\nIn order to calculate the integral of the function we need to generate the integral of each of the spline variables. This can be done by using the type(ibs) option of gensplines. If we use df(4) as above, then the knots will be in exactly the same location. Alternatively, we could have saved the knots when we generated the original spline variables and used the allknots() option.\n. gensplines x, type(ibs) df(4) gen(_ibs) \nWe need to integrate the intercept and then incude the integrated spline functions and multiply each by the associated coefficient.\n. gen double integ1 = _b[_cons]*x + _b[_bs1]*_ibs1 + _b[_bs2]*_ibs2 + _b[_bs3]*_ibs3 + _b[_bs\n&gt; 4]*_ibs4      \nWe can compare to the numerically integrated function.\n. integ mu x, gen(integ2) double\n\nnumber of points = 1000\n\nintegral         = 10.73512\n\n. compare integ1 integ2\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\ninteg1&lt;integ2                   1     -1.38e-11    -1.38e-11   -1.38e-11\ninteg1=integ2                   1\ninteg1&gt;integ2                 998      1.05e-12     2.82e-12    8.18e-12\n                       ----------\nJointly defined              1000     -1.38e-11     2.80e-12    8.18e-12\n                       ----------\nTotal                        1000\nAnd plot the integral at each value of x.\n. line integ1 x\n\nIf we are just interested in the integral at one value of x, we just pass this value to gensplines. For example, the integral at x=5 is,\n. gensplines 5, type(ibs) allknots(${knots}) gen(_k) \n\n. lincom _b[_cons]*5 + _b[_bs1]*_k1 + _b[_bs2]*_k2 + _b[_bs3]*_k3 + _b[_bs4]*_k4\n\n ( 1)  1.25*_bs1 + 1.25*_bs2 + 1.25*_bs3 + .625*_bs4 + 5*_cons = 0\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n         (1) |   10.73512   .0157442   681.85   0.000     10.70422    10.76602\n------------------------------------------------------------------------------\nNote we also get a confidence interval for the integral as I used lincom.\nAdding the integral of the intercept can be avoided by generating an extra spline variable and then using the nonconstant option when fitting the model. Below I do this and then obtain the integral in a frame. By naming the integrated B-spline variables the same as the spline variables, I can use the predict command to obtain the integrated function.\n. drop _*\n\n. gensplines x, type(bs) df(4) gen(_bs) intercept\n\n. regress y _bs*, nocons\n\n      Source |       SS           df       MS      Number of obs   =     1,000\n-------------+----------------------------------   F(5, 995)       &gt;  99999.00\n       Model |  5108.18252         5   1021.6365   Prob &gt; F        =    0.0000\n    Residual |  9.86543954       995  .009915015   R-squared       =    0.9981\n-------------+----------------------------------   Adj R-squared   =    0.9981\n       Total |  5118.04796     1,000  5.11804796   Root MSE        =    .09957\n\n------------------------------------------------------------------------------\n           y | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        _bs1 |    1.92711   .0150208   128.30   0.000     1.897634    1.956586\n        _bs2 |   3.106492   .0191994   161.80   0.000     3.068816    3.144168\n        _bs3 |   3.350088   .0261145   128.28   0.000     3.298842    3.401334\n        _bs4 |   .6172346   .0191994    32.15   0.000     .5795586    .6549105\n        _bs5 |   1.101452   .0150208    73.33   0.000     1.071976    1.130928\n------------------------------------------------------------------------------\n\n.  \n. cap frame drop integral\n\n. frame put y x, into(integral)\n\n. frame integral {\n.   gensplines x, type(ibs) df(4) gen(_bs) intercept\n.   predict mu,\n(option xb assumed; fitted values)\n.   line mu x, ytitle(Integral of fitted values)\n. }"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Recent (and not so recent) Talks:\n30 August 2024 A practical approach to fitting cancer survival models when data can’t move across borders. Association of Nordic Cancer Registries (ANCR) Symposium 2024, Bodø, Norway\n7 June 2024 Recent developments in the fitting and assessment of flexible parametric survival models 2024 German Stata Conference, Mannheim, Germany.\n14th November 2023 Reference adjusted cancer survival measures What are they and when should they be used? 2023 ENCR-IACR Scientific Conference, Granada, Spain.\n12 October 2022 Improving fitting and predictions for flexible parametric survival models Northern European Stata Conference, Oslo, Norway.\n9 September 2022 Improving fitting and predictions for flexible parametric survival models 2022 UK Stata Conference, London, UK\n6 August 2021. Making Stata estimation commands faster through automatic differentiation and integration with Python. 2021 Stata Conference (online)\n18 February 2021. Regression standardization with time-to-event data to estimate marginal measures of association and causal effects using the standsurv command.. Stata Biostatistics and Epidemiology Virtual Symposium.\n22 September 2020. Standardised and reference adjusted all-cause and crude probabilities in the relative survival framework. Advances in Survival Analysis. International Biometric Society - British and Irish Region.\nAugust 2020 A marginal model for relative survival.. International Biometric Society 2020\n26 September 2019. Issues in Standardization. Symposium for statisticians working in register-based cancer epidemiology 2019, Stockholm, Sweden\n29 August 2019. Standardised crude probabilities of death to improve understanding of national and international cancer survival comparisons. Association of the Nordic Cancer Registries meeting 2019, Stockholm Sweden\n30 August 2019. Marginal estimates through regression standardization in competing risks and relative survival models. Nordic and Baltic Stata Users Group meeting 2019, Stockholm, Sweden."
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "When I worked at the University of Leicester my main teaching was on the MSc Medical Statistics course where I taught various modules including survival analysis, advanced survival analysis, statistical inference and computationally intensive methods. I was a student on this course way back in 1991.\nNow my teaching is mainly delivery of specialist courses."
  },
  {
    "objectID": "courses.html#upcoming-courses",
    "href": "courses.html#upcoming-courses",
    "title": "Courses",
    "section": "Upcoming courses",
    "text": "Upcoming courses\n\nJune 2025. We (Paul Dickman, Mark Rutherford, Therese Andersson and Betty Syriopoulou and I) hope to teach our 5-day course on statistical methods for population-based cancer survival analysis in Veneto Italy. Further details will be available here."
  },
  {
    "objectID": "courses.html#past-recent-courses",
    "href": "courses.html#past-recent-courses",
    "title": "Courses",
    "section": "Past (recent) courses",
    "text": "Past (recent) courses\n\n27 September 2024. Modelling survival data using flexible parametric models in Stata using stpm3: concepts and modelling choices. Internal course at Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden.\n9 September 2024. Modelling survival data using flexible parametric models in Stata using stpm3: concepts and modelling choices. Pre conference course at the 2024 Northern European Stata Conference."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "I have written a book with Patrick Royston titled Flexible parametric survival models using Stata: Beyond the Cox model.\n\nYou can download the datasets and code used in the book.\nA review of the book can be found here.\nWe are writing a second edition of the book with Mark Rutherford included as an additional author."
  },
  {
    "objectID": "publications.html#flexible-parametric-survival-models-using-stata-beyond-the-cox-model",
    "href": "publications.html#flexible-parametric-survival-models-using-stata-beyond-the-cox-model",
    "title": "Publications",
    "section": "",
    "text": "I have written a book with Patrick Royston titled Flexible parametric survival models using Stata: Beyond the Cox model.\n\nYou can download the datasets and code used in the book.\nA review of the book can be found here.\nWe are writing a second edition of the book with Mark Rutherford included as an additional author."
  },
  {
    "objectID": "publications.html#my-publications",
    "href": "publications.html#my-publications",
    "title": "Publications",
    "section": "My publications",
    "text": "My publications\nJohansson ALV, Kønig SM, Larønningen S, Engholm G, Kroman N, Seppä K, Malila N, Steig BÁ, Gudmundsdóttir EM, Ólafsdóttir EJ, Lundberg FE, Andersson TM-L, Lambert PC, Lambe M, Pettersson D, Aagnes B, Friis S, Storm H. Have the recent advancements in cancer therapy and survival benefitted patients of all age groups across the Nordic countries? NORDCAN survival analyses 2002-2021. Acta Oncologica 2024;63:179–91. https://doi.org/10.2340/1651-226X.2024.35094.\nLundberg FE, Birgisson H, Engholm G, Ólafsdóttir EJ, Mørch LS, Johannesen TB, Pettersson D, Lambe M, Seppä K, Lambert PC, Johansson ALV, Hölmich LR, Andersson TM-L. Survival trends for patients diagnosed with cutaneous malignant melanoma in the Nordic countries 1990-2016: The NORDCAN survival studies. European Journal of Cancer 2024;202:113980. https://doi.org/10.1016/j.ejca.2024.113980.\nHall M, Smith L, Wu J, Hayward C, Batty JA, Lambert PC, Hemingway H, Gale CP. Health outcomes after myocardial infarction: A population study of 56 million people in England. PLoS Medicine 2024;21:e1004343. https://doi.org/10.1371/journal.pmed.1004343.\nLee S, Lambert PC, Sweeting MJ, Latimer NR, Rutherford MJ. Evaluation of flexible parametric relative survival approaches for enforcing long-term constraints when extrapolating all-cause survival. Value in Health 2024;27:51–60. https://doi.org/10.1016/j.jval.2023.10.003.\nJennings AC, Rutherford MJ, Latimer NR, Sweeting MJ, Lambert PC. Perils of randomized controlled trial survival extrapolation assuming treatment effect waning: Why the distinction between marginal and conditional estimates matters. Value in Health 2023. https://doi.org/10.1016/j.jval.2023.12.008.\nLeontyeva Y, Lambe M, Bower H, Lambert PC, Andersson TM-L. Including uncertainty of the expected mortality rates in the prediction of loss in life expectancy. BMC Medical Research Methodology 2023;23:291. https://doi.org/10.1186/s12874-023-02118-w.\nWaterhouse JV, Welch CA, Battisti NML, Sweeting MJ, Paley L, Lambert PC, Deanfield J, Belder M de, Peake MD, Adlam D, Ring A. Geographical variation in underlying social deprivation, cardiovascular and other comorbidities in patients with potentially curable cancers in England: Results from a national registry dataset analysis. Clinical Oncology 2023;35:e709–19. https://doi.org/10.1016/j.clon.2023.08.009.\nBooth S, Mozumder SI, Archer L, Ensor J, Riley RD, Lambert PC, Rutherford MJ. Using temporal recalibration to improve the calibration of risk prediction models in competing risk settings when there are trends in survival over time. Statistics in Medicine 2023;30:5007–24. https://doi.org/10.1002/sim.9898.\nTyrer F, Chudasama YV, Lambert PC, Rutherford MJ. Flexible parametric methods for calculating life expectancy in small populations. Population Health Metrics 2023;21:13. https://doi.org/10.1186/s12963-023-00313-x.\nWells M, Rutherford MJ, Lambert PC. Fair comparisons of cause-specific and relative survival by accounting for the systematic removal of patients from risk-sets. Cancer Epidemiology 2023;86:102408. https://doi.org/10.1016/j.canep.2023.102408.\nSweeting MJ, Rutherford MJ, Jackson D, Lee S, Latimer NR, Hettle R, Lambert PC. Survival extrapolation incorporating general population mortality using excess hazard and cure models: A tutorial. Medical Decision Making 2023;43:737–48. https://doi.org/10.1177/0272989X231184247.\nMyklebust TÅa, Aagnes B, Nilssen Y, Rutherford M, Lambert PC, Andersson TML, Johansson ALV, Dickman PW, Møller B. Improving communication of cancer survival statistics-feasibility of implementing model-based algorithms in routine publications. British Journal of Cancer 2023;129:819–28. https://doi.org/10.1038/s41416-023-02360-5.\nTeece L, Sweeting MJ, Hall M, Coles B, Oliver-Williams C, Welch CA, Belder MA de, Deanfield J, Weston C, Rutherford MJ, Paley L, Kadam UT, Lambert PC, Peake MD, Gale CP, Adlam D, VICORI Collaborative. Impact of a prior cancer diagnosis on quality of care and survival following acute myocardial infarction: Retrospective population-based cohort study in England. Circulation Cardiovascular Quality and Outcomes 2023;16:e009236. https://doi.org/10.1161/CIRCOUTCOMES.122.009236.\nSkourlis N, Crowther MJ, Andersson TM-L, Lu D, Lambe M, Lambert PC. Exploring different research questions via complex multi-state models when using registry-based repeated prescriptions of antidepressants in women with breast cancer and a matched population comparison group. BMC Medical Research Methodology 2023;23:87. https://doi.org/10.1186/s12874-023-01905-9.\nColes B, Welch CA, Motiwale RS, Teece L, Oliver-Williams C, Weston C, Belder MA de, Lambert PC, Rutherford MJ, Paley L, Kadam UT, Lawson CA, Deanfield J, Peake MD, McDonagh T, Sweeting MJ, Adlam D, VICORI Collaborative. Acute heart failure presentation, management, and outcomes in cancer patients: A national longitudinal study. European Heart Journal Acute Cardiovascular Care 2023;12:315–27. https://doi.org/10.1093/ehjacc/zuad020.\nLundberg FE, Kroman N, Lambe M, Andersson TM-L, Engholm G, Johannesen TB, Virtanen A, Pettersson D, Ólafsdóttir EJ, Birgisson H, Lambert PC, Mørch LS, Johansson ALV. Age-specific survival trends and life-years lost in women with breast cancer 1990-2016: The NORDCAN survival studies. Acta Oncologica 2022;61:1481–9. https://doi.org/10.1080/0284186X.2022.2156811.\nBatyrbekova N, Bower H, Dickman PW, Ravn Landtblom A, Hultcrantz M, Szulkin R, Lambert PC, Andersson TM-L. Modelling multiple time-scales with flexible parametric survival models. BMC Medical Research Methodology 2022;22:290. https://doi.org/10.1186/s12874-022-01773-9.\nSyriopoulou E, Wästerlid T, Lambert PC, Andersson TM-L. Standardised survival probabilities: A useful and informative tool for reporting regression models for survival data. British Journal of Cancer 2022;127:1808–15. https://doi.org/10.1038/s41416-022-01949-6.\nLeontyeva Y, Bower H, Gauffin O, Lambert PC, Andersson TM-L. Assessing the impact of including variation in general population mortality on standard errors of relative survival and loss in life expectancy. BMC Medical Research Methodology 2022;22:130. https://doi.org/10.1186/s12874-022-01597-7.\nSyriopoulou E, Mozumder SI, Rutherford MJ, Lambert PC. Estimating causal effects in the presence of competing events using regression standardisation with the stata command standsurv. BMC Medical Research Methodology 2022;22:226. https://doi.org/10.1186/s12874-022-01666-x.\nSchmidt JCF, Lambert PC, Gillies CL, Sweeting MJ. Patterns of rates of mortality in the Clinical Practice Research Datalink. PloS One 2022;17:e0265709. https://doi.org/10.1371/journal.pone.0265709.\nLundberg FE, Birgisson H, Johannesen TB, Engholm G, Virtanen A, Pettersson D, Ólafsdóttir EJ, Lambe M, Lambert PC, Mørch LS, Johansson ALV, Andersson TM-L. Survival trends in patients diagnosed with colon and rectal cancer in the Nordic countries 1990-2016: The NORDCAN survival studies. European Journal of Cancer 2022;172:76–84. https://doi.org/10.1016/j.ejca.2022.05.032.\nBower H, Andersson TM-L, Crowther MJ, Lambert PC. Flexible parametric survival analysis with multiple timescales: Estimation and implementation using stmt. The Stata Journal 2022;22:679–701. https://doi.org/10.1177/1536867x221124552.\nSmith A, Lambert PC, Rutherford MJ. Generating high-fidelity synthetic time-to-event datasets to improve data transparency and accessibility. BMC Medical Research Methodology 2022;22:176. https://doi.org/10.1186/s12874-022-01654-1.\nStannard R, Lambert PC, Andersson TM-L, Rutherford MJ. Obtaining long-term stage-specific relative survival estimates in the presence of incomplete historical stage information. British Journal of Cancer 2022;127:1061–8. https://doi.org/10.1038/s41416-022-01866-8.\nSkourlis N, Crowther MJ, Andersson TM-L, Lambert PC. On the choice of timescale for other cause mortality in a competing risk setting using flexible parametric survival models. Biometrical Journal 2022;64:1161–77. https://doi.org/10.1002/bimj.202100254.\nAndersson TM-L, Rutherford MJ, Møller B, Lambert PC, Myklebust TÅ. Reference-adjusted loss in life expectancy for population-based cancer patient survival comparisons-with an application to colon cancer in Sweden. Cancer Epidemiology, Biomarkers & Prevention 2022;31:1720–6. https://doi.org/10.1158/1055-9965.EPI-22-0137.\nAndersson TM-L, Myklebust TÅ, Rutherford MJ, Møller B, Arnold M, Soerjomataram I, Bray F, Parkin DM, Lambert PC. Five ways to improve international comparisons of cancer survival: Lessons learned from ICBP SURVMARK-2. British Journal of Cancer 2022;126:1224–8. https://doi.org/10.1038/s41416-022-01701-0.\nRutherford MJ, Andersson TM-L, Myklebust TÅ, Møller B, Lambert PC. Non-parametric estimation of reference adjusted, standardised probabilities of all-cause death and death due to cancer for population group comparisons. BMC Medical Research Methodology 2022;22:2. https://doi.org/10.1186/s12874-021-01465-w.\nAndersson TM-L, Rutherford MJ, Myklebust TÅ, Møller B, Arnold M, Soerjomataram I, Bray F, Elkader HA, Engholm G, Huws D, Little A, Shack L, Walsh PM, Woods RR, Parkin DM, Lambert PC. A way to explore the existence of “immortals” in cancer registry data - an illustration using data from ICBP SURVMARK-2. Cancer Epidemiology 2022;76:102085. https://doi.org/10.1016/j.canep.2021.102085.\nLee SF, Vellayappan BA, Wong LC, Chiang CL, Chan SK, Wan EY-F, Wong IC-K, Lambert PC, Rachet B, Ng AK, Luque-Fernandez MA. Cardiovascular diseases among diffuse large b-cell lymphoma long-term survivors in asia: A multistate model study. ESMO Open 2022;7:100363. https://doi.org/10.1016/j.esmoop.2021.100363.\nRiley RD, Collins GS, Ensor J, Archer L, Booth S, Mozumder SI, Rutherford MJ, Smeden M van, Lambert PC, Snell KIE. Minimum sample size calculations for external validation of a clinical prediction model with a time-to-event outcome. Statistics in Medicine 2021;41:1280–95. https://doi.org/10.1002/sim.9275.\nSkourlis N, Crowther MJ, Andersson TM-L, Lambert PC. Development of a dynamic interactive web tool to enhance understanding of multi-state model analyses: MSMplus. BMC Medical Research Methodology 2021;21:262. https://doi.org/10.1186/s12874-021-01420-9.\nSyriopoulou E, Rutherford MJ, Lambert PC. Inverse probability weighting and doubly robust standardization in the relative survival framework. Statistics in Medicine 2021;40:6069–92. https://doi.org/10.1002/sim.9171.\nSweeting MJ, Oliver-Williams C, Teece L, Welch CA, Belder MA de, Coles B, Lambert PC, Paley L, Rutherford MJ, Elliss-Brookes L, Deanfield J, Peake MD, Adlam D. Data resource profile: The Virtual Cardio-Oncology Research Initiative (VICORI) linking national English cancer registration and cardiovascular audits. International Journal of Epidemiology 2022;50:1768–79. https://doi.org/10.1093/ije/dyab082.\nColes B, Teece L, Weston C, Belder MA de, Oliver-Williams C, Welch CA, Rutherford MJ, Lambert PC, Bidulka P, Paley L, Nitsch D, Deanfield J, Peake MD, Adlam D, Sweeting MJ, collaborative V. Case-ascertainment of acute myocardial infarction hospitalisations in cancer patients: A cohort study using English linked electronic health data. European Heart Journal Quality of Care & Clinical Outcomes 2021;8:86–95. https://doi.org/10.1093/ehjqcco/qcab045.\nLambert PC, Syriopoulou E, Rutherford MJ. Direct modelling of age standardized marginal relative survival through incorporation of time-dependent weights. BMC Medical Research Methodology 2021;21:84. https://doi.org/10.1186/s12874-021-01266-1.\nMozumder SI, Rutherford MJ, Lambert PC. Estimating restricted mean survival time and expected life-years lost in the presence of competing risks within flexible parametric survival models. BMC Medical Research Methodology 2021;21:52. https://doi.org/10.1186/s12874-021-01213-0.\nEnsor J, Snell KIE, Debray TPA, Lambert PC, Look MP, Mamas MA, Moons KGM, Riley RD. Individual participant data meta-analysis for external validation, recalibration, and updating of a flexible parametric prognostic model. Statistics in Medicine 2021;40:3066–84. https://doi.org/10.1002/sim.8959.\nHill M, Lambert PC, Crowther MJ. Relaxing the assumption of constant transition rates in a multi-state model in hospital epidemiology. BMC Medical Research Methodology 2021;21:16. https://doi.org/10.1186/s12874-020-01192-8.\nWeibull CE, Lambert PC, Eloranta S, Andersson TM-L, Dickman PW, Crowther MJ. A multistate model incorporating estimation of excess hazards and multiple time scales. Statistics in Medicine 2021;40:2139–54. https://doi.org/10.1002/sim.8894.\nAndersson TM-L, Rutherford MJ, Myklebust TÅ, Møller B, Soerjomataram I, Arnold M, Bray F, Parkin DM, Sasieni P, Bucher O, De P, Engholm G, Gavin A, Little A, Porter G, Ramanakumar AV, Saint-Jacques N, Walsh PM, Woods RR, Lambert PC. Exploring the impact of cancer registry completeness on international cancer survival differences: A simulation study. British Journal of Cancer 2021;124:1026–32. https://doi.org/10.1038/s41416-020-01196-7.\nRutherford MJ, Lambert PC, Sweeting MJ, Pennington B, Crowther MJ, Abrams KR, Latime NR. NICE DSU TECHNICAL SUPPORT DOCUMENT 21: Flexible methods for survival analysis. Decision Support Unit, University of Sheffield 2021.\nAndersson TM-L, Myklebust TÅ, Rutherford MJ, Møller B, Soerjomataram I, Arnold M, Bray F, Parkin DM, Sasieni P, Bucher O, De P, Engholm G, Gavin A, Little A, Porter G, Ramanakumar AV, Saint-Jacques N, Walsh PM, Woods RR, Lambert PC. The impact of excluding or including Death Certificate Initiated (DCI) cases on estimated cancer survival: A simulation study. Cancer Epidemiology 2021;71:101881. https://doi.org/10.1016/j.canep.2020.101881.\nSyriopoulou E, Rutherford MJ, Lambert PC. Understanding disparities in cancer prognosis: An extension of mediation analysis to the relative survival framework. Biometrical Journal 2021;63:341–53. https://doi.org/10.1002/bimj.201900355.\nSmith AJ, Lambert PC, Rutherford MJ. Understanding the impact of sex and stage differences on melanoma cancer patient survival: A SEER-based study. British Journal of Cancer 2021;1124:671–7. https://doi.org/10.1038/s41416-020-01144-5.\nLundberg FE, Andersson TM-L, Lambe M, Engholm G, Mørch LS, Johannesen TB, Virtanen A, Pettersson D, Olafsdottir EJ, Birgisson H, Johansson ALV, Lambert PC. Trends in cancer survival in the Nordic countries 1990-2016: The NORDCAN survival studies. Acta Oncologica 2020;59:1266–74. https://doi.org/10.1080/0284186X.2020.1822544.\nLambert PC, Andersson TM-L, Rutherford MJ, Myklebust TÅ, Møller B. Reference-adjusted and standardized all-cause and crude probabilities as an alternative to net survival in population-based cancer studies. International Journal of Epidemiology 2020;49:1614–23. https://doi.org/10.1093/ije/dyaa112.\nMyklebust TÅ, Andersson TM-L, Bardot A, Vernon S, Gavin A, Fitzpatrick D, Jerm MB, Rutherford MJ, Parkin DM, Sasieni P, Arnold M, Soerjomataram I, Bray F, Lambert PC, Møller B. Can different definitions of date of cancer incidence explain observed international variation in cancer survival? An ICBP SURVMARK-2 study. Cancer Epidemiology 2020;67:101759. https://doi.org/10.1016/j.canep.2020.101759.\nRutherford MJ, Dickman PW, Coviello E, Lambert PC. Estimation of age-standardized net survival, even when age-specific data are sparse. Cancer Epidemiology 2020;67:101745. https://doi.org/10.1016/j.canep.2020.101745.\nWelch CA, Sweeting MJ, Lambert PC, Rutherford MJ, Jack RH, West D, Adlam D, Peake M. Impact on survival of modelling increased surgical resection rates in patients with non-small-cell lung cancer and cardiovascular comorbidities: A VICORI study. British Journal of Cancer 2020;123:471–9. https://doi.org/10.1038/s41416-020-0869-8.\nBooth S, Riley RD, Ensor J, Lambert PC, Rutherford MJ. Temporal recalibration for improving prognostic model development and risk predictions in settings where survival is improving over time. International Journal of Epidemiology 2020;49:1316–25. https://doi.org/10.1093/ije/dyaa030.\nSyriopoulou E, Rutherford MJ, Lambert PC. Marginal measures and causal effects using the relative survival framework. International Journal of Epidemiology 2020;49:619–28. https://doi.org/10.1093/ije/dyz268.\nArnold M, Rutherford MJ, Bardot A, Ferlay J, Andersson TM, Myklebust TÅ, Tervonen H, Thursfield V, Ransom D, Shack L, Woods RR, Turner D, Leonfellner S, Ryan S, Saint-Jacques N, De P, McClure C, Ramanakumar AV, Stuart-Panko H, Engholm G, Walsh PM, Jackson C, Vernon S, Morgan E, Gavin A, Morrison DS, Huws DW, Porter G, Butler J, Bryant H, Currow DC, Hiom S, Parkin DM, Sasieni P, Lambert PC, Möller B, Soerjomataram I, Bray F. Progress in cancer survival, mortality, and incidence in seven high-income countries 1995-2014 (ICBP SURVMARK-2): A population-based study. Lancet Oncology 2019;20:1493–505.\nWong KF, Lambert PC, Mozumder SI, Broggio J, Rutherford MJ. Conditional crude probabilities of death for English cancer patients. British Journal of Cancer 2019;121:883–9. https://doi.org/10.1038/s41416-019-0597-0.\nAndersson TM-L, Rutherford MJ, Lambert PC. Illustration of different modelling assumptions for estimation of loss in expectation of life due to cancer. BMC Medical Research Methodology 2019;19:19. https://doi.org/https://doi.org/10.1186/s12874-019-0785-x.\nBower H, Crowther MJ, Rutherford MJ, Andersson TML, Clements M, Liu XR, Dickman PW, Lambert PC. Capturing simple and complex time-dependent effects using flexible parametric survival models: Communications in Statistics - Simulation and Computation 2019. https://doi.org/https://doi.org/10.1080/03610918.2019.1634201.\nSyriopoulou E, Morris E, P. F, Lambert PC, Rutherford MJ. Understanding the impact of socioeconomic differences in colorectal cancer survival: Potential gain in life-years. British Journal of Cancer 2019;120:1052–8. https://doi.org/10.1038/s41416-019-0455-0.\nRutherford MJ, Andersson TM-L, Björkholm M, Lambert PC. Loss in life expectancy and gain in life years as measures of cancer impact. Cancer Epidemiology 2019;60:168–73. https://doi.org/10.1016/j.canep.2019.04.005.\nBower H, Andersson TM-L, Syriopoulou E, Rutherford MJ, Lambe M, Ahlgren J, Dickman PW, Lambert PC. Potential gain in life years for Swedish women with breast cancer if stage and survival differences between education groups could be eliminated - three what-if scenarios. Breast 2019;45:75–81. https://doi.org/10.1016/j.breast.2019.03.005.\nWeibull CE, Björkholm M, Glimelius I, Lambert PC, Andersson TM-L, Smedby KE, Dickman PW, Eloranta S. Temporal trends in treatment-related incidence of diseases of the circulatory system among Hodgkin lymphoma patients. International Journal of Cancer 2019;145:1200–8. https://doi.org/10.1002/ijc.32142.\nSyriopoulou E, Mozumder SI, Rutherford MJ, Lambert PC. Robustness of individual and marginal model-based estimates: A sensitivity analysis of flexible parametric models. Cancer Epidemiology 2018;58:17–24. https://doi.org/10.1016/j.canep.2018.10.017.\nPlym A, Bower H, Fredriksson I, Holmberg L, Lambert PC, Lambe M. Loss in working years after a breast cancer diagnosis. British Journal of Cancer 2018;118:738–43. https://doi.org/10.1038/bjc.2017.456.\nMozumder SI, Dickman PW, Rutherford MJ, Lambert PC. InterPreT cancer survival: A dynamic web interactive prediction cancer survival tool for health-care professionals and cancer epidemiologists. Cancer Epidemiology 2018;56:46–52. https://doi.org/10.1016/j.canep.2018.07.009.\nWeibull CE, Johansson ALV, Eloranta S, Smedby KaE, Björkholm M, Lambert PC, Dickman PW, Glimelius I. Contemporarily treated patients with Hodgkin lymphoma have childbearing potential in line with matched comparators. Journal of Clinical Oncology 2018;36:2718–25. https://doi.org/10.1200/JCO.2018.78.3514.\nLatimer NR, Abrams KR, Lambert PC, Morden JP, Crowther MJ. Assessing methods for dealing with treatment switching in clinical trials: A follow-up simulation study. Statistical Methods in Medical Research 2018;27:765–84. https://doi.org/10.1177/0962280216642264.\nMozumder SI, Rutherford MJ, Lambert PC. A flexible parametric competing-risks model using a direct likelihood approach for the cause-specific cumulative incidence function. The Stata Journal 2017;17:462–89. https://doi.org/10.1177/1536867x1701700212.\nMozumder SI, Lambert PC, Rutherford MJ. Direct likelihood inference on the cause-specific cumulative incidence function: A flexible parametric regression modelling approach. Statistics in Medicine 2018;37:82–97. https://doi.org/10.1002/sim.7498.\nBower H, Andersson TM-L, Crowther MJ, Dickman PW, Lambe M, Lambert PC. Adjusting expected mortality rates using information from a control population: An example using socioeconomic status. American Journal of Epidemiology 2018;187:828–36. https://doi.org/10.1093/aje/kwx303.\nLatimer NR, Abrams KR, Lambert PC, Crowther MJ, Wailoo AJ, Morden JP, Akehurst RL, Campbell MJ. Adjusting for treatment switching in randomised controlled trials - a simulation study and a simplified two-stage method. Statistical Methods in Medical Research 2017;26:724–51. https://doi.org/10.1177/0962280214557578.\nPeters TL, Weibull CE, Fang F, Sandler DP, Lambert PC, Ye W, Kamel F. Association of fractures with the incidence of amyotrophic lateral sclerosis. Amyotrophic Lateral Sclerosis & Frontotemporal Degeneration 2017;18:419–25. https://doi.org/10.1080/21678421.2017.1300287.\nCrowther MJ, Lambert PC. Parametric multi-state survival models: Flexible modelling allowing transition-specific distributions with application to estimating clinically useful measures of effect differences. Statistics in Medicine 2017;36:4719–42. https://doi.org/10.1002/sim.7448.\nCramb SM, Mengersen KL, Lambert PC, Ryan LM, Baade PD. A flexible parametric approach to examining spatial variation in relative survival. Statistics in Medicine 2016;35:5448–63. https://doi.org/10.1002/sim.7071.\nLambert PC. The estimation and modelling of cause-specific cumulative incidence functions using time-dependent weights. The Stata Journal 2017;17:181–207.\nLambert PC, Wilkes SR, Crowther MJ. Flexible parametric modelling of the cause-specific cumulative incidence function. Statistics in Medicine 2017;36:1429–46. https://doi.org/10.1002/sim.7208.\nSyriopoulou E, Bower H, Andersson TM-L, Lambert PC, Rutherford MJ. Estimating the impact of a cancer diagnosis on life expectancy by socio-economic group for a range of cancer types in England. British Journal of Cancer 2017;117:1419–26. https://doi.org/10.1038/bjc.2017.300.\nBower H, Andersson TML, Bjorkholm M, Dickman PW, Lambert PC, Derolf AR. Continued improvement in survival of acute myeloid leukemia patients: An application of the loss in expectation of life. Blood Cancer Journal 2016;6:e390. https://doi.org/10.1038/bcj.2016.3.\nBower H, Björkholm M, Dickman PW, Höglund M, Lambert PC, Andersson TM-L. Life expectancy of chronic myeloid leukemia patients is approaching the life expectancy of the general population. Journal of Clinical Oncology 2016;34:2851–7. https://doi.org/10.1200/JCO.2015.66.2866.\nBower H, Crowther MJ, Lambert PC. strcs: A command for fitting flexible parametric survival models on the log-hazard scale. The Stata Journal 2016;16:989–1012. https://doi.org/10.1177/1536867X1601600410.\nEdgren G, Hjalgrim H, Rostgaard K, Lambert PC, Wikman A, Norda R, Titlestad K-E, Erikstrup C, Ullum H, Melbye M, Busch MP, Nyrón O. Transmission of neurodegenerative disorders through blood transfusion: A cohort study. Annals of Internal Medicine 2016;165:316–24. https://doi.org/10.7326/M15-2421.\nCrowther MJ, Andersson TM-L, Lambert PC, Abrams KR, Humphreys K. Joint modelling of longitudinal and survival data: Incorporating delayed entry and an assessment of model misspecification. Statistics in Medicine 2016;35:1193–209. https://doi.org/10.1002/sim.6779.\nAndersson TM-L, Dickman PW, Eloranta S, Sjövall A, Lambe M, Lambert PC. The loss in expectation of life after colon cancer: A population-based study. BMC Cancer 2015;15:412. https://doi.org/10.1186/s12885-015-1427-2.\nHultcrantz M, Wilkes SR, Kristensson SY, Andersson TM-L, Derolf A, Eloranta S, O. OL, Lambert PC, Björkholm M. Risk and cause of death in 9,285 patients diagnosed with myeloproliferative neoplasms in Sweden between 1973 and 2005. A population-based study. Journal of Clinical Oncology 2015;33:2288–95. https://doi.org/10.1200/JCO.2014.57.6652.\nRutherford MJ, Abel GA, Greenberg DC, Lambert PC, Lyratzopoulos G. The impact of eliminating age inequalities in stage at diagnosis on breast cancer survival for older women. British Journal of Cancer 2015;112:S124–8. https://doi.org/10.1038/bjc.2015.51.\nRutherford MJ, Ironmonger L, Ormiston-Smith N, Abel GA, Greenberg DC, Lyratzopoulos G, Lambert PC. Estimating the potential survival gains by eliminating socioeconomic and sex inequalities in stage at diagnosis of melanoma. British Journal of Cancer 2015;112 Suppl:S116–23. https://doi.org/10.1038/bjc.2015.50.\nCrowther MJ, Lambert PC. Reply to letter to the Editor by Remontet et al. Statistics in Medicine 2015;34:3378–80. https://doi.org/10.1002/sim.6606.\nLambert PC, Dickman PW, Rutherford MJ. Comparison of approaches to estimating age-standardized net survival. BMC Med Res Methodol 2015;15:64. https://doi.org/10.1186/s12874-015-0057-3.\nRutherford MJ, Andersson TM-L, Møller H, Lambert PC. Understanding the impact of socioeconomic differences in breast cancer survival in England and Wales: Avoidable deaths and potential gain in expectation of life. Cancer Epidemiology 2015;39:118–25. https://doi.org/10.1016/j.canep.2014.11.002.\nRutherford MJ, Crowther MJ, Lambert PC. The use of restricted cubic splines to approximate complex hazard functions in the analysis of time-to-event data: A simulation study. Journal of Statistical Computation and Simulation 2015;85:777–93. https://doi.org/10.1080/00949655.2013.845890.\nCrowther MJ, Lambert PC. A general framework for parametric survival analysis. Statistics in Medicine 2014;33:5280–97. https://doi.org/10.1002/sim.6300.\nEloranta S, Lambert PC, Andersson TM-L, Björkholm M, Dickman PW. The application of cure models in the presence of competing risks: A tool for improved risk communication in population-based cancer patient survival. Epidemiology 2014;25:742–8. https://doi.org/10.1097/EDE.0000000000000130.\nFeldman AL, Johansson ALV, Lambert PC, Sieurin J, Yang F, Pedersen NL, Wirdefeldt K. Familial coaggregation of alzheimer’s disease and parkinson’s disease: Systematic review and meta-analysis. Neuroepidemiology 2014;42:69–80. https://doi.org/10.1159/000355452.\nGao H, Hägg S, Sjögren P, Lambert PC, Ingelsson E, Dam RM van. Serum selenium in relation to measures of glucose metabolism and incidence of type 2 diabetes in an older swedish population. Diabetic Medicine : A Journal of the British Diabetic Association 2014;31:787–93. https://doi.org/10.1111/dme.12429.\nLatimer NR, Abrams KR, Lambert PC, Crowther MJ, Wailoo AJ, Morden JP, Akehurst RL, Campbell MJ. Adjusting survival time estimates to account for treatment switching in randomized controlled trials–an economic evaluation context: Methods, limitations, and recommendations. Medical Decision Making 2014;34:387–402. https://doi.org/10.1177/0272989X13520192.\nAndersson TM-L, Eriksson H, Hansson J, Månsson-Brahme E, Dickman PW, Eloranta S, Lambe M, Lambert PC. Estimating the cure proportion of malignant melanoma, an alternative approach to assess long term survival: A population-based study. Cancer Epidemiology 2014;38:93–9. https://doi.org/10.1016/j.canep.2013.12.006.\nAndersson TM-L, Dickman PW, Eloranta S, Lambe M, Lambert PC. Estimating the loss in expectation of life due to cancer using flexible parametric survival models. Statistics in Medicine 2013;32:5286–300. https://doi.org/10.1002/sim.5943.\nAhyow LC, Lambert PC, Jenkins DR, Neal KR, Tobin M. Bed occupancy rates and hospital-acquired clostridium difficile infection: A cohort study. Infection Control and Hospital Epidemiology 2013;34:1062–9. https://doi.org/10.1086/673156.\nCrowther MJ, Abrams KR, Lambert PC. Joint modelling of longitudinal and survival data. The Stata Journal 2013;13:165–84.\nCrowther MJ, Lambert PC. Stgenreg: A stata package for general parametric survival analysis. Journal of Statistical Software 2013;53:1–17. https://doi.org/10.18637/jss.v053.i12.\nCrowther MJ, Lambert PC. Simulating biologically plausible complex survival data. Statistics in Medicine 2013;32:4118–34. https://doi.org/10.1002/sim.5823.\nCrowther MJ, Lambert PC, Abrams KR. Adjusting for measurement error in baseline prognostic biomarkers included in a time-to-event analysis: A joint modelling approach. BMC Medical Research Methodology 2013;13:146. https://doi.org/10.1186/1471-2288-13-146.\nCvancarova M, Aagnes B, Fosså SD, Lambert PC, Møller B, Bray F. Proportion cured models applied to 23 cancer sites in norway. International Journal of Cancer 2012;132:1700–10. https://doi.org/10.1002/ijc.27802.\nEloranta S, Adolfsson J, Lambert PC, Stattin P, Akre O, Andersson TM-L, Dickman PW. How can we make cancer survival statistics more useful for patients and clinicians: An illustration using localized prostate cancer in Sweden. Cancer Causes Control 2013;24:505–15. https://doi.org/10.1007/s10552-012-0141-5.\nEloranta S, Lambert PC, Sjöberg J, Andersson TM-L, Björkholm M, Dickman PW. Temporal trends in mortality from diseases of the circulatory system after treatment for Hodgkin lymphoma: A population-based cohort study in Sweden (1973 to 2006). Journal of Clinical Oncology 2013;31:1435–41. https://doi.org/10.1200/JCO.2012.45.2714.\nHinchliffe SR, Abrams KR, Lambert PC. The impact of under and over-recording of cancer on death certificates in a competing risks analysis: A simulation study. Cancer Epidemiology 2013;37:11–9. https://doi.org/10.1016/j.canep.2012.08.012.\nHinchliffe SR, Lambert PC. Flexible parametric modelling of cause-specific hazards to estimate cumulative incidence functions. BMC Medical Research Methodology 2013;13:13. https://doi.org/10.1186/1471-2288-13-13.\nHinchliffe SR, Lambert PC. Extending the flexible parametric survival model for competing risks. The Stata Journal 2013;13:344–55.\nHinchliffe SR, Scott DA, Lambert PC. Flexible parametric illness-death models. The Stata Journal 2013;13:759–75.\nHinchliffe SR, Seaton SE, Lambert PC, Draper ES, Field DJ, Manktelow BN. Modelling time to death or discharge in neonatal care: An application of competing risks. Paediatr Perinat Epidemiol 2013;27:426–33. https://doi.org/10.1111/ppe.12053.\nRutherford MJ, Hinchliffe SR, Abel GA, Lyratzopoulos G, Lambert PC, Greenberg DC. How much of the deprivation gap in cancer survival can be explained by variation in stage at diagnosis: An example from breast cancer in the East of England. International Journal of Cancer 2013;133:2192–200. https://doi.org/10.1002/ijc.28221.\nRutherford MJ, Møller H, Lambert PC. A comprehensive assessment of the impact of errors in the cancer registration process on 1- and 5-year relative survival estimates. British Journal of Cancer 2013;108:691–8. https://doi.org/10.1038/bjc.2013.12.\nDickman PW, Lambert PC, Coviello E, Rutherford MJ. Estimating net survival in population-based cancer studies. International Journal of Cancer 2013;133:519–21. https://doi.org/10.1002/ijc.28041.\nShah A, Andersson TM-L, Rachet B, Björkholm M, Lambert PC. Survival and cure of acute myeloid leukaemia in England, 1971-2006: A population-based study. British Journal of Haematology 2013;162:509–16. https://doi.org/10.1111/bjh.12425.\nYu XQ, De Angelis R, Andersson TML, Lambert PC, O’Connell DL, Dickman PW. Estimating the proportion cured of cancer: Some practical advice for users. Cancer Epidemiology 2013;37:836–42. https://doi.org/10.1016/j.canep.2013.08.014.\nAndersson TM-L, Lambert PC. Fitting and modeling cure in population-based cancer studies within the framework of flexible parametric survival models. The Stata Journal 2012;12:623–8.\nAndrae B, Andersson TM-L, Lambert PC, Kemetli L, Silfverdal L, Strander B, Ryd W, Dillner J, Törnberg S, Sparén P. Screening and cervical cancer cure: Population based cohort study. BMJ 2012;344:e900. https://doi.org/10.1136/bmj.e900.\nCrowther MJ, Abrams KR, Lambert PC. Flexible parametric joint modelling of longitudinal and survival data. Statistics in Medicine 2012;31:4456–71. https://doi.org/10.1002/sim.5644.\nCrowther MJ, Lambert PC. Simulating complex survival data. The Stata Journal 2012;12:674–87.\nCrowther MJ, Riley RD, Staessen JA, Wang J, Gueyffier F, Lambert PC. Individual patient data meta-analysis of survival data using Poisson regression models. BMC Medical Research Methodology 2012;12:34. https://doi.org/10.1186/1471-2288-12-34.\nEloranta S, Lambert PC, Andersson TM-L, Czene K, Hall P, Björkholm M, Dickman PW. Partitioning of excess mortality in population-based cancer patient survival studies using flexible parametric survival models. BMC Medical Research Methodology 2012;12:86. https://doi.org/10.1186/1471-2288-12-86.\nHinchliffe SR, Dickman PW, Lambert PC. Adjusting for the proportion of cancer deaths in the general population when using relative survival: A sensitivity analysis. Cancer Epidemiology 2012;36:148–52. https://doi.org/10.1016/j.canep.2011.09.007.\nHinchliffe SR, Rutherford MJ, Crowther MJ, Nelson CP, Lambert PC. Should relative survival be used with lung cancer data? British Journal of Cancer 2012;106:1854–9. https://doi.org/10.1038/bjc.2012.182.\nHolmberg L, Robinson D, Sandin F, Bray F, Linklater KM, Klint A, Lambert PC, Adolfsson J, Hamdy FC, Catto J, Møller H. A comparison of prostate cancer survival in England, Norway and Sweden: A population-based study. Cancer Epidemiology 2012;36:e7–12. https://doi.org/10.1016/j.canep.2011.08.001.\nMøller H, Sandin F, Robinson D, Bray F, Klint S, Linklater KM, Lambert PC, Påhlman L, Holmberg L, Morris E. Colorectal cancer survival in socioeconomic groups in England: Variation is mainly in the short term after diagnosis. European Journal of Cancer 2012;48:46–53. https://doi.org/10.1016/j.ejca.2011.05.018.\nRutherford MJ, Dickman PW, Lambert PC. Comparison of methods for calculating relative survival in population-based studies. Cancer Epidemiology 2012;36:16–21. https://doi.org/10.1016/j.canep.2011.05.010.\nRutherford MJ, Thompson JR, Lambert PC. Projecting cancer incidence using age-period-cohort models incorporating restricted cubic splines. International Journal of Biostatistics 2012;8:33. https://doi.org/10.1515/1557-4679.1411.\nShack LG, Shah A, Lambert PC, Rachet B. Cure by age and stage at diagnosis for colorectal cancer patients in North West England, 1997-2004: A population-based study. Cancer Epidemiology 2012;36:548–53. https://doi.org/10.1016/j.canep.2012.06.011.\nAndersson TM-L, Dickman PW, Eloranta S, Lambert PC. Estimating and modelling cure in population-based cancer studies within the framework of flexible parametric survival models. BMC Medical Research Methodology 2011;11:96. https://doi.org/10.1186/1471-2288-11-96.\nEaker S, Wigertz A, Lambert PC, Bergkvist L, Ahlgren J, Lambe M, Uppsala/Örebro Breast Cancer Group. Breast cancer, sickness absence, income and marital status. A study on life situation 1 year prior diagnosis compared to 3 and 5 years after diagnosis. PLoS One 2011;6:e18040. https://doi.org/10.1371/journal.pone.0018040.\nHakulinen T, Seppä K, Lambert PC. Choosing the relative survival method for cancer survival estimation. European Journal of Cancer 2011;47:2202–10. https://doi.org/10.1016/j.ejca.2011.03.011.\nLambert PC, Holmberg L, Sandin F, Bray F, Linklater KM, Purushotham A, Robinson D, Møller H. Quantifying differences in breast cancer survival between England and Norway. Cancer Epidemiology 2011;35:526–33. https://doi.org/10.1016/j.canep.2011.04.003.\nColeman MP, Rachet B, Woods L, Berrino F, Butler J, Capocaccia R, Dickman PW, Gavin A, Giorgi R, Hamilton W, Lambert PC, Peake MD, Perme MP, Stare J, Vedstedt P. Rebuttal to editorial saying cancer survival statistics are misleading. BMJ 2011;343:d4214. https://doi.org/10.1136/bmj.d4214.\nMorden JP, Lambert PC, Latimer N, Abrams KR, Wailoo AJ. Assessing methods for dealing with treatment switching in randomised controlled trials: A simulation study. BMC Medical Research Methodology 2011;11:572–82. https://doi.org/10.1093/biostatistics/kxq007.\nMorris EJA, Sandin F, Lambert PC, Bray F, Klint Å, Linklater K, Robinson D, Påhlman L, Holmberg L, Møller H. A population-based comparison of the survival of patients with colorectal cancer in England, Norway and Sweden between 1996 and 2004. Gut 2011;60:1087–93. https://doi.org/10.1136/gut.2010.229575.\nAndersson TM-L, Lambert PC, Derolf AR, Kristinsson SY, Eloranta S, Landgren O, Björkholm M, Dickman PW. Temporal trends in the proportion cured among adults diagnosed with acute myeloid leukaemia in Sweden 1973-2001, a population-based study. Br J Haematol 2010;148:918–24. https://doi.org/10.1111/j.1365-2141.2009.08026.x.\nEloranta S, Lambert PC, Cavalli-Björkman N, Andersson TM-L, Glimelius B, Dickman PW. Does socioeconomic status influence the prospect of cure from colon cancer–a population-based study in Sweden 1965-2000. European Journal of Cancer 2010;46:2965–72. https://doi.org/10.1016/j.ejca.2010.05.028.\nLambert PC, Dickman PW, Nelson CP, Royston P. Estimating the crude probability of death due to cancer and other causes using relative survival models. Statistics in Medicine 2010;29:885–95. https://doi.org/10.1002/sim.3762.\nLambert PC, Dickman PW, Weston CL, Thompson JR. Estimating the cure fraction in population-based cancer studies by using finite mixture models. Journal of the Royal Statistical Society, Series C 2010;59:35–55. https://doi.org/10.1111/j.1467-9876.2009.00677.x.\nRiley RD, Lambert PC, Abo-Zaid G. Meta-analysis of individual participant data: Rationale, conduct, and reporting. BMJ 2010;340:c221. https://doi.org/10.1136/bmj.c221.\nRutherford MJ, Lambert PC, Thompson JR. Age-period-cohort modelling. The Stata Journal 2010;10:606–27. https://doi.org/10.1038/bjc.2015.51.\nSquire IB, Nelson CP, Ng LL, Jones DR, Woods KL, Lambert PC. Prognostic value of admission blood glucose concentration and diabetes diagnosis on survival after acute myocardial infarction; results from 4702 index cases in routine practice. Clinical Science 2010;118:527–35. https://doi.org/10.1042/CS20090322.\nLambert PC, Royston P. Further development of flexible parametric models for survival analysis. The Stata Journal 2009;9:265–90.\nLarfors G, Lambert PC, Lambe M, Ekbom A, Cnattingius S. Placental weight and breast cancer survival in young women. Cancer Epidemiol Biomarkers Prev 2009;18:777–83. https://doi.org/10.1158/1055-9965.EPI-08-0979.\nPanickar J, Lakhanpaul M, Lambert PC, Kenia P, Stephenson T, Smyth A, Grigg J. Oral prednisolone for preschool children with acute virus-induced wheezing. New England Journal of Medicine 2009;360:329–38. https://doi.org/10.1056/NEJMoa0804897.\nWoods LM, Rachet B, Lambert PC, Coleman MP. ‘Cure’ from breast cancer among two populations of women followed for 23 years after diagnosis. Annals of Oncology 2009;20:1331–6. https://doi.org/10.1093/annonc/mdn791.\nBhaskaran K, Hamouda O, Sannes M, Boufassa F, Johnson AM, Lambert PC, Porter K, CASCADE Collaboration. Changes in the risk of death after HIV seroconversion compared with mortality in the general population. JAMA 2008;300:51–9. https://doi.org/10.1001/jama.300.1.51.\nGillies CL, Lambert PC, Abrams KR, Sutton AJ, Cooper NJ, Hsu RT, Davies MJ, Khunti K. Different strategies for screening and prevention of type 2 diabetes in adults: Cost effectiveness analysis. BMJ 2008;336:1180–5. https://doi.org/10.1136/bmj.39545.585289.25.\nLambert PC, Billingham LJ, Cooper NJ, Sutton AJ, Abrams KR. Estimating the cost-effectiveness of an intervention in a clinical trial when partial cost information is available: A Bayesian approach. Health Economics 2008;17:67–81. https://doi.org/10.1002/hec.1243.\nNelson CP, Lambert PC, Squire IB, Jones DR. Relative survival: What can cardiovascular disease learn from cancer? European Heart Journal 2008;29:941–7. https://doi.org/10.1093/eurheartj/ehn079.\nLambert PC, Sutton AJ, Burton PR, Abrams KR, Jones DR. Comments on ’trying to be precise about vagueness’ by stephen senn, statistics in medicine 2007; 26:1417-1430. Statistics in Medicine 2008;27:619–22, author reply 622–4. https://doi.org/10.1002/sim.3043.\nReynolds R, Lambert PC, Burton PR, B. S. A. C. Extended Working Parties on Resistance Surveillance. Analysis, power and design of antimicrobial resistance surveillance studies, taking account of inter-centre variation and turnover. J Antimicrob Chemother 2008;62 Suppl 2:ii29–39. https://doi.org/10.1093/jac/dkn350.\nRiley RD, Lambert PC, Staessen JA, Wang J, Gueyffier F, Thijs L, Boutitie F. Meta-analysis of continuous outcomes combining individual patient data and aggregate data. Statistics in Medicine 2008;27:1870–93. https://doi.org/10.1002/sim.3165.\nCooper NJ, Lambert PC, Abrams KR, Sutton AJ. Predicting costs over time using Bayesian Markov chain Monte Carlo methods: An application to early inflammatory polyarthritis. Health Economics 2007;16:37–56. https://doi.org/10.1002/hec.1141.\nGillies CL, Abrams KR, Lambert PC, Cooper NJ, Sutton AJ, Hsu RT, Khunti K. Pharmacological and lifestyle interventions to prevent or delay type 2 diabetes in people with impaired glucose tolerance: Systematic review and meta-analysis. BMJ 2007;334:299. https://doi.org/10.1136/bmj.39063.689375.55.\nLambert PC. Modeling of the cure fraction in survival studies. The Stata Journal 2007;7:351–75.\nLambert PC, Dickman PW, Österlund P, Andersson TM-L, Sankila R, Glimelius B. Temporal trends in the proportion cured for cancer of the colon and rectum: A population-based study using data from the Finnish cancer registry. International Journal of Cancer 2007;121:2052–9. https://doi.org/10.1002/ijc.22948.\nLambert PC, Thompson JR, Weston CL, Dickman PW. Estimating and modeling the cure fraction in population-based cancer survival analysis. Biostatistics 2007;8:576–94. https://doi.org/10.1093/biostatistics/kxl030.\nManca A, Lambert PC, Sculpher M, Rice N. Cost-effectiveness analysis using data from multinational trials: The use of bivariate hierarchical modeling. Medical Decision Making 2007;27:471–90. https://doi.org/10.1177/0272989X07302132.\nNelson CP, Lambert PC, Squire IB, Jones DR. Flexible parametric models for relative survival, with application in coronary heart disease. Statistics in Medicine 2007;26:5486–98. https://doi.org/10.1002/sim.3064.\nRiley RD, Abrams KR, Lambert PC, Sutton AJ, Thompson JR. An evaluation of bivariate random-effects meta-analysis for the joint synthesis of two correlated outcomes. Statistics in Medicine 2007;26:78–97. https://doi.org/10.1002/sim.2524.\nRiley RD, Abrams KR, Sutton AJ, Lambert PC, Thompson JR. Bivariate random-effects meta-analysis and the estimation of between-study correlation. BMC Medical Research Methodology 2007;7:3. https://doi.org/10.1186/1471-2288-7-3.\nSutton AJ, Cooper NJ, Jones DR, Lambert PC, Thompson JR, Abrams KR. Evidence-based sample size calculations based upon updated meta-analysis. Statistics in Medicine 2007;26:2479–500. https://doi.org/10.1002/sim.2704.\nAbrams KR, Gillies CL, Lambert PC. Meta-analysis of heterogeneously reported trials assessing change from baseline. Statistics in Medicine 2005;24:3823–44. https://doi.org/10.1002/sim.2423.\nLambert PC, Smith LK, Jones DR, Botha JL. Additive and multiplicative covariate regression models for relative survival incorporating fractional polynomials for time-dependent effects. Statistics in Medicine 2005;24:3871–85. https://doi.org/10.1002/sim.2399.\nLambert PC, Sutton AJ, Burton PR, Abrams KR, Jones DR. How vague is vague? A simulation study of the impact of the use of vague prior distributions in MCMC using WinBUGS. Statistics in Medicine 2005;24:2401–28. https://doi.org/10.1002/sim.2112.\nMinelli C, Thompson JR, Abrams KR, Lambert PC. Bayesian implementation of a genetic model-free approach to the meta-analysis of genetic association studies. Statistics in Medicine 2005;24:3845–61. https://doi.org/10.1002/sim.2393.\nSutton AJ, Cooper NJ, Abrams KR, Lambert PC, Jones DR. A Bayesian approach to evaluating net clinical benefit allowed for parameter uncertainty. Journal of Clinical Epidemiology 2005;58:26–40. https://doi.org/10.1016/j.jclinepi.2004.03.015.\nTaub NA, Morgan Z, Brugha TS, Lambert PC, Bebbington PE, Jenkins R, Kessler RC, Zaslavsky AM, Hotz T. Recalibration methods to enhance information on prevalence rates from large mental health surveys. Int J Methods Psychiatr Res 2005;14:3–13.\nLambert PC, Burton PR, Abrams KR, Brooke AM. The analysis of peak expiratory flow data using a three-level hierarchical model. Statistics in Medicine 2004;23:3821–39. https://doi.org/10.1002/sim.1951.\nRiley RD, Heney D, Jones DR, Sutton AJ, Lambert PC, Abrams KR, Young B, Wailoo AJ, Burchill SA. A systematic review of molecular and biological tumor markers in neuroblastoma. Clinical Cancer Research 2004;10:4–12.\nRiley RD, Sutton AJ, Abrams KR, Lambert PC. Sensitivity analyses allowed more appropriate and reliable meta-analysis conclusions for multiple outcomes when missing data was present. Journal of Clinical Epidemiology 2004;57:911–24. https://doi.org/10.1016/j.jclinepi.2004.01.018.\nSmith LK, Lambert PC, Botha JL, Jones DR. Providing more up-to-date estimates of patient survival: A comparison of standard survival analysis with period analysis using life-table methods and proportional hazards models. Journal of Clinical Epidemiology 2004;57:14–20. https://doi.org/10.1016/S0895-4356(03)00253-1.\nSweeting MJ, Sutton AJ, Lambert PC. What to add to nothing? Use and avoidance of continuity corrections in meta-analysis of sparse data. Statistics in Medicine 2004;23:1351–75. https://doi.org/10.1002/sim.1761.\nBaker R, Smith JF, Lambert PC. Randomised controlled trial of the effectiveness of feedback in improving test ordering in general practice. Scand J Prim Health Care 2003;21:219–23.\nHsu RT, Lambert PC, Dixon-Woods M, Kurinczuk JJ. Effect of NHS walk-in centre on local primary healthcare services: Before and after observational study. BMJ 2003;326:530. https://doi.org/10.1136/bmj.326.7388.530.\nMckean MC, Hewitt C, Lambert PC, Myint S, Silverman M. An adult model of exclusive viral wheeze: Inflammation in the upper and lower respiratory tracts. Clin Exp Allergy 2003;33:912–20.\nOommen A, Lambert PC, Grigg J. Efficacy of a short course of parent-initiated oral prednisolone for viral wheeze in children aged 1-5 years: Randomised controlled trial. Lancet 2003;362:1433–8. https://doi.org/10.1016/S0140-6736(03)14685-5.\nRiley RD, Abrams KR, Sutton AJ, Lambert PC, Jones DR, Heney D, Burchill SA. Reporting of prognostic markers: Current problems and development of guidelines for evidence-based practice in the future. British Journal of Cancer 2003;88:1191–8. https://doi.org/10.1038/sj.bjc.6600886.\nCooper NJ, Abrams KR, Sutton AJ, Turner D, Lambert PC. A bayesian approach to markov modelling in cost-effectiveness analyses: Application to taxane use in advanced breast cancer. Journal of the Royal Statistical Society Series A: Statistics in Society 2003;166:389–405. https://doi.org/10.1111/1467-985x.00283.\nRiley RD, Burchill SA, Abrams KR, Heney D, Lambert PC, Jones DR, Sutton AJ, Young B, Wailoo AJ, Lewis IJ. A systematic review and evaluation of the use of tumour markers in paediatric oncology: Ewing’s sarcoma and neuroblastoma. Health Technol Assess 2003;7:1–162.\nWaugh J, Kilby M, Lambert P, Bell SC, Blackwell CN, Shennan A, Halligan A. Validation of the DCA 2000 microalbumin:creatinine ratio urinanalyzer for its use in pregnancy and preeclampsia. Hypertension in Pregnancy 2003;22:77–92. https://doi.org/10.1081/prg-120017006.\nRiley RD, Burchill SA, Abrams KR, Heney D, Sutton AJ, Jones DR, Lambert PC, Young B, Wailoo AJ, Lewis IJ. A systematic review of molecular and biological markers in tumours of the ewing’s sarcoma family. European Journal of Cancer 2003;39:19–30.\nSmith LK, Lambert PC, Jones DR. Up-to-date estimates of long-term cancer survival in England and Wales. British Journal of Cancer 2003;89:74–6. https://doi.org/10.1038/sj.bjc.6600976.\nWaugh J, Bell SC, Kilby MD, Lambert PC, Blackwell CN, Shennan A, Halligan A. Urinary microalbumin/creatinine ratios: Reference range in uncomplicated pregnancy. Clinical Science 2003;104:103–7. https://doi.org/10.1042/CS20020170.\nLambert PC, Sutton AJ, Abrams KR, Jones DR. A comparison of summary patient-level covariates in meta-regression with individual patient data meta-analysis. Journal of Clinical Epidemiology 2002;55:86–94.\nYoung B, Fitch GE, Dixon-Woods M, Lambert PC, Brooke AM. Parents’ accounts of wheeze and asthma related symptoms: A qualitative study. Arch Dis Child 2002;87:131–4.\nSutton AJ, Cooper NJ, Lambert PC, Jones DR, Abrams KR, Sweeting MJ. Meta-analysis of rare and adverse event data. Expert Review of Pharmacoeconomics and Outcomes Research 2002;2:367–79. https://doi.org/10.1586/14737167.2.4.367.\nLambert PC, Abrams KR, Jones DR, Halligan AW, Shennan A. Analysis of ambulatory blood pressure monitor data using a hierarchical model incorporating restricted cubic splines and heterogeneous within-subject variances. Statistics in Medicine 2001;20:3789–805.\nMckean MC, Leech M, Lambert PC, Hewitt C, Myint S, Silverman M. A model of viral wheeze in nonasthmatic adults: Symptoms and physiology. Eur Respir J 2001;18:23–32.\nWaugh J, Perry IJ, Halligan AW, Swiet MD, Lambert PC, Penny JA, Taylor DJ, Jones DR, Shennan A. Birth weight and 24-hour ambulatory blood pressure in nonproteinuric hypertensive pregnancy. Am J Obstet Gynecol 2000;183:633–7. https://doi.org/10.1067/mob.2000.106448.\nBell SC, Halligan AW, Martin A, Ashmore J, Shennan AH, Lambert PC, Taylor DJ. The role of observer error in antenatal dipstick proteinuria analysis. Br J Obstet Gynaecol 1999;106:1177–80.\nWilliams N, Jackson D, Lambert PC, Johnstone JM. Incidence of non-specific abdominal pain in children during school term: Population survey based on discharge diagnoses. BMJ 1999;318:1455.\nBrooke AM, Lambert PC, Burton PR, Clarke C, Luyt DK, Simpson H. Recurrent cough: Natural history and significance in infancy and early childhood. Pediatr Pulmonol 1998;26:256–61.\nHellmich M, Abrams KR, Jones DR, Lambert PC. A Bayesian approach to a general regression model for ROC curves. Medical Decision Making 1998;18:436–43.\nPenny JA, Halligan AW, Shennan AH, Lambert PC, Jones DR, Swiet M de, Taylor DJ. Automated, ambulatory, or conventional blood pressure measurement in pregnancy: Which is the better predictor of severe hypertension? Am J Obstet Gynecol 1998;178:521–6.\nHalligan AW, Shennan A, Lambert PC, Bell SC, Taylor DJ, Swiet M de. Automated blood pressure measurement as a predictor of proteinuric pre-eclampsia. Br J Obstet Gynaecol 1997;104:559–62.\nBrooke AM, Lambert PC, Burton PR, Clarke C, Luyt DK, Simpson H. Night cough in a population-based sample of children: Characteristics, relation to symptoms and associations with measures of asthma severity. Eur Respir J 1996;9:65–71.\nHalligan A, Lambert PC, O’Brien E, Shennan A. Characteristics of a reversed circadian blood pressure rhythm in pregnant women with hypertension. J Hum Hypertens 1996;10:135.\nHalligan A, Shennan A, Lambert PC, Swiet M de, Taylor DJ. Diurnal blood pressure difference in the assessment of preeclampsia. Obstet Gynecol 1996;87:205–8. https://doi.org/10.1016/0029-7844(95)00379-7.\nPeek M, Shennan A, Halligan A, Lambert PC, Taylor DJ, Swiet MD. Hypertension in pregnancy: Which method of blood pressure measurement is most predictive of outcome? Obstet Gynecol 1996;88:1030–3. https://doi.org/10.1016/S0029-7844(96)00350-X.\nLuyt D, Bourke A, Lambert P, Burton P, Simpson H. Wheeze in preschool children: Who is followed-up, who is treated and who is hospitalized? European Respiratory Journal 1995;8:1736–41. https://doi.org/10.1183/09031936.95.08101736.\nBrooke AM, Lambert PC, Burton PR, Clarke C, Luyt DK, Simpson H. The natural history of respiratory symptoms in preschool children. Am J Respir Crit Care Med 1995;152:1872–8.\nEsmail A, Lambert PC, Jones DR, Mitchell EA. Prevalence of risk factors for sudden infant death syndrome in south east England before the 1991 national ’Back to Sleep’ health education campaign. J Public Health Med 1995;17:282–9."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "I have developed a number of Stata commands. I have added some examples/tutorials. I occasionally add to these."
  },
  {
    "objectID": "software.html#my-main-stata-commands.",
    "href": "software.html#my-main-stata-commands.",
    "title": "Software",
    "section": "My main Stata commands.",
    "text": "My main Stata commands.\n\nstpm3 - flexible parametric survival models\nstandsurv - standardized survival curves and more after fitting various types of survival models.\nmrsprep - prepare data to directly fit marginal relative survival models.\nstpp - Non-parametric marginal relative (net) survival using Pohar Perme estimator\nmlad - Maximum likelIhood estimation with automatic differentiation using Python\nstcrprep - data-preparation command to fit a range of competing risks models.\ngensplines - obtain basis functions for various types of splines."
  },
  {
    "objectID": "software.html#older-and-less-used-now",
    "href": "software.html#older-and-less-used-now",
    "title": "Software",
    "section": "Older (and less used now)",
    "text": "Older (and less used now)\n\nstpm2 - flexible parametric survival models\nstpm2_standsurv - standardized survival curves after fitting an stpm2 model\nrcsgen - generate restricted cubic splines\nstrcs - flexible parametric models on log hazard scale\nstpm2cif - cause-specific cumulative incidence function after fitting a stpm2 competing risks model\npartpred - partial predictions\n\nI have worked with Paul Dickman, who has written some excellent Stata tutorials, many of which use my commands."
  },
  {
    "objectID": "interactive_graphs.html",
    "href": "interactive_graphs.html",
    "title": "Interactive Graphs",
    "section": "",
    "text": "Many years ago I wrote a few programs in JavaScript using the excellent D3 library. I still use some of these as a teaching guide to using splines in regression models and to illustrate some additional issues in survival analysis. I have found these to be excellent teaching tools and use them in lectures, but also encourage course participants to try them out to help gain an understanding of key concepts. I strongly believe that to be able to interact with graphs leads to a much better understanding of various methods."
  },
  {
    "objectID": "interactive_graphs.html#splines",
    "href": "interactive_graphs.html#splines",
    "title": "Interactive Graphs",
    "section": "Splines",
    "text": "Splines\n\nThe number and location of knots\nThe first graph fits a non-linear function using splines using a linear regression model. The user is allowed to move, add and remove knots. The fitted regression function updated as you change the position or number of knots. Follow the instructions below the graph. The user can also select different spline functions, including linear, quadratic, cubic and restricted cubic splines. To open the graph in a new window click here.\n\n\nContinuity restrictions\nA spline function of degree \\(n\\) is a piecewise polynomial function whose function values and first \\(n-1\\) derivatives agree at the knots, i.e. the function is constrained to be continuous and continuously differentiable up to order \\(n-1\\). The continuity restrictions graph allows the user to investigate the impact of different continuity restrictions from piecewise polynomials with no restrictions to the function being continuously differentiable up to order \\(n-1\\). To open the graph in a new window click here."
  },
  {
    "objectID": "interactive_graphs.html#survival-analysis",
    "href": "interactive_graphs.html#survival-analysis",
    "title": "Interactive Graphs",
    "section": "Survival Analysis",
    "text": "Survival Analysis\n\nWeibull proportional hazards model\nThis graph plots the probability density function, the survival function and the hazard function from a Weibull model under proportional hazards where two groups are being compared (e.g. standard and new treatment). The Weibull model is as follows,\n\\[\nh(t)=\\lambda\\gamma t^{\\gamma-1}\\exp\\left(\\beta x\\right)\n\\] where \\(h(t)\\) is the hazard function and the hazard ratio is \\(\\exp(\\beta)\\). The user is able to change the parameters of the baseline hazard, i.e. \\(\\lambda\\) and \\(\\gamma\\), and also the hazard ratio, \\(\\beta\\) using the slide bars. It is useful to fix the range of the y-axis at an appropriate level. To open the graph in a new window clickMixture Weibull distribution We have used the mixture Weibull distribution to simulate data when evaluating how well spline function approximate true, complex survival/hazard functions. For example see Rutherford et al. (2014), Journal of Statistical Computation and Simulation or Crowther and Lambert (2014), Statistics in Medicine. This graph allows the user to play around with the parameters of a mixture Weibull distribution and see the hazard/survival curves. The component distributions of the mixture Weibull can also be displayed. To open the graph in a new window click here. here.\n\n\nMixture Weibull distribution\nWe have used the mixture Weibull distribution to simulate data when evaluating how well spline function approximate true, complex survival/hazard functions. For example see Rutherford et al. (2014), Journal of Statistical Computation and Simulation or Crowther and Lambert (2014), Statistics in Medicine. This graph allows the user to play around with the parameters of a mixture Weibull distribution and see the hazard/survival curves. The component distributions of the mixture Weibull can also be displayed. To open the graph in a new window click here.\n\n\nCompeting Risks\nThis is a simple demonstration of the link between cause-specific hazards and cause-specific cumulative incidence functions. Assuming exponential distributions, i.e. a constant hazard, the cause-specific hazards for cancer and for other causes can be defined for those unexposed and exposed to a risk factor. By changing the underlying mortality (hazard) rate and/or the hazard ratio between the exposed and unexposed it is possible to see the impact on the cause-specific cumulative incidence function for both cancer and other causes. To open the graph in a new window click here.\n\n\nExpected Survival\nThis shows expected survival by deprivation quintile and sex. You can drag the age slide bar, so you can see the expected survival for someone of a given age. To open the graph in a new window click here.\n\n\nInterPreT\nThis is a webpage developed by Sarwar Mozumder, when he was a PhD student based in Leicester. This is far more professional looking than my attempts. What we have done here is export the model parameters and details about knot locations etc from a flexible parametric survival model fitted in Stata using stpm2. Various predictions can then be made instantly as they are just transformations of model parameters. I particularly like the ability to drag the y-axis in order to get conditional estimates.\n\n\nModel Sensitivity.\nThis is work with Elisavet Syriopoulou, Sarwar Mozumder and Mark Rutherford to assess how sensitive estimates obtained from flexible parametric survival models (FPM) with different number of knots are. A sensitivity analysis was performed for a range of cancer types. For each cancer type considered, 18 FPMs were fitted assuming varying degrees of freedom to model the log cumulative baseline excess hazard and the main and time dependent effect of age. Both estimates of relative survival and excess hazard functions over years since diagnosis are given and there is also an option to choose marginal or age-specific estimates. Age specific estimates are obtained by moving the slider in the age histogram that is available under the graphs. Agreement across different models is so good that for most of the cancers the estimates overlay."
  },
  {
    "objectID": "software/gensplines/gensplines_vs_makesplines.html",
    "href": "software/gensplines/gensplines_vs_makesplines.html",
    "title": "Comparison of gensplines and makespline",
    "section": "",
    "text": "Stata has it’s own command, makespline to generate spline basis functions. This will show similarities and differeneces between the commands.\nI will show how to obtain identical basis functions for B-splines, and how when using restricted cubic splines, the basis functions are different, but give identical fitted values when included in a statistical model."
  },
  {
    "objectID": "software/gensplines/gensplines_vs_makesplines.html#b-splines",
    "href": "software/gensplines/gensplines_vs_makesplines.html#b-splines",
    "title": "Comparison of gensplines and makespline",
    "section": "B-Splines",
    "text": "B-Splines\nI will use the auto data.\n. sysuse auto, clear\n(1978 automobile data)\nI will first use Stata’s makespline command to obtain the spline variables for weight.\n. makespline bspline weight, bsepsilon(0) basis(bs_ms)\nFive new variables have been created, bs_ms_1_1-bs_ms_1_5. I have used the option bsepsilon(0) as by default makespline adds a small value to the minimum and subtracts a small value from the maxiumum when considering knot placement. The gensplines command happily put knots at the minimum and maximum values.\nWe can add these spline variables to a regression model. For example, in the auto data, we can let mpg be a non-linear function of weight.\n. regress mpg bs_ms*, nocons\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(5, 69)        =    612.79\n       Model |  35214.9626         5  7042.99252   Prob &gt; F        =    0.0000\n    Residual |  793.037383        69  11.4932954   R-squared       =    0.9780\n-------------+----------------------------------   Adj R-squared   =    0.9764\n       Total |       36008        74  486.594595   Root MSE        =    3.3902\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n   bs_ms_1_1 |   30.81413   1.650387    18.67   0.000      27.5217    34.10656\n   bs_ms_1_2 |    25.6187   2.130947    12.02   0.000     21.36758    29.86982\n   bs_ms_1_3 |    17.1258   3.125635     5.48   0.000     10.89032    23.36127\n   bs_ms_1_4 |   15.97043   2.794922     5.71   0.000     10.39471    21.54615\n   bs_ms_1_5 |   12.16523   2.676801     4.54   0.000     6.825159     17.5053\n------------------------------------------------------------------------------\n\n. predict mu_ms1\n(option xb assumed; fitted values)\n\n. twoway (scatter mpg weight) ///\n&gt;        (line mu_ms1 weight, sort)\n\nNote I have used the nocons option. If I do not then one of the spline variables would be dropped due to collinearity. I can get exactly the same fitted values if I drop either the first of last spline variable and now estimate a constant term. Below I drop the first spline variable and show the predicted values are essentially the same.\n. regress mpg bs_ms_1_2-bs_ms_1_5, \n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     35.90\n       Model |  1650.42208         4  412.605519   Prob &gt; F        =    0.0000\n    Residual |  793.037383        69  11.4932954   R-squared       =    0.6754\n-------------+----------------------------------   Adj R-squared   =    0.6566\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.3902\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n   bs_ms_1_2 |  -5.195432   3.401967    -1.53   0.131    -11.98217    1.591308\n   bs_ms_1_3 |  -13.68834   2.884242    -4.75   0.000    -19.44224   -7.934431\n   bs_ms_1_4 |   -14.8437   3.596973    -4.13   0.000    -22.01946   -7.667934\n   bs_ms_1_5 |   -18.6489   3.040172    -6.13   0.000    -24.71388   -12.58392\n       _cons |   30.81413   1.650387    18.67   0.000      27.5217    34.10656\n------------------------------------------------------------------------------\n\n. predict mu_ms2\n(option xb assumed; fitted values)\n\n. compare mu_ms1 mu_ms2\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\nmu_ms1&lt;mu_ms2                  39     -3.55e-14    -1.72e-14   -3.55e-15\nmu_ms1=mu_ms2                   6\nmu_ms1&gt;mu_ms2                  29      3.55e-15     1.78e-14    4.09e-14\n                       ----------\nJointly defined                74     -3.55e-14    -2.11e-15    4.09e-14\n                       ----------\nTotal                          74\nI will now use the gensplines command.\n. gensplines weight, type(bs) df(4) gen(bs_gs) \nFour splines variables have been created. This is one less than makespline as it is assumed that a model with an intercept term will be fitted. Fitting a model (with an intercept) will give essentially identical fitted values to when using makespline.\n. regress mpg bs_gs1-bs_gs4, \n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     35.90\n       Model |  1650.42208         4  412.605519   Prob &gt; F        =    0.0000\n    Residual |  793.037383        69  11.4932954   R-squared       =    0.6754\n-------------+----------------------------------   Adj R-squared   =    0.6566\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.3902\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      bs_gs1 |  -5.195432   3.401967    -1.53   0.131    -11.98217    1.591308\n      bs_gs2 |  -13.68834   2.884242    -4.75   0.000    -19.44224   -7.934431\n      bs_gs3 |   -14.8437   3.596973    -4.13   0.000    -22.01946   -7.667934\n      bs_gs4 |   -18.6489   3.040172    -6.13   0.000    -24.71388   -12.58392\n       _cons |   30.81413   1.650387    18.67   0.000      27.5217    34.10656\n------------------------------------------------------------------------------\n\n. predict mu_gs1\n(option xb assumed; fitted values)\n\n. compare mu_gs1 mu_ms2\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\nmu_gs1&lt;mu_ms2                  20     -7.11e-15    -3.91e-15   -3.55e-15\nmu_gs1=mu_ms2                  40\nmu_gs1&gt;mu_ms2                  14      3.55e-15     4.82e-15    7.11e-15\n                       ----------\nJointly defined                74     -7.11e-15    -1.44e-16    7.11e-15\n                       ----------\nTotal                          74\nIn gensplines the intercept option can be used which will calculate the additional spline variable (i.e. the default behavior of makespline).\n. drop bs_gs*\n\n. gensplines weight, type(bs) df(4) gen(bs_gs) intercept\n\n. regress mpg bs_gs1-bs_gs5, nocons\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(5, 69)        =    612.79\n       Model |  35214.9626         5  7042.99252   Prob &gt; F        =    0.0000\n    Residual |  793.037383        69  11.4932954   R-squared       =    0.9780\n-------------+----------------------------------   Adj R-squared   =    0.9764\n       Total |       36008        74  486.594595   Root MSE        =    3.3902\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      bs_gs1 |   30.81413   1.650387    18.67   0.000      27.5217    34.10656\n      bs_gs2 |    25.6187   2.130947    12.02   0.000     21.36758    29.86982\n      bs_gs3 |    17.1258   3.125635     5.48   0.000     10.89032    23.36127\n      bs_gs4 |   15.97043   2.794922     5.71   0.000     10.39471    21.54615\n      bs_gs5 |   12.16523   2.676801     4.54   0.000     6.825159     17.5053\n------------------------------------------------------------------------------\n\n. predict mu_gs2\n(option xb assumed; fitted values)\n\n. compare mu_gs1 mu_gs2\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\nmu_gs1&lt;mu_gs2                  30     -2.31e-14    -7.70e-15   -3.55e-15\nmu_gs1=mu_gs2                   3\nmu_gs1&gt;mu_gs2                  41      3.55e-15     1.15e-14    2.13e-14\n                       ----------\nJointly defined                74     -2.31e-14     3.24e-15    2.13e-14\n                       ----------\nTotal                          74"
  },
  {
    "objectID": "software/gensplines/gensplines_vs_makesplines.html#restricted-cubic-splines",
    "href": "software/gensplines/gensplines_vs_makesplines.html#restricted-cubic-splines",
    "title": "Comparison of gensplines and makespline",
    "section": "Restricted Cubic Splines",
    "text": "Restricted Cubic Splines\nI will now use the default behaviour for calculating restricted cubic splines using makespline.\n. sysuse auto, clear\n(1978 automobile data)\n\n. makespline rcs weight, knots(5) basis(rcs_ms) \nmakespline creates 3 spline variables, rcs_ms_1_1-rcs_ms_1_3. In addition it creates the rescaled weight variable named _rs_rcs_1. I found this confusing and would prefer this variable to be named the same way as defined in the basis() option. The default behaviour of makespline is to rescale the variable (weight) to be in the range [0,1].\nI will store the knots so I can use these later in gensplines.\n. mata: st_local(\"knots\",invtokens(strofreal(st_matrix(\"r(knots)\"))))\nI now fit a regression model where a model mpg as a non-linear function of weight. Note that I have to include _rs_rcs_1 as well as the variables created and named due to the basis() option.\n. regress mpg _rs_rcs_1 rcs_ms_1_*\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     37.05\n       Model |  1667.16739         4  416.791848   Prob &gt; F        =    0.0000\n    Residual |  776.292068        69  11.2506097   R-squared       =    0.6823\n-------------+----------------------------------   Adj R-squared   =    0.6639\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.3542\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n   _rs_rcs_1 |  -36.44172    8.54955    -4.26   0.000     -53.4976   -19.38583\n  rcs_ms_1_1 |   69.72852   45.95646     1.52   0.134    -21.95212    161.4092\n  rcs_ms_1_2 |  -226.4863   177.8215    -1.27   0.207    -581.2306    128.2579\n  rcs_ms_1_3 |   587.4961   573.0472     1.03   0.309    -555.7019    1730.694\n       _cons |   31.33251    1.27378    24.60   0.000     28.79139    33.87363\n------------------------------------------------------------------------------\n\n. predict mu_ms1\n(option xb assumed; fitted values)\n\n. twoway (scatter mpg weight)                        ///\n&gt;        (line mu_ms1 weight, sort),                 ///\n&gt;        xline(`knots', lcolor(gs10) lpattern(dash)) ///\n&gt;        plotr(margin(1 0 1 0))\n\nNow I will use gensplines. As the default location of the knots in gensplines is different from makespline, I define the knots using the allknots() option.\n. gensplines weight, type(rcs) gen(rcs_gs) allknots(`knots')  \n\n. regress mpg rcs_gs*\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     37.05\n       Model |  1667.16739         4  416.791848   Prob &gt; F        =    0.0000\n    Residual |  776.292068        69  11.2506097   R-squared       =    0.6823\n-------------+----------------------------------   Adj R-squared   =    0.6639\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.3542\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n     rcs_gs1 |  -.0118317   .0027758    -4.26   0.000    -.0173694   -.0062941\n     rcs_gs2 |  -2.80e-08   2.20e-08    -1.27   0.207    -7.19e-08    1.59e-08\n     rcs_gs3 |   7.27e-08   7.09e-08     1.03   0.309    -6.87e-08    2.14e-07\n     rcs_gs4 |  -6.80e-08   7.06e-08    -0.96   0.339    -2.09e-07    7.28e-08\n       _cons |   52.15635   6.015477     8.67   0.000      40.1558     64.1569\n------------------------------------------------------------------------------\n\n. predict mu_gs1\n(option xb assumed; fitted values)\n\n. compare mu_ms1 mu_gs1\n\n                                        ---------- Difference ----------\n                            Count       Minimum      Average     Maximum\n------------------------------------------------------------------------\nmu_ms1&lt;mu_gs1                  30     -4.50e-12    -1.88e-12   -3.55e-15\nmu_ms1&gt;mu_gs1                  44      2.13e-14     1.28e-12    3.11e-12\n                       ----------\nJointly defined                74     -4.50e-12    -4.08e-15    3.11e-12\n                       ----------\nTotal                          74\nThe predicted values are essentially the same.\nIt is unclear where the boundary knots are placed in makespline. I could not find details in the documentation. The graph shows they are fairly far from the miniumum and maximum values. When using restricted cubic splines, we usually have the boundary knots at the minimum and maximum values. This means that we are not imposing linearity in the range of the data, but allowing the function to be stable towards the boundaries, due to the linearity assumption beyond. This is the default behaviour in gensplines, as I show below.\n. drop rcs_gs*\n\n. gensplines weight, type(rcs) gen(rcs_gs) df(4)\n\n. local knots `r(knots)'\n\n. regress mpg rcs_gs*\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     35.99\n       Model |  1651.83963         4  412.959907   Prob &gt; F        =    0.0000\n    Residual |  791.619832        69  11.4727512   R-squared       =    0.6760\n-------------+----------------------------------   Adj R-squared   =    0.6572\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.3871\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n     rcs_gs1 |  -.0119595   .0048096    -2.49   0.015    -.0215545   -.0023645\n     rcs_gs2 |  -4.98e-09   8.72e-09    -0.57   0.570    -2.24e-08    1.24e-08\n     rcs_gs3 |   2.24e-09   1.17e-08     0.19   0.848    -2.10e-08    2.55e-08\n     rcs_gs4 |  -8.44e-10   8.74e-09    -0.10   0.923    -1.83e-08    1.66e-08\n       _cons |   52.21262   9.841582     5.31   0.000      32.5792    71.84604\n------------------------------------------------------------------------------\n\n. predict mu_gs2\n(option xb assumed; fitted values)\n\n. twoway (scatter mpg weight)                         ///\n&gt;        (line mu_ms1 weight, sort),                  ///\n&gt;        xline(`knots',  lcolor(gs10) lpattern(dash)) ///\n&gt;        plotr(margin(1 0 1 0))\n\nIn makespline it is not possible to obtain the basis functions for the derivative and intergral of the fitted function, as is possible in gensplines"
  },
  {
    "objectID": "software/mrsprep/mrsprep_marginal_relative_survival.html#background",
    "href": "software/mrsprep/mrsprep_marginal_relative_survival.html#background",
    "title": "Direct modelling of marginal relative survival models",
    "section": "Background",
    "text": "Background\nWhen using relative survival we may be intested in both estimating relative survival conditional on specific covariate patterns, for example, for a male aged 70 diagnosed in 2018 with localized cancer, or marginal relative survival where we may interested in an average effect in a population or when making comparisons where we average over the same covariate (confounder) patterns. My standsurv command can be used to estimate marginal relative survival after fitting a model conditional on covariates.\nThe estimand of interest, is marginal relative survival. Consider a set of covariates, \\(\\mathbf{X}_i\\), for the \\(i^{th}\\) individual that may affect the rate of death from the cancer under study and the rate of death from other causes. The all cause rate of death, \\(h(t|\\mathbf{X}_i)\\), can be partitioned into two components,\n\\[\nh(t|\\mathbf{X}_i) = h^*(t|\\mathbf{X}_i) + \\lambda(t|\\mathbf{X}_i)\n\\]\nwhere \\(h^*(t|\\mathbf{X}_i)\\) is the expected mortaliity rate and \\(\\lambda(t|\\mathbf{X}_i)\\) is the excess mortality rate for the \\(i^{th}\\) individual. The relative survival for covariate pattern, \\(\\mathbf{X}_i\\) is,\n\\[\nR(t|\\mathbf{X}_i) = \\int_0^t {\\lambda(u|\\mathbf{X}_i) du}\n\\]\nThe marginal relative survival involves taking the expectation of \\(R(t|\\mathbf{X})\\) over covariate pattern, \\(\\mathbf{X}\\),\n\\[\nR^m(t|\\mathbf{X}) = E_{\\mathbf{X}}\\left[R(t|\\mathbf{X})\\right]\n\\tag{Equation 1}\n\\]\nNote that in the above for simplicity, I assume the same covariates act on the expected and excess mortality rates, but this is not a requirement"
  },
  {
    "objectID": "software/mrsprep/mrsprep_marginal_relative_survival.html#example",
    "href": "software/mrsprep/mrsprep_marginal_relative_survival.html#example",
    "title": "Direct modelling of marginal relative survival models",
    "section": "Example",
    "text": "Example\nI use the Melanoma data, restricting to those diagnosed in the later calendar perdiod, 1985-1994. I restrict follow-up to 10 years after diagnosis using the exit() option.\n. use https://pclambert.net/data/melanoma.dta if year8594 == 1 \n(Skin melanoma, diagnosed 1975-94, follow-up to 1995)\n\n. stset surv_mm, failure(status=1,2) id(id) exit(time 120.5) scale(12)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: status==1 2\nObserved time interval: (surv_mm[_n-1], surv_mm]\n     Exit on or before: time 120.5\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      4,744  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      4,744  observations remaining, representing\n      4,744  subjects\n      1,401  failures in single-failure-per-subject data\n 22,003.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  10.04167\nI will first estimate the non-parametric estimate of marginal relative survival using stpp, so we have something to compare our model based estimates to.\n. stpp R_pp using https://pclambert.net/data/popmort.dta, /// \n&gt;                 agediag(age) datediag(dx) pmother(sex)\n\n. frame put R_pp* _t, into(PP)\nI have saved the Pohar Perme estimates in a frame, so I can plot them after I restructure the data using mrsprep.\nI will now fit some relative survival models, but first I need to merge in the expected mortality rates at the event/censoring times.\n. // conditional model (no covariates)\n. gen _age = floor(min(age + _t,99))\n\n. gen _year = floor(year(dx + _t*365.24))\n\n. merge m:1 _age _year sex using https://pclambert.net/data/popmort.dta, ///\n&gt;           keep(match master)        \n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                             4,744  (_merge==3)\n    -----------------------------------------\nNow I will fit a flexible parametric relative survival model with no covariate using stpm3. I will then predict the estimated relative survival.\n. stpm3, scale(lncumhazard) df(5) bhazard(rate)\n\nIteration 0:  Log likelihood = -4317.6147  \nIteration 1:  Log likelihood = -4279.9521  \nIteration 2:  Log likelihood = -4279.5867  \nIteration 3:  Log likelihood = -4279.5864  \n\n                                                        Number of obs =  4,744\n                                                        Wald chi2(5)  = 585.83\nLog likelihood = -4279.5864                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -17.87731   1.426021   -12.54   0.000    -20.67226   -15.08236\n        _ns2 |   4.574298   .7477189     6.12   0.000     3.108796      6.0398\n        _ns3 |  -1.225422   .0787509   -15.56   0.000    -1.379771   -1.071073\n        _ns4 |  -.7203963   .0589846   -12.21   0.000    -.8360041   -.6047885\n        _ns5 |  -.3020431    .075848    -3.98   0.000    -.4507024   -.1533838\n       _cons |  -1.398172    .054032   -25.88   0.000    -1.504073   -1.292271\n------------------------------------------------------------------------------\n\n. predict s_cond, surv timevar(0 10, step(0.1)) frame(surv, replace) ci        \nPredictions are stored in frame - surv\nI can now compare the model based and the non-parametric estimates.\n. twoway (rarea R_pp_lci R_pp_uci _t, sort connect(stairstep) color(%30))     ///\n&gt;        (line R_pp _t, sort connect(stairstep) pstyle(p1line)),              ///\n&gt;          ylabel(0.6(0.1)1, format(%3.1f))                                   ///\n&gt;          ytitle(\"Marginal relative survival\")                               ///\n&gt;          xtitle(\"Years from diagnosis\")                                     ///\n&gt;          name(int_stand, replace)   \n\n.          \n. frame surv: addplot: (line s_cond* tt, pstyle(p2line..)                 ///\n&gt;                                        lpattern(solid dash dash)        ///\n&gt;                      , legend(order(2 \"Pohar Perme\"                     ///\n&gt;                                     3 \"stpm3 model without covariates\") ///\n&gt;                                     ring(0) cols(1) pos(7)) norescaling)\n\nIt can be seen that there is disagrement between the non-parametric estimate and the model based estimate. This is not good and differs in what we would expect to see in a standard survival model. For example, if I fit an all-cause stpm3 survival model without covariates I get the following graph comparing the model based estmates with a Kaplan Meier estimate.\n\n\nThere is now near perfect agreement. I explain in the next section why there is disagreement between the model based and non-parametric estimate.\n\nWhy is there disagreement when a model with no covariates is fitted.\nConsider the relative survival model fitted when not including any covariates.\n\\[\nh(t|\\mathbf{X}_i) = h^*(t|\\mathbf{X}_i) + \\lambda(t)\n\\]\nIn this model the excess mortality is assumed to be exactly the same for each individual. In this model the all cause mortality rate varies between individuals only through variation in expected (other cause) mortality rates and the excess (cancer) mortality rate is assumed to be the same for all individuals. This is different from the definition in Equation 1 where relative survival is allowed to vary between individuals. Assuming that the excess mortality is the same over age, sex etc is a very strong assumption and almost certainly not true.\n\n\nRegression standardization\nRegression standardization can be used in the relative survival framework. This means that we should include all covariates that affect expected mortality rates in the model. In the case of the Melanoma data this is age, sex and calendar year\nI will fit a model that uses restricted cubic splines to model the effect of age at diagnosis and also relax the proportional hazards assumption for the effect of age by allowing an interaction with time. The model will include sex and calendar years as these both impact the expected mortality rates. I will allow the effect of sex to be time-dependent (non-proportional), and model the effect of year of diagnosis using restricted cubic splines. A key point here is that various modelling choices need to be made, for example, I have chosen not to include interactions between any of the covariates. Different modelling choices will result in different estimates.\n. gen female = sex==2\n\n. stpm3 @ns(age,df(3)) i.female @ns(yydx,df(3)), scale(lncumhazard) df(5) bhazard(rate) ///\n&gt;                           tvc(@ns(age,df(3)) i.female) dftvc(3)   \n\nIteration 0:  Log likelihood = -4282.7708  \nIteration 1:  Log likelihood = -4232.0164  \nIteration 2:  Log likelihood = -4217.1952  \nIteration 3:  Log likelihood = -4216.7915  \nIteration 4:  Log likelihood = -4216.7715  \nIteration 5:  Log likelihood =  -4216.771  \nIteration 6:  Log likelihood =  -4216.771  \n\n                                                        Number of obs =  4,744\n                                                        Wald chi2(7)  =  42.75\nLog likelihood = -4216.771                              Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------------------\n                         | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------------------+----------------------------------------------------------------\nxb                       |\n             _ns_f1_age1 |  -11.22114   3.385041    -3.31   0.001     -17.8557   -4.586584\n             _ns_f1_age2 |   1.989596   1.260412     1.58   0.114    -.4807653    4.459957\n             _ns_f1_age3 |   -3.86527   1.260658    -3.07   0.002    -6.336114   -1.394427\n                1.female |  -.4872245   .1119448    -4.35   0.000    -.7066323   -.2678167\n            _ns_f1_yydx1 |  -.0434216   .5642721    -0.08   0.939    -1.149375    1.062531\n            _ns_f1_yydx2 |  -.4650447   .2809398    -1.66   0.098    -1.015677    .0855871\n            _ns_f1_yydx3 |  -.1871899   .3394343    -0.55   0.581    -.8524689    .4780891\n-------------------------+----------------------------------------------------------------\ntime                     |\n                    _ns1 |  -36.82314    26.3184    -1.40   0.162    -88.40626    14.75998\n                    _ns2 |   9.331382   11.01803     0.85   0.397    -12.26356    30.92633\n                    _ns3 |  -2.918356   .8051024    -3.62   0.000    -4.496327   -1.340384\n                    _ns4 |  -1.910931   .7813821    -2.45   0.014    -3.442412   -.3794507\n                    _ns5 |  -1.106962   .8472997    -1.31   0.191    -2.767639    .5537151\n                         |\nc._ns_f1_age1#c._ns_tvc1 |  -1.731685   118.9872    -0.01   0.988    -234.9422    231.4789\n                         |\nc._ns_f1_age1#c._ns_tvc2 |   16.01398   60.12386     0.27   0.790    -101.8266    133.8546\n                         |\nc._ns_f1_age1#c._ns_tvc3 |  -.7339993   6.025834    -0.12   0.903    -12.54442    11.07642\n                         |\nc._ns_f1_age2#c._ns_tvc1 |    28.7778   39.36414     0.73   0.465     -48.3745    105.9301\n                         |\nc._ns_f1_age2#c._ns_tvc2 |  -17.24092   20.88894    -0.83   0.409    -58.18249    23.70065\n                         |\nc._ns_f1_age2#c._ns_tvc3 |   1.386903   2.317659     0.60   0.550    -3.155626    5.929431\n                         |\nc._ns_f1_age3#c._ns_tvc1 |   24.54162   43.35966     0.57   0.571    -60.44175     109.525\n                         |\nc._ns_f1_age3#c._ns_tvc2 |  -5.038554   21.17538    -0.24   0.812    -46.54154    36.46443\n                         |\nc._ns_f1_age3#c._ns_tvc3 |   2.869028   2.100064     1.37   0.172    -1.247021    6.985077\n                         |\n       female#c._ns_tvc1 |\n                      1  |   4.273373   2.755442     1.55   0.121    -1.127194    9.673939\n                         |\n       female#c._ns_tvc2 |\n                      1  |  -2.243662   1.420855    -1.58   0.114    -5.028487    .5411632\n                         |\n       female#c._ns_tvc3 |\n                      1  |   .0362194   .1836685     0.20   0.844    -.3237642     .396203\n                         |\n                   _cons |   1.499636   .7380288     2.03   0.042     .0531259    2.946146\n------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n (2) @ns(yydx, df(3))\n\n. range tt 0 10 101\n(4,643 missing values generated)\n\n. standsurv mrs_cond, surv timevar(tt) ci frame(margrs)\nAfter fitting the model I have used standsurv to obtain the estimate of marginal relative survival using regression standardization. This predicts a relative survival function for each individual conditional on their observed covariate pattern and takes the average of these curves. In this case there are 4,744 individuals in the study and so the estimated marginal relative survival is an average of 4,744 different survival curves.\nI can now compare the model based estimate, based on regression standardization, and the non-parametric Pohar Perme estimate.\n. twoway (rarea R_pp_lci R_pp_uci _t, sort connect(stairstep) color(%30))                 ///\n&gt;        (line R_pp _t, sort connect(stairstep) pstyle(p1line)),                          ///\n&gt;          ylabel(0.6(0.1)1, format(%3.1f))                                               ///\n&gt;          ytitle(\"Marginal relative survival\")                                           ///\n&gt;          xtitle(\"Years from diagnosis\")                                                 ///\n&gt;          name(int_stand_standsurv, replace)      \n\n. frame margrs: addplot: (line mrs_cond* tt, pstyle(p2line..)                             ///\n&gt;                                                 lpattern(solid dash dash)               ///\n&gt;                         legend(order(2 \"Pohar Perme\"                                    ///\n&gt;                                      3 \"Regression standardization after stpm3 model\")  ///\n&gt;                                ring(0) cols(1) pos(7)) norescaling)  \n\nThere is now good agreement between the estimate based on regression standardizion and the non-parametric estimate. I will now move on to describing how to model marginal relative survival directly, so we can make fewer modelling decisions if we are only interested in the estimation of marginal relative survival."
  },
  {
    "objectID": "software/mrsprep/mrsprep_marginal_relative_survival.html#using-mrsprep-to-prepare-data-for-fitting-a-marginal-modelling",
    "href": "software/mrsprep/mrsprep_marginal_relative_survival.html#using-mrsprep-to-prepare-data-for-fitting-a-marginal-modelling",
    "title": "Direct modelling of marginal relative survival models",
    "section": "Using mrsprep to prepare data for fitting a marginal modelling",
    "text": "Using mrsprep to prepare data for fitting a marginal modelling\nIn order to directly model marginal relative survival I will run mrsprep. This does two things, (1). It calculates time-dependent weights which are the inverse of the expected survival. These are needed as the estimand of interest is in the net world, where it is not possible to die from causes other than the cancer under study. However, we have data in the real world and as follow-up time increases we have fewer at risk and fewer deaths than we would see in the net world. The weights are based on the same idea as the weights used in the Pohar Perme non-parametric estimate. (2). At each event time it calculates the weighted mean mortality (hazard) rate for those still at risk. The weights are based on the inverse of expected survival among those at risk. The weighted mean is needed as the marginal relative survival is of interest. See the paper for more details.\nThe code for mrsprep is shown below.\n. mrsprep using https://pclambert.net/data/popmort.dta   ///\n&gt;               , pmother(sex) agediag(age) datediag(dx) ///\n&gt;                 breaks(0(0.2)10)                       \nmrsprep needs the filename of where the expected mortality rates are stored. It requires the name of the variable for age at diagnosis and the name of the variable for date of diagnosis. It also needs the name of variables other than age and calendar year that the expected mortality rates are stratified by, in this case this is just sex. The final option is breaks(0(0.2)10). This splits the time scale into intervals, each of width 0.2 years. The weights are calculated at the mid-point of each interval. This is an approximation, greater precision can be obtained with narrower intervals, but the expanded dataset becomes larger. See the paper for a sensitivity analysis for different interval widths.\nBelow is a listing for the first two individuals in the dataset.\n. list id age sex tstart tstop wt meanhazard_wt event if inlist(id,51,574), ///\n&gt;      noobs sepby(id) abbrev(13)\n\n  +--------------------------------------------------------------------------+\n  |  id   age   sex   tstart       tstop          wt   meanhazard_wt   event |\n  |--------------------------------------------------------------------------|\n  |  51    86     1        0          .2    1.017644             999       0 |\n  |  51    86     1       .2          .4   1.0556412             999       0 |\n  |  51    86     1       .4          .6   1.0968963             999       0 |\n  |  51    86     1       .6          .8   1.1378526             999       0 |\n  |  51    86     1       .8           1   1.1783593             999       0 |\n  |  51    86     1        1         1.2   1.2222716             999       0 |\n  |  51    86     1      1.2       1.375   1.2674326       .02960256       1 |\n  |--------------------------------------------------------------------------|\n  | 574    69     2        0          .2   1.0039818             999       0 |\n  | 574    69     2       .2          .4   1.0119931             999       0 |\n  | 574    69     2       .4          .6   1.0206144             999       0 |\n  | 574    69     2       .6          .8   1.0298603             999       0 |\n  | 574    69     2       .8           1   1.0391899             999       0 |\n  | 574    69     2        1         1.2   1.0486292             999       0 |\n  | 574    69     2      1.2         1.4   1.0581798             999       0 |\n  | 574    69     2      1.4         1.6   1.0673769             999       0 |\n  | 574    69     2      1.6         1.8   1.0762101             999       0 |\n  | 574    69     2      1.8           2    1.085564             999       0 |\n  | 574    69     2        2         2.2   1.0958287             999       0 |\n  | 574    69     2      2.2         2.4   1.1065721             999       0 |\n  | 574    69     2      2.4         2.6   1.1174208             999       0 |\n  | 574    69     2      2.6         2.8   1.1283759             999       0 |\n  | 574    69     2      2.8           3   1.1394383             999       0 |\n  | 574    69     2        3         3.2   1.1510196             999       0 |\n  | 574    69     2      3.2         3.4   1.1631333             999       0 |\n  | 574    69     2      3.4         3.6   1.1753744             999       0 |\n  | 574    69     2      3.6         3.8   1.1877444             999       0 |\n  | 574    69     2      3.8           4   1.2002446             999       0 |\n  | 574    69     2        4         4.2   1.2135969             999       0 |\n  | 574    69     2      4.2         4.4   1.2278268             999       0 |\n  | 574    69     2      4.4         4.6   1.2422236             999       0 |\n  | 574    69     2      4.6         4.8   1.2567893             999       0 |\n  | 574    69     2      4.8           5   1.2715257             999       0 |\n  | 574    69     2        5         5.2   1.2863285             999       0 |\n  | 574    69     2      5.2         5.4   1.3011962             999       0 |\n  | 574    69     2      5.4         5.6   1.3162357             999       0 |\n  | 574    69     2      5.6         5.8    1.331449             999       0 |\n  | 574    69     2      5.8           6   1.3468382             999       0 |\n  | 574    69     2        6         6.2   1.3633453             999       0 |\n  | 574    69     2      6.2         6.4    1.381007             999       0 |\n  | 574    69     2      6.4         6.6   1.3988974             999       0 |\n  | 574    69     2      6.6         6.8   1.4170196             999       0 |\n  | 574    69     2      6.8           7   1.4353766             999       0 |\n  | 574    69     2        7         7.2   1.4547646             999       0 |\n  | 574    69     2      7.2   7.2916667   1.4696508       .03708329       1 |\n  +--------------------------------------------------------------------------+\nIndividual 51 is 86 years old at diagnosis and male. They have 7 rows of data with each row corresponding to a different time interval. The start of the interval is given by tstart and the end of the interval by tstop. Each time interval is 0.2 years, execept the last interval in which they die (event==1) at 1.375 years. For each interval there is an associated weight (wt), which is the inverse of the expected survival at the midpoint of the interval. As the expected survival decreases over time, the weights increase over time. The meanhazard_wt gives the weighted mean expected mortality rate at each individuals event time. Note that for any censored time it is set to 999. When fitting relative survival models using stpm3 or other commands the expected mortality rate at the event time is needed, but is not required for any censored times. However, having a missing value would exclude these rows from the analysis and so we feed it a value that is actually not used when we fit the model. Individual 574 is younger than Individual 1 and so the weights are lower at the same time points, e.g. 1.039 vs 1.222 at 1 year.\nHaving restructured the data we can now use stset where we need to give the end of each interval (tstop), the start of the interval (tstart). The weights are passed using [iweights=wt].\n. stset tstop [iweight=wt], enter(tstart) failure(event==1)                                          \n\nSurvival-time data settings\n\n         Failure event: event==1\nObserved time interval: (0, tstop]\n     Enter on or after: time tstart\n     Exit on or before: failure\n                Weight: [iweight=wt]\n\n--------------------------------------------------------------------------\n    112,229  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n    112,229  observations remaining, representing\n      1,401  failures in single-record/single-failure data\n 21,994.417  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nThe marginal model van now be fitted using stpm3. As there are time-dependent weights cluster robust standard errors are used using vce(cluster id).\n. stpm3, scale(lncumhazard) df(5) bhazard(meanhazard_wt) vce(cluster id)\n\nIteration 0:  Log pseudolikelihood = -5644.1536  \nIteration 1:  Log pseudolikelihood = -5557.6921  \nIteration 2:  Log pseudolikelihood = -5557.3554  \nIteration 3:  Log pseudolikelihood = -5557.3542  \nIteration 4:  Log pseudolikelihood = -5557.3542  \n\n                                                       Number of obs = 112,229\n                                                       Wald chi2(5)  =  589.51\nLog pseudolikelihood = -5557.3542                      Prob &gt; chi2   =  0.0000\n\n                                 (Std. err. adjusted for 4,744 clusters in id)\n------------------------------------------------------------------------------\n             |               Robust\n             | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -18.20708   1.089207   -16.72   0.000    -20.34189   -16.07227\n        _ns2 |   4.682916   .5470787     8.56   0.000     3.610662    5.755171\n        _ns3 |  -1.065117   .1005134   -10.60   0.000     -1.26212   -.8681146\n        _ns4 |  -.5983905   .0831871    -7.19   0.000    -.7614342   -.4353468\n        _ns5 |   -.135204    .136843    -0.99   0.323    -.4034113    .1330033\n       _cons |  -1.217818   .0846971   -14.38   0.000    -1.383821   -1.051815\n------------------------------------------------------------------------------\n\n. predict rs_mrsprep, surv timevar(0 10, step(0.1)) ci frame(margrs,replace)\nPredictions are stored in frame - margrs\nAfter fitting the model, the marginal relative survival has been predicted. This can now be compared to the Pohar Perme non-parametric estimate.\n. frame PP {\n.   twoway (rarea R_pp_lci R_pp_uci _t, sort connect(stairstep) color(%30))   ///\n&gt;          (line R_pp _t, sort connect(stairstep) pstyle(p1line))             ///\n&gt;          , legend(order(2 \"Pohar Perme\" 3 \"Marginal stpm2 model\")           ///\n&gt;                   ring(0) cols(1) pos(7))                                   ///\n&gt;            ylabel(0.6(0.1)1, format(%3.1f))                                 ///\n&gt;            ytitle(\"Marginal relative survival\")                             ///\n&gt;            xtitle(\"Years from diagnosis\")                                   ///\n&gt;            name(int_stand_standsurv, replace)   \n. }\n\n. frame margrs: addplot: (line rs_mrsprep* tt, pstyle(p2line..)           ///\n&gt;                                              lpattern(solid dash dash)  ///\n&gt;                                              norescaling                ///\n&gt;                         legend(order(2 \"Pohar Perme\"                    ///\n&gt;                                      3 \"Marginal stpm3 model\")          ///\n&gt;                                ring(0) cols(1) pos(7)))           \n\n.            \n\nThere is now good agreement between the model based and the non parametric Pohar Perme estimate. Here the marginal estimate obtained from regression standardization and the marginal model are very similar.\nThe estimate here is an internally standardized estimate, over the observed covariate distribution and thus would not be comparable to another study with a different age/sex distribution or if separate analysis were performed for males and females. See the example of external age standardization and modelling covarites for further extensions.\nNote that mrsprep makes uses of frames.\n. frame\n  (current frame is mrs_data)\n\n. frames dir\n* PP        4744 x 4; Skin melanoma, diagnosed 1975-94, follow-up to 1995\n* default   4744 x 50; Skin melanoma, diagnosed 1975-94, follow-up to 1995\n* margrs    101 x 4\n* mrs_data  112229 x 29\n* surv      101 x 4; Skin melanoma, diagnosed 1975-94, follow-up to 1995\n\nNote: Frames marked with * contain unsaved data.\nIt is possible to switch to the orginal data using frame change default."
  },
  {
    "objectID": "software/mrsprep/mrsprep_marginal_relative_survival.html#references",
    "href": "software/mrsprep/mrsprep_marginal_relative_survival.html#references",
    "title": "Direct modelling of marginal relative survival models",
    "section": "References",
    "text": "References\nLambert PC, Syriopoulou E, Rutherford MJ. Direct modelling of age standardized marginal relative survival through incorporation of time-dependent weights. BMC Medical Research Methodology 2021;21:84"
  },
  {
    "objectID": "software/mrsprep.html",
    "href": "software/mrsprep.html",
    "title": "mrsprep",
    "section": "",
    "text": "The mrsprep command restructures survival data and calculates weighted mean expected mortality rates and time-dependent weights so that a marginal relative survival can be directly estimated. After running mrsprep estimation commands that fit (conditional) relative survival models (e.g. stpm3) can be used to estimate marginal relative survival without the need to include covariates that affect expected survival.\nYou can install mrsprep within Stata using"
  },
  {
    "objectID": "software/mrsprep.html#examples",
    "href": "software/mrsprep.html#examples",
    "title": "mrsprep",
    "section": "Examples",
    "text": "Examples\n\nEstimating marginal relative survival using mrsprep and stpm3\nExternal age standardization\nModelling covariates"
  },
  {
    "objectID": "software/mrsprep.html#updates",
    "href": "software/mrsprep.html#updates",
    "title": "mrsprep",
    "section": "Updates",
    "text": "Updates\nSee mrsprep_releases.txt"
  },
  {
    "objectID": "software/standsurv/standardized_cif.html",
    "href": "software/standsurv/standardized_cif.html",
    "title": "",
    "section": "",
    "text": "title: “Standardized cumulative incidence functions”"
  },
  {
    "objectID": "software/standsurv/standardized_cif.html#background",
    "href": "software/standsurv/standardized_cif.html#background",
    "title": "",
    "section": "Background",
    "text": "Background\nI have been meaning to write about using standsurv for standardized measures in competing risks for a while and how many of the ideas of standardization in a standard survival carry over to competing risks. Last week a very nice paper by Kipourou et al. was published that decribes using cause-specific flexible parametric models on the log-hazard scale and then using these to derive standardized cause-specific cumulative incidence functions. It is great that they include R code for their analysis and as they used the publically available MGUS2 data set available from the survival library in R, I thought I would try and do a similar analysis using standsurv.\nIn competing risks there is interest in the time to more than one type of event. A common example is different causes of death. For example, for patients diagnosed with a type of cancer, they at risk from dying from their cancer or from some other cause, i.e. there are competing events. An indvidual can only experience one of these events. In such situations we can think of a separate hazard (mortality) rate for each of the different causes.\nSo for two causes we could have two proportional hazards models,\nModel 1: \\(h_1(t) = h_{01}(t) \\exp\\left(\\boldsymbol{\\beta_1} \\mathbf{Z_1}\\right)\\)\nModel 2: \\(h_2(t) = h_{02}(t) \\exp\\left(\\boldsymbol{\\beta_2} \\mathbf{Z_2} \\right)\\)\nIt is well known that transforming the cause-specific hazard function to a cause-specific survival function does not give a “real” world probability of death, i.e. using the transformation\n\\[\nS_k(t) = \\exp\\left(-\\int_0^t h_k(u) du\\right)\n\\]\nIf one is willing to assume conditional independence between the times to each event then \\(S_k(t)\\) can be interpreted as a net probability, that is the probability of still being alive in the hypothetical situation where it is only possible to die from cause \\(k\\). The independence asumption cannot be assessed from the data as we of course never observe the time to two events on the same individual.\nIf interest lies in the probability of dying of cause \\(k\\) in the situation where dying from another cause first will make it impossible to die from cause \\(k\\), then the cause-specific cumulative incidence function, \\(F_k(t)\\) should be estimated. This is defined as follows\n\\[\nF_{k}(t) = \\int_0^t S(u) h_k(u) du\n\\]\nwhere \\(S(t)\\) is the overall survival function,\n\\[\nS(t) = S_1(t) S_2(t) = \\exp\\left(-\\int_0^t {h_1(u) + h_2(u) du}\\right)\n\\]\nThis is for two competing risks, but of course it can be extended to any number. For more detail on competing risks see Andersen et al. 2012, Geskus 2016."
  },
  {
    "objectID": "software/standsurv/standardized_cif.html#example",
    "href": "software/standsurv/standardized_cif.html#example",
    "title": "",
    "section": "Example",
    "text": "Example\nFirst I load the mgus2 data. This is the same data used by Kipourou et al in their example. This is a dataset that comes with the survival package in R. The two events of interest are time to plasma cell malignacy (PCM) or death (before PCM). I will fit similar models to those in the Kipourou paper.\nFirst I will load the data and drop rows with missing values for the mspike variable\n. use https://www.pclambert.net/data/mgus2, clear\n\n. drop if mspike == .\n(11 observations deleted)\nAfter dropping the missing values of mspike we are left with 1373 individuals. I will now tabulate the event variable,\n. tab event\n\n      event |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |        404       29.42       29.42\n          1 |        115        8.38       37.80\n          2 |        854       62.20      100.00\n------------+-----------------------------------\n      Total |      1,373      100.00\nThere are 404 individuals who are censored (event=0), 115 had a PCM event (event=1) and 854 died before PCM (event=2).\nI will now fit the models. As there are two events we fit two separate models, one for PCM and one for death. I will fit similar models to Kipourou et al, but the models here will be on the log cumulative hazard scale rather than the log hazard scale.\n\nPCM model\nFor the PCM model we need to use, event=1, when using stset\n. stset survtime, failure(event=1)\n\nSurvival-time data settings\n\n         Failure event: event==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n--------------------------------------------------------------------------\n      1,373  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,373  observations remaining, representing\n        115  failures in single-record/single-failure data\n 10,739.583  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  35.33333\n\n. stpm3 age mspike i.male, scale(lncumhazard) df(4)\n\nIteration 0:  Log likelihood = -436.35927  \nIteration 1:  Log likelihood = -435.78559  \nIteration 2:  Log likelihood = -435.78118  \nIteration 3:  Log likelihood = -435.78118  \n\n                                                        Number of obs =  1,373\n                                                        Wald chi2(3)  =  31.52\nLog likelihood = -435.78118                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n         age |    .016625   .0083603     1.99   0.047     .0002391    .0330108\n      mspike |    .883143   .1645591     5.37   0.000     .5606132    1.205673\n      1.male |  -.0255884   .1877314    -0.14   0.892    -.3935353    .3423584\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |   -19.2611   2.240876    -8.60   0.000    -23.65313   -14.86906\n        _ns2 |   4.240545   1.148641     3.69   0.000      1.98925     6.49184\n        _ns3 |  -2.345719   .2692337    -8.71   0.000    -2.873408   -1.818031\n        _ns4 |  -1.711317   .4184964    -4.09   0.000    -2.531555    -.891079\n       _cons |   -3.02243   .6282616    -4.81   0.000      -4.2538    -1.79106\n------------------------------------------------------------------------------\n\n. estimates store pcm\nThis is a proportional hazards model including the effects of age at diagnosis, age, size of the monoclonal serum spike (mspike) and sex (male). The effects of age and mspike are assumed to be linear. I have used 4 degrees of freedom, i.e. 5 knots, for the effect of time since diagnosis for the restricted cubic splines.\n\n\nDeath before PCM model\nFor the death before PCM model we to need use, event=2, when using stset.\n. stset survtime, failure(event=2)\n\nSurvival-time data settings\n\n         Failure event: event==2\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n--------------------------------------------------------------------------\n      1,373  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,373  observations remaining, representing\n        854  failures in single-record/single-failure data\n 10,739.583  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  35.33333\n\n. stpm3 age mspike i.male, scale(lncumhazard) df(4) tvc(age) dftvc(2)\n\nIteration 0:  Log likelihood = -1820.2633  \nIteration 1:  Log likelihood = -1797.1359  \nIteration 2:  Log likelihood = -1794.6344  \nIteration 3:  Log likelihood = -1794.5668  \nIteration 4:  Log likelihood = -1794.5667  \n\n                                                        Number of obs =  1,373\n                                                        Wald chi2(3)  = 195.73\nLog likelihood = -1794.5667                             Prob &gt; chi2   = 0.0000\n\n----------------------------------------------------------------------------------\n                 | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-----------------+----------------------------------------------------------------\nxb               |\n             age |   .0893457   .0067803    13.18   0.000     .0760566    .1026348\n          mspike |  -.0445153   .0638026    -0.70   0.485    -.1695661    .0805354\n          1.male |   .4041454   .0699583     5.78   0.000     .2670297    .5412612\n-----------------+----------------------------------------------------------------\ntime             |\n            _ns1 |  -3.526569   2.605836    -1.35   0.176    -8.633914    1.580777\n            _ns2 |   1.730746   1.163022     1.49   0.137    -.5487345    4.010226\n            _ns3 |  -.3259044   .5716026    -0.57   0.569    -1.446225    .7944161\n            _ns4 |  -.3377873    .514584    -0.66   0.512    -1.346353    .6707788\n                 |\nc.age#c._ns_tvc1 |   -.102553   .0189964    -5.40   0.000    -.1397854   -.0653207\n                 |\nc.age#c._ns_tvc2 |  -.0814865    .020701    -3.94   0.000    -.1220596   -.0409133\n                 |\n           _cons |  -4.912348   .4686894   -10.48   0.000    -5.830962   -3.993734\n----------------------------------------------------------------------------------\n\n. estimates store death\nThis model has relaxed the assumption of proportional hazards for age through use of the tvc() and dftvc() options.\nI have stored both models using estimates store as these will need to be passed to to standsurv when making predictions.\n\n\nEstimating the Marginal Cause-Specific CIFs\nThe marginal cause-specific CIFs is the expection of the CIF over covariates \\(Z\\), i.e.\n\\[\nE\\left[F_k(t|Z)\\right]\n\\]\nThis can be estimated by predicting the cause specific CIF for each individual and then taking the mean, i.e.\n\\[\n\\widehat{F}_{k}(t|Z) = \\frac{1}{N} \\sum_{i=1}^{N} \\int_0^t \\widehat{S}_1(u|Z_i) \\widehat{S}_2(u|Z_i) \\widehat{h}_k(u|Z_i) du\n\\]\nIn this case \\(Z_i=(\\mbox{age}\\_i,\\mbox{mspike}_i,\\mbox{male}_i)\\)\nI now create the times I want to predict the cause-specific CIF at\n. range tt 0 30 31\n(1,342 missing values generated)\nThis creates 31 equally spaced values between 0 and 30, i.e. increasing in steps of 1 year, and stores in a new variable, tt. I then use standsurv.\n. standsurv, crmodels(pcm death) cif  timevar(tt) ci frame(cif,replace) atvar(F) \nThe crmodels(pcm death) gives the names of the two models, the cif option requests the cause-specific CIFs are estimated (the default is overall survival), the ci option means that confidence intervals will be calculated (using the delta method), the timevar(tt) option gives the times to predict at and the atvar(F) option gives the stub name of the new variables. Here the defaults of using the model names will be used so variables F_pcm and F_death will be created.\nWe can now plot the results,\n. frame cif {\n.   twoway (rarea F_pcm_lci F_pcm_uci tt, color(red%30))              ///\n&gt;          (line F_pcm tt, color(red))                                ///\n&gt;          (rarea F_death_lci F_death_uci tt, color(blue%30))         ///\n&gt;          (line F_death tt, color(blue))                             ///\n&gt;          , legend(order(2 \"PCM\" 4 \"Death\") cols(1) ring(0) pos(11)) ///\n&gt;          ylabel(,angle(h) format(%3.2f))                            ///\n&gt;          xtitle(\"Time from diagnosis (years)\")                      ///\n&gt;          ytitle(\"cause-specific CIF\")                               ///\n&gt;          name(cifs, replace)\n. }\n\nThis is similar to Figure 3 of the Kipourou et al. paper.\n\n\nContrasts\nContrasts are of more interest and the general idea is essentially the same as when making contrasts of survival functions. For a binary exposure \\(X\\) and confounders \\(Z\\) we want to estimate\n\\[\nE\\left[F_k(t|X=1,Z)\\right] - E\\left[F_k(t|X=0,Z)\\right]\n\\]\n\\(F_k(t|X=x,Z)\\) is estimated by,\n\\[\n\\widehat{F}_{k}(t|X=x,Z) = \\frac{1}{N} \\sum_{i=1}^{N} \\int_0^t \\widehat{S}_1(u|X=x,Z_i) \\widehat{S}_2(u|X=x,Z_i) \\widehat{h}_k(u|X=x,Z_i) du\n\\]\nHere we are interested in the effect of sex, so here our exposure is male and the potential confounders are age and mspike. The standsurv command is shown below.\n. standsurv, crmodels(pcm death) cif ci timevar(tt) frame(cif2, replace) ///\n&gt;     at1(male 1) at2(male 0) atvar(F_male F_female)                     ///\n&gt;     contrast(difference) contrastvar(cif_diff)\nThe options that are different to the previous standsurv command are that I have used at1(male 1) and at2(male 0). When estimating the standardized CIFs it first forces the covariate male to be set to 1 for all subjects in the individual predictions and then to 0. As in the other standsurv examples the key point here is that the distribution of confounders is forced to be the same for males and females when obtaining the the estimates. As there are two at() options, two new variables are listed using atvar(F_male F_female). If atvar() is not specified the default names would be _at2 and _at1. The contrast(difference) option means that the difference between the at options will be taken. By default at1 is the reference, but this can be changed using atreference(). The contrastvar(cif_diff) option gives the variable name for the difference. Note that two new variables will be created as there are two competing events, cif_diff_pcm and cif_diff_death.\nHaving created the standardized cause-specific CIFs we can now plot them.\n. frame cif2 {\n.   twoway (rarea F_male_pcm_lci F_male_pcm_uci tt, color(red%30))        ///\n&gt;          (line F_male_pcm tt, color(red))                               ///\n&gt;          (rarea F_female_pcm_lci F_female_pcm_uci tt, color(blue%30))   ///\n&gt;          (line F_female_pcm tt, color(blue))                            ///\n&gt;          , legend(order(2 \"Males\" 4 \"Females\") cols(1) ring(0) pos(11)) ///\n&gt;          ylabel(, angle(h) format(%3.2f))                               ///\n&gt;          xtitle(\"Time from diagnosis (years)\")                          ///\n&gt;          ytitle(\"cause-specific CIF\")                                   ///\n&gt;          title(\"PCM\")                                                   ///\n&gt;          name(pcm, replace)\n.                 \n.   twoway (rarea F_male_death_lci F_male_death_uci tt, color(red%30))      ///\n&gt;          (line F_male_death tt, color(red))                               ///\n&gt;          (rarea F_female_death_lci F_female_death_uci tt, color(blue%30)) ///\n&gt;          (line F_female_death tt, color(blue))                            ///\n&gt;          , legend(order(2 \"Males\" 4 \"Females\") cols(1) ring(0) pos(11))   ///\n&gt;          ylabel(, angle(h) format(%3.2f))                                 ///\n&gt;          xtitle(\"Time from diagnosis (years)\")                            ///\n&gt;            ytitle(\"cause-specific CIF\")                                   ///\n&gt;          title(\"Death\")                                                   ///\n&gt;          name(death, replace)\n. }               \n\n. graph combine pcm death, nocopies ycommon               \n\nThis is similar to the top row of Figure 4 in the Kipourou et al. paper although I have shown both cause-specific CIFs with the y-axes over the same range.\nFor the contrast I just need to plot the new variables cif_diff_pcm and cif_diff_death together with their confidence limits.\n. frame cif2 {\n.   twoway (rarea cif_diff_pcm_lci cif_diff_pcm_uci tt, color(red%30)) ///\n&gt;          (line cif_diff_pcm tt, color(red))                          ///\n&gt;          , legend(off)                                               ///\n&gt;          ylabel(, angle(h) format(%3.2f))                            ///\n&gt;          xtitle(\"Time from diagnosis (years)\")                       ///\n&gt;            ytitle(\"cause-specific CIF\")                              ///\n&gt;          title(\"PCM\")                                                ///\n&gt;          name(pcm_diff, replace)\n.                 \n.   twoway (rarea cif_diff_death_lci cif_diff_death_uci tt, color(red%30)) ///\n&gt;          (line cif_diff_death tt, color(red))                            ///\n&gt;          , legend(off)                                                   ///\n&gt;          ylabel(, angle(h) format(%3.2f))                                ///\n&gt;          xtitle(\"Time from diagnosis (years)\")                           ///\n&gt;            ytitle(\"cause-specific CIF\")                                  ///\n&gt;          title(\"Death\")                                                  ///\n&gt;          name(death_diff, replace)\n. }               \n\n. graph combine pcm_diff death_diff, nocopies ycommon             \n\nThis is similar to the bottom row of Figure 4 in the Kipourou et al. paper although, as above, I have shown both cause-specific CIFs with the y-axes over the same range."
  },
  {
    "objectID": "software/standsurv/standardized_cif.html#using-different-survival-models",
    "href": "software/standsurv/standardized_cif.html#using-different-survival-models",
    "title": "",
    "section": "Using different survival models",
    "text": "Using different survival models\nstandsurv is a general command and it possible to use a variety of different survival models. It is also possible to use different survival distributions for different causes. In order to illustrate this I will use a weibull model for PCM where the shape parameter is a function of age and a log-logistic accelerated failure time model for death. I am not claiming these are sensible models, but just aim to show the versatility of standsurv\nI fit the two models below.\n. stset survtime, failure(event=1)\n\nSurvival-time data settings\n\n         Failure event: event==1\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n--------------------------------------------------------------------------\n      1,373  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,373  observations remaining, representing\n        115  failures in single-record/single-failure data\n 10,739.583  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  35.33333\n\n. streg age mspike male, dist(weibull) anc(age)\n\n        Failure _d: event==1\n  Analysis time _t: survtime\n\nFitting constant-only model:\nIteration 0:  Log likelihood = -452.48861  \nIteration 1:  Log likelihood = -452.44835  \nIteration 2:  Log likelihood = -452.44832  \n\nFitting full model:\nIteration 0:  Log likelihood = -452.44832  \nIteration 1:  Log likelihood = -437.70531  \nIteration 2:  Log likelihood = -435.60846  \nIteration 3:  Log likelihood = -435.60532  \nIteration 4:  Log likelihood = -435.60532  \n\nWeibull PH regression\n\nNo. of subjects =       1,373                           Number of obs =  1,373\nNo. of failures =         115\nTime at risk    = 10,739.5833\n                                                        LR chi2(3)    =  33.69\nLog likelihood = -435.60532                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n          _t | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n_t           |\n         age |   .0429871   .0171147     2.51   0.012     .0094429    .0765314\n      mspike |   .8710854   .1643031     5.30   0.000     .5490573    1.193114\n        male |  -.0308749   .1875072    -0.16   0.869    -.3983823    .3366325\n       _cons |  -9.181064   1.316739    -6.97   0.000    -11.76183   -6.600303\n-------------+----------------------------------------------------------------\nln_p         |\n         age |  -.0088294   .0042727    -2.07   0.039    -.0172039    -.000455\n       _cons |    .802942   .3018274     2.66   0.008     .2113712    1.394513\n------------------------------------------------------------------------------\n\n. estimates store pcm2\n\n. \n. stset survtime, failure(event=2)\n\nSurvival-time data settings\n\n         Failure event: event==2\nObserved time interval: (0, survtime]\n     Exit on or before: failure\n\n--------------------------------------------------------------------------\n      1,373  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,373  observations remaining, representing\n        854  failures in single-record/single-failure data\n 10,739.583  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  35.33333\n\n. streg age mspike male, dist(llogistic) \n\n        Failure _d: event==2\n  Analysis time _t: survtime\n\nFitting constant-only model:\nIteration 0:  Log likelihood = -2056.9536  \nIteration 1:  Log likelihood = -2051.5925  \nIteration 2:  Log likelihood = -2051.5305  \nIteration 3:  Log likelihood = -2051.5305  \n\nFitting full model:\nIteration 0:  Log likelihood = -2051.5305  \nIteration 1:  Log likelihood = -1936.9223  \nIteration 2:  Log likelihood = -1924.5341  \nIteration 3:  Log likelihood = -1924.4786  \nIteration 4:  Log likelihood = -1924.4786  \n\nLoglogistic AFT regression\n\nNo. of subjects =       1,373                           Number of obs =  1,373\nNo. of failures =         854\nTime at risk    = 10,739.5833\n                                                        LR chi2(3)    = 254.10\nLog likelihood = -1924.4786                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n          _t | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n         age |  -.0590111   .0039933   -14.78   0.000    -.0668378   -.0511844\n      mspike |   .1093803    .075813     1.44   0.149    -.0392104    .2579711\n        male |  -.4249628   .0857712    -4.95   0.000    -.5930714   -.2568543\n       _cons |   6.452482   .3170312    20.35   0.000     5.831113    7.073852\n-------------+----------------------------------------------------------------\n    /lngamma |  -.1515847   .0296779    -5.11   0.000    -.2097524   -.0934171\n-------------+----------------------------------------------------------------\n       gamma |   .8593451   .0255036                       .810785    .9108135\n------------------------------------------------------------------------------\n\n. estimates store death2\nI have stored the models using estimates store and just need to pass these new models to standsurv. The rest of the standsurv code is the same, with the exception of creating new variables names.\n. standsurv, crmodels(pcm2 death2) cif ci timevar(tt) frame(cif3, replace) ///\n&gt;            at1(male 1) at2(male 0) atvar(F_male F_female)                ///\n&gt;            contrast(difference) contrastvar(cif_diff)\nThe plots can be reproduced the same way and are shown in a panel graph below.\n\n\nThey are reasonably similar to the previous plot, with some small differences."
  },
  {
    "objectID": "software/standsurv/standardized_cif.html#some-comments",
    "href": "software/standsurv/standardized_cif.html#some-comments",
    "title": "",
    "section": "Some comments",
    "text": "Some comments\nFor the flexible parametric models I have modelled on the log cumulative hazard scale, while Kipourou et al fitted models on the log hazard scale. In stpm3 you can fit a model on log hazard scale using scale(lnhazard) for standard survival models and relative survival models these are compatable with standsurv. However, computations are easier and faster on the log cumulative hazard scale so unless there is a good reason for not doing so, I prefer models on this scale. In the MGUS2 example, the models here have very similar fits (BIC = 925.6 for stpm3 with scale(lncumhazard) PCM model and 926.7 for stpm3 with scale(lnhazard) for the PCM model and BIC = 3656.6 vs 3656.4 for the death model."
  },
  {
    "objectID": "software/standsurv/standardized_cif.html#references",
    "href": "software/standsurv/standardized_cif.html#references",
    "title": "",
    "section": "References",
    "text": "References\nAndersen, P. K., Geskus, R. B., de Witte, T., Putter, H. Competing risks in epidemiology: possibilities and pitfalls. Int J Epidemiol 2012;41:861-70\nGeskus, R. B. Data analysis with competing risks and intermediate states. Chapman and Hall 2016\nKipourou, D.-K., Charvat, H., Rachet, B., Belot, A. Estimation of the adjusted cause-specific cumulative probability using flexible regression models for the cause-specific hazards.  Statistics in Medicine 2019. DOI: 10.1002/sim.8209"
  },
  {
    "objectID": "software/standsurv/standardized_relative_survival.html",
    "href": "software/standsurv/standardized_relative_survival.html",
    "title": "Standardized relative survival",
    "section": "",
    "text": "You will need to install standsurv, stpm3 and gensplines to run the example. Details here"
  },
  {
    "objectID": "software/standsurv/standardized_relative_survival.html#background",
    "href": "software/standsurv/standardized_relative_survival.html#background",
    "title": "Standardized relative survival",
    "section": "Background",
    "text": "Background\nHere I will describe how to obtain estimates of standardized relative survival after fitting a relative survival model. The relative survival framework is used extensively in population-based cancer studies for the analysis of cancer registry data. Rather than use cause of death information, the relative survival framework uses expected mortality rates in order to estimate the mortality in excess of that expected in the general population.\nIn a relative survival model the underlying all cause mortality rate, \\(h(t|Z=z_i)\\), for the \\(i^{th}\\) individual with covariate pattern, \\(Z=z_i\\), is partitioned into the expected mortality rate if they did not have cancer, \\(h^*(t|Z_1 = z_{1i})\\), and their excess mortality rate due to the cancer, \\(\\lambda(t|Z_2=z_{2i})\\).\n\\[\nh(t|Z=z_i) = h^*(t|Z_1 = z_{1i}) + \\lambda(t|Z_2=z_{2i})\n\\]\nwith \\(Z\\) denoting the set of all covariates. \\(Z_1\\) and \\(Z_2\\) denote the covariates for expected and excess mortalities respectively. In the example below \\(Z_1\\) and \\(Z_2\\) will be the same.\nThe survival analogue of excess mortality is relative survival. The relative survival of individual \\(i\\), \\(R(t|Z_2=z_{2i}⁠)\\), is defined as their all-cause survival, \\(S(t|Z=z_i)⁠\\), divided by their expected survival, \\(S^*(t|Z1=z_{1i})\\)⁠. The all-cause survival is thus,\n\\[\nS(t|Z=z_i) = S^*(t|Z_1 = z_{1i})R(t|Z_2=z_{2i})\n\\]\nThere are a number of different relative survival models. I will use an adaption of Royston-Parmar (flexible parametric survival) models to the relative survival framework (Nelson et al. 2007). These models are conditional models, i.e. the can predict relative survival/excess mortality conditional on specific covariate patterns. I will use these models to obtain marginal (standardized) estimates using standsurv, but first I need to fit the conditional model."
  },
  {
    "objectID": "software/standsurv/standardized_relative_survival.html#example-simulated-colon-cancer-data",
    "href": "software/standsurv/standardized_relative_survival.html#example-simulated-colon-cancer-data",
    "title": "Standardized relative survival",
    "section": "Example (simulated colon cancer data)",
    "text": "Example (simulated colon cancer data)\nI will use simulated data. The data is simulated in a way to be similar to colon cancer data in England. There are just three covariates, age at diagnosis (agediag), sex (female) and deprivation group (dep). There are five derpivation groups derived from national quintiles of the income domain of the area of patients’ residence at diagnosis (in real data, but simulated here).\nI first load and stset the data.\n. use https://www.pclambert.net/data/colonsim, clear      \n\n. stset t, failure(dead=1,2) id(id) exit(time 5)\n\nSurvival-time data settings\n\n           ID variable: id\n         Failure event: dead==1 2\nObserved time interval: (t[_n-1], t]\n     Exit on or before: time 5\n\n--------------------------------------------------------------------------\n     20,000  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n     20,000  observations remaining, representing\n     20,000  subjects\n     10,677  failures in single-failure-per-subject data\n 60,922.154  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nThere are 20,000 individuals and follow-up has been restricted to 5 years.\nFor simplicity in this example I will only keep the least and most deprived groups.\n. keep if inlist(dep,1,5)\n(12,667 observations deleted)\nIn a relative survival model the expected mortality rates at the event times are required. Expected mortality rates are stored in a “popmort file”. Attained age and attained calendar year can be calculated through making use of _t, and then the expected rates can be merged in.\n. // attained age\n. gen age = min(floor(agediag + _t),99)\n\n. // attained calendar year\n. gen year = floor(yeardiag + _t)\n\n. merge m:1 age year dep sex using https://www.pclambert.net/data/popmort_uk_2017, ///\n&gt;       keep(match master) keepusing(rate)\n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                             0\n    Matched                             7,333  (_merge==3)\n    -----------------------------------------\n\n. drop age year      \nI have drop attained age (age) and attained year (year) variables as we do not need them now we have the rates and it avoids potential confusion with the agediag variable.\nRather than create age groups, age will be modelled continuously using natural spline with 4 knots (3 natural splines variables). I create a dummy variable, female (so I don’t have to remember how sex is coded).\n. gen female = sex == 2 \nThe model can now be fitted. I include the main effect and the twoway interactions. In addition time-dependent effect of deprivation, sex and age are incorporated though use of the tvc() and dftvc options. Time-dependent effects are an interaction with time.\n. stpm3 i.dep i.female i.dep#i.female @ns(agediag,df(3))                        ///\n&gt;       (i.dep i.female)#@ns(agediag,df(3)), scale(lncumhazard) df(5)           ///\n&gt;                                        tvc(i.dep i.female @ns(agediag,df(3))) ///\n&gt;                                        dftvc(3)                               ///\n&gt;                                        bhazard(rate)\n\nIteration 0:  Log likelihood = -8428.5345  \nIteration 1:  Log likelihood =    -8278.5  \nIteration 2:  Log likelihood = -8265.7391  \nIteration 3:  Log likelihood = -8265.6187  \nIteration 4:  Log likelihood = -8265.6186  \n\n                                                        Number of obs =  7,333\n                                                        Wald chi2(12) = 113.87\nLog likelihood = -8265.6186                             Prob &gt; chi2   = 0.0000\n\n----------------------------------------------------------------------------------------------\n                             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-----------------------------+----------------------------------------------------------------\nxb                           |\n                       5.dep |  -.6419774   .5845227    -1.10   0.272    -1.787621    .5036659\n                    1.female |    -1.3657    .582489    -2.34   0.019    -2.507357    -.224042\n                             |\n                  dep#female |\n                        5 1  |  -.0191719   .0827025    -0.23   0.817    -.1812658    .1429219\n                             |\n             _ns_f1_agediag1 |   6.501771   2.152943     3.02   0.003      2.28208    10.72146\n             _ns_f1_agediag2 |  -2.279435   .6160949    -3.70   0.000    -3.486958   -1.071911\n             _ns_f1_agediag3 |    2.81975    .956029     2.95   0.003     .9459672    4.693532\n                             |\n       dep#c._ns_f1_agediag1 |\n                          5  |   .9056399   2.348349     0.39   0.700     -3.69704    5.508319\n                             |\n       dep#c._ns_f1_agediag2 |\n                          5  |   1.345686   .7804873     1.72   0.085    -.1840408    2.875413\n                             |\n       dep#c._ns_f1_agediag3 |\n                          5  |   1.117606   .9777112     1.14   0.253    -.7986725    3.033885\n                             |\n    female#c._ns_f1_agediag1 |\n                          1  |   5.925897   2.384517     2.49   0.013     1.252329    10.59947\n                             |\n    female#c._ns_f1_agediag2 |\n                          1  |  -1.433401   .8081704    -1.77   0.076    -3.017386     .150584\n                             |\n    female#c._ns_f1_agediag3 |\n                          1  |   2.310526   .9781133     2.36   0.018      .393459    4.227593\n-----------------------------+----------------------------------------------------------------\ntime                         |\n                        _ns1 |  -14.65779   5.375015    -2.73   0.006    -25.19263   -4.122953\n                        _ns2 |   5.887241    2.32776     2.53   0.011     1.324915    10.44957\n                        _ns3 |  -.1530168   .4739203    -0.32   0.747    -1.081884      .77585\n                        _ns4 |  -.2829653   .4219911    -0.67   0.503    -1.110053    .5441221\n                        _ns5 |  -.1131354   .3294513    -0.34   0.731    -.7588481    .5325774\n                             |\n              dep#c._ns_tvc1 |\n                          5  |   1.100971   .7883876     1.40   0.163    -.4442405    2.646182\n                             |\n              dep#c._ns_tvc2 |\n                          5  |    .187929   .4241331     0.44   0.658    -.6433566    1.019215\n                             |\n              dep#c._ns_tvc3 |\n                          5  |   .0426729   .0602108     0.71   0.478    -.0753381     .160684\n                             |\n           female#c._ns_tvc1 |\n                          1  |  -.1184546   .7751156    -0.15   0.879    -1.637653    1.400744\n                             |\n           female#c._ns_tvc2 |\n                          1  |  -.0180684   .4172699    -0.04   0.965    -.8359023    .7997655\n                             |\n           female#c._ns_tvc3 |\n                          1  |   .0901707   .0600834     1.50   0.133    -.0275906    .2079319\n                             |\nc._ns_f1_agediag1#c._ns_tvc1 |  -6.021449   30.79645    -0.20   0.845    -66.38139    54.33849\n                             |\nc._ns_f1_agediag1#c._ns_tvc2 |  -11.14933   15.88018    -0.70   0.483     -42.2739    19.97524\n                             |\nc._ns_f1_agediag1#c._ns_tvc3 |  -.6694085   2.162692    -0.31   0.757    -4.908207     3.56939\n                             |\nc._ns_f1_agediag2#c._ns_tvc1 |   -2.16063   12.96547    -0.17   0.868    -27.57248    23.25122\n                             |\nc._ns_f1_agediag2#c._ns_tvc2 |   1.459072   6.675109     0.22   0.827     -11.6239    14.54205\n                             |\nc._ns_f1_agediag2#c._ns_tvc3 |  -.5614446   .5591487    -1.00   0.315    -1.657356    .5344667\n                             |\nc._ns_f1_agediag3#c._ns_tvc1 |    1.75344   9.352329     0.19   0.851    -16.57679    20.08367\n                             |\nc._ns_f1_agediag3#c._ns_tvc2 |  -3.286367   4.893296    -0.67   0.502    -12.87705    6.304317\n                             |\nc._ns_f1_agediag3#c._ns_tvc3 |   .0178396   .9596607     0.02   0.985    -1.863061     1.89874\n                             |\n                       _cons |  -2.112934   .5808717    -3.64   0.000    -3.251422   -.9744464\n----------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(agediag, df(3))\nThis is a complex model and I would not attempt to interpret individual parameters. However, the model can predict relative survival for any covariate pattern at any time point. For example, the code below predicts relative survival for 50, 65 and 80 year old females in each deprivation group\n. foreach age in 50 65 80 {\n  2.   predict S`age'_dep1 S`age'_dep5, survival timevar(0 5, step(0.1)) ci ///\n&gt;                                    frame(surv_age, mergecreate)        ///\n&gt;                                    at1(agediag `age' dep 1 female 1)       ///\n&gt;                                    at2(agediag `age' dep 5 female 1)                \n  3. }\nPredictions are stored in frame - surv_age\nPredictions are stored in frame - surv_age\nPredictions are stored in frame - surv_age\nI could have performed all 6 predictions in call to predict, but have chosen to loop over ages. Note the use of frame(surv_age, mergecreate). The mergecreate option will create the frame if it does not exist, otherwise it will merge in predictions to the existing frame. It is useful when writing predictions in loops.\nThe predictions can then be plotted.\n\nRelative survival is lower as age increases and lower among those who live in more deprived areas. These are conditional predictions, i.e. prediction conditional on specific covariate patterns. By using standsurv we can obtain marginal predictions in order to obtain an overall summary of relative survival and perform contrasts between different population groups.\n\nUsing standsurv\nstandsurv enables various marginal estimates to be obtained. For a review of marginal measures in survival analysis see our recent International Journal of Epidemiology paper (Syrioupoulou et al. 2020).\nIf an overall population summary of relative survival is required then marginal (standardized) measures can be obtained. For example marginal relative survival is simply the expectation over covariates \\(Z_2\\),\n\\[\nR_M(t) = E\\left[R(t|Z_2) \\right]\n\\]\nIn a modelling framework an estimate can be calculated by obtaining predictions for each of the \\(N\\) individuals in the study at the observed values of their covariates, and then taking an average of these predictions.\n\\[\n\\widehat{R}_{M}(t) =  \\frac{1}{N} \\sum_{i=1}^{N} {\\widehat{R}(t|Z_2=z\\_{2i})}\n\\]\nstandsurv will do these calculations\n. range tt 0 5 101\n(7,232 missing values generated)\n\n. standsurv, surv timevar(tt) ci frame(mrs) ///\n&gt;            atvar(mrs) at1(.) \nNote the at(.) option requests standsurv uses the observed covariate distribution to average over. Here standsurv has predicted a survival function for each of the 7,333 individuals in our study and then taken the average of these functions. The results can then be plotted.\n\nI have overlayed the non-parametric Pohar Perme estimator of marginal relative survival (using stpp) that shows the model is doing a pretty good job, at least in terms of estimating the average well.\nI have referred to this is marginal relative survival. Under assumptions this can be interpreted as marginal net survival. Net survival is survival in the hypothetical situation where it is not possible to die from other causes. For details of these interpretations and of the assumptons, see (Lambert et al. 2015, Pavlic, K. & Pohar Perme 2018).\nThis measure is a summary for our population, but there is often interest in comparing different population subgroups. In these comparisons it is important to account for the fact that the age (and other covariate) distribution may be different between the groups being compared. This is where standsurv is useful through allowing one to “force” the same covariate distribution on both groups.\nNote that in the relative survival framework it is common to standardise to an external age distribution. This is shown in a separate tutorial and here I will use the covariate distribution observed in the study.\nThe key issue is that by applying a simple comparison of marginal relative survival betwen population groups, the differences could be due to differences in the covariate distribution between the groups. For example. if one group was older an average then this could explain any observed difference in marginal relative survival.\nWith two or more population groups it is useful to perform contrasts. Here we will compare the absolute difference in marginal relative survival between the two deprivation groups.\nTo illustrate the methods I will compare the least and the most deprived individuals. First I will average over the combined covariate distribution of the two groups. The estimand of interest here is as follows,\n\\[\nE\\left[R(t|X=1,Z_2\\right)] - E\\left[R(t|X=0,Z_2\\right)]\n\\]\nHere \\(X\\) denotes a binary exposure (deprivation group in our case) with \\(X=1\\) denoting the most deprived and \\(X=0\\) denoting the least deprived. Thus, the left hand term is the marginal relative survival among the exposed and the right hand term is the marginal relative survival among the unexposed.\nThis can be estimated using using two standardized survival functions, one where all individuals are forced to be exposed and one where there are forced to be unexposed.\n\\[\n\\frac{1}{N}\\sum_{i=1}^N{\\widehat{R}(t|X=1,Z_2=z_{2i})} - \\frac{1}{N}\\sum_{i=1}^N{\\widehat{R}(t|X=0,Z_2=z_{2i})}\n\\]\nThe code required for standsurv to estimate this is a follows,\n. standsurv, surv frame(mrs, merge) ci                  ///\n&gt;            atvar(ms_dep1a ms_dep5a)                   ///\n&gt;            at1(dep 1) at2(dep 5)                      ///\n&gt;            contrast(difference) contrastvar(ms_diffa)\n\n.            \nNote that even though there are interactions in the model, standsurv will incorporate these. In stpm2 this was not the case. By using at1(dep5 1) we force everyone to be in the least deprived group and using at2(dep 5) forces everyone to be in the most deprived group.\nThe resulting predictions can then be plotted.\n\nAn important point here is that we have not averaged over the covariate pattern within each deprivation group as the distribution of age and sex will be different and thus could potentially explain any differences we see. We have averaged over same covariate distribution (of age and sex). The estimate in each group is hypothetical in that it is the estimated relative survival if each of the deprivation groups had the age/sex distribution of the group as a whole. It is done to give a “fair” comparison.\nWhen performing standardization, it is possible to standardise to the covariate distribution of one of the groups, so at least one of the groups does not have a hypothetical covariate distribution. In the code below I use an if statement to restrict the standardisation to the covariate distribution among the deprived group.\n. standsurv if dep==5, surv ci frame(mrs, merge) ///\n&gt;                      atvar(ms_dep1b ms_dep5b)  ///\n&gt;                      at1(dep 1) at2(dep 5)   \nThe resulting predictions can then be plotted.\n\nYou probably can’t see much of a difference between the different graphs in this case as the age/sex distribution is very similar between the two groups.\n. tab sex dep, row\n\n+----------------+\n| Key            |\n|----------------|\n|   frequency    |\n| row percentage |\n+----------------+\n\n           |          dep\n       sex |         1          5 |     Total\n-----------+----------------------+----------\n      Male |     2,122      1,703 |     3,825 \n           |     55.48      44.52 |    100.00 \n-----------+----------------------+----------\n    Female |     1,949      1,559 |     3,508 \n           |     55.56      44.44 |    100.00 \n-----------+----------------------+----------\n     Total |     4,071      3,262 |     7,333 \n           |     55.52      44.48 |    100.00 \n\n. tabstat agediag, by(dep)               \n\nSummary for variables: agediag\nGroup variable: dep \n\n   dep |      Mean\n-------+----------\n     1 |  71.47067\n     5 |  71.12984\n-------+----------\n Total |  71.31905\n------------------\nAn important point here is that the above analysis is fine for internal comparisons for this study, but could not be directly compared to other studies where the age/sex distribution could be different. See the tutorial on external standardzation in relative survival for how this can be done."
  },
  {
    "objectID": "software/standsurv/standardized_relative_survival.html#references",
    "href": "software/standsurv/standardized_relative_survival.html#references",
    "title": "Standardized relative survival",
    "section": "References",
    "text": "References\nLambert, P. C.; Dickman, P. W. & Rutherford, M. J. Comparison of approaches to estimating age-standardized net survival. BMC Med Res Methodol 2015;15:64\nNelson, C. P.; Lambert, P. C.; Squire, I. B. & Jones, D. R. Flexible parametric models for relative survival, with application in coronary heart disease. Statistics in Medicine 2007;26:5486-5498\nPavlic, K. & Pohar Perme, M. Using pseudo-observations for estimation in relative survival. Biostatistics 2018;20:384-399\nSyriopoulou, E.; Rutherford, M. J. & Lambert, P. C. Marginal measures and causal effects using the relative survival framework. International Journal of Epidemiology 2020;49:619–628"
  },
  {
    "objectID": "software/standsurv/standardized_survival_AF.html",
    "href": "software/standsurv/standardized_survival_AF.html",
    "title": "Attributable Fraction from Standardized Survival Functions",
    "section": "",
    "text": "This example will demonstrate how the attributable fraction (\\(AF\\)) can be obtained for survival data. It will also demonstrate the flexibility to calculate various function of standardized estimates through use of the userfunction() option.\nThe is defined in epidemiology as the proportion of preventable outcomes if all subjects had not been exposed to a particular exposure. i.e.\n\\[\nAF = \\frac{P(D=1) - P(D=1|X=0)}{P(D=1)}\n\\]\nwhere \\(P(D)\\) is proportion diseased in the whole population, and \\(P(D|X=0)\\) is the probability of being diseased in the exposed. In observation studies there will be confounding and thus we need to consider potential confounders, \\(Z\\).\n\\[\nAF = \\frac{E(D=1|Z) - E(D=1|X=0,Z)}{P(D|Z)}\n\\]\nIn survival studies the probability of being diseased is a function of time, so we define the \\(AF\\) using the failure function, \\(F(t) = 1 - S(t)\\), so \\(AF(t)\\) is defined as\n\\[\nAF(t) = \\frac{E[F(t|Z)] - E[F(t|X=0,Z)]}{E[F(t|Z)]} = 1 - \\frac{E[F(t|X=0,Z)]}{E[F(t|Z)]}\n\\]\n\\(E[F(t|Z)]\\) is the standardized failure function over covariate distribution, \\(Z\\), and \\(E[F(t|X=0,Z)]\\) is the standardized failure function over covariate distribution, \\(Z\\) where all subjects forced to be unexposed. See Samualson (2008) for some background."
  },
  {
    "objectID": "software/standsurv/standardized_survival_AF.html#example",
    "href": "software/standsurv/standardized_survival_AF.html#example",
    "title": "Attributable Fraction from Standardized Survival Functions",
    "section": "Example",
    "text": "Example\nI will use the Rotterdam Breast cancer data. The code below loads and stset’s the data and then fits a model using stpm3.\n. clear all\n\n. use https://www.pclambert.net/data/rott3, \n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm3 i.hormon age enodes pr_1, scale(lncumhazard) df(4) eform nolog \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  = 619.62\nLog likelihood = -2668.4925                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .7906432   .0715077    -2.60   0.009       .66221    .9439854\n         age |   1.013244   .0024119     5.53   0.000     1.008528    1.017983\n      enodes |   .1132534   .0110135   -22.40   0.000     .0935998    .1370337\n        pr_1 |   .9064855   .0119282    -7.46   0.000     .8834055    .9301685\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -25.90082   1.871965   -13.84   0.000     -29.5698   -22.23184\n        _ns2 |   7.980587   1.003724     7.95   0.000     6.013324    9.947851\n        _ns3 |  -1.091126   .0461407   -23.65   0.000     -1.18156   -1.000691\n        _ns4 |    -.70103   .0504635   -13.89   0.000    -.7999366   -.6021234\n       _cons |    .801967    .161537     4.96   0.000     .4853603    1.118574\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nIt is worthwhile commenting what we mean be “exposed” here. Those on hormal treatment will be consided unexposed and those not taking the treatment will be exposed, i.e our unexposed group is when hormon=1.\nI will first use the failure option to calculate the standardized failure probabilities in both groups. I also predict the failure probability in the population as a whole. I do this using . within an at option, i.e. using at3(.) in the example below.\n. range timevar 0 10 101\n(2,881 missing values generated)\n\n. standsurv, failure timevar(timevar) ci frame(Ft, replace)             ///\n&gt;            at1(hormon 0) at2(hormon 1) at3(.) atvar(F_hormon0 F_hormon1 F_all)\n\n. frame Ft {\n.   twoway (line F_hormon0 timevar)                                       ///\n&gt;          (line F_hormon1 timevar)                                       ///\n&gt;          (line F_all timevar),                                          ///\n&gt;           legend(order(1 \"No treatment\" 2 \"Treatment\" 3 \"All\") pos(11)) /// \n&gt;           ylabel(, format(%3.1f))                                       ///\n&gt;           ytitle(\"S(t)\")                                                ///\n&gt;           xtitle(\"Years from surgery\") \n. }\n\nThese are just 1 - the standardized survival functions. There are more untreated women (88.6%) which is why the “No Treatment” function is closer to the combined function. The attributable fraction could be calculated using\n. frame Ft {\n.   gen AF_tmp = 1 - F_hormon1/F_all\n(1 missing value generated)\n.   list timevar F_hormon1 F_all AF_tmp if inlist(timevar,1,5,10), noobs\n\n  +---------------------------------------------+\n  | timevar   F_hormon1       F_all      AF_tmp |\n  |---------------------------------------------|\n  |       1   .01685169   .02035349   .17204904 |\n  |       5   .22362896   .26167585   .14539701 |\n  |      10   .39250923   .44808119   .12402208 |\n  +---------------------------------------------+\n. }\nI have listed the \\(AF\\) at 1, 5 and 10 years. If I just wanted a point estimate I could stop here. However, generally we will want to calculate confidence intervals. This is where the userfunction() option comes in. We can calculate a transformation of our standardized estimates with standard errors estimated using the delta method where derivatives are calculated numerically (similar to nlcom and predictnl). I “borrowed” the idea of a userfunction() from Arvid Sjölander’s stdReg R package (Sjölander 2018).\nThe user function needs to be written in Mata. The function should receive one argument at, which refer to the various at options and can be indexed by at[1], at[2] etc. The code below calculates the AF assuming that at1 is the standardized failure function in the population as a whole and at2 is the standardized failure function assuming everyone is unexposed (takes hormonal treatment). We need to be careful to specify the at() options is this order.\n. mata\n------------------------------------------------- mata (type end to exit) -----------------------------------------------------------------------\n: function calcAF(at) {\n&gt;     // at2 is F(t|unexposed,Z)\n&gt;     // at1 is F(t,Z)\n&gt;     return(1 - at[2]/at[1])\n&gt; }\n\n: end\n-------------------------------------------------------------------------------------------------------------------------------------------------\nHaving defined the Mata function I just pass this to standsurv using the userfunction() option.\n. standsurv, failure timevar(timevar) ci frame(Ft2, replace)   ///\n&gt;            at1(.) at2(hormon 0) atvar(F_hormon1 F_all)       ///    \n&gt;            userfunction(calcAF) userfunctionvar(AF) \nI have specified the userfunctionvar(AF) option so that the new variable is called AF. Without this option the default is _userfunc. I can now plot the AF as a function of follow-up time.\n. frame Ft2 {\n.   twoway (rarea AF_lci AF_uci timevar, color(red%30)) ///\n&gt;          (line AF timevar, lcolor(red))               ///\n&gt;          , legend(off)                                /// \n&gt;          ylabel(0(0.05)0.3, format(%4.2f))            ///\n&gt;          ytitle(\"AF\")                                 ///\n&gt;          xtitle(\"Years from surgery\") \n. }\n\nI purposely chose for the effect of hormonal treatment to be proportional as this example is illustrative. When I relaxed this assumption, the AF was negative for the first few months.\nSamualson (2008) defines alternative based on the hazard function. I am less keen on this than the use of the survival function, but show how this can be estimated using standsurv for completeness.\nSamualson defines this is the attributable hazard fraction. The equation is similar to the AF defined above, but we replace the failure function with the hazard function.\n\\[\nAHF(t) = \\frac{E[\\lambda(t|Z)] - E[\\lambda(t|X=0,Z)]}{E[\\lambda(t|Z)]} = 1 - \\frac{E[\\lambda(t|X=0,Z)]}{E[\\lambda(t|Z)]}\n\\]\nThis give the proportion of preventable events at time \\(t\\) rather than by time \\(t\\).\nSee the page of The hazard function of the standardized survival curve. for a description of standardized hazard functions.\nAs I just have to replace the failure probability with the hazard function, I can just use the same Mata function. This means that I just have the change the option failure to hazard in standsurv.\n. standsurv, hazard timevar(timevar) ci frame(haz, replace)   ///\n&gt;            at1(.) at2(hormon 0) atvar(F_hormon1 F_all)      ///    \n&gt;            userfunction(calcAF) userfunctionvar(AHF) \nI can now plot the results.\n. frame haz {\n.   twoway (rarea AHF_lci AHF_uci timevar, color(red%30)) ///\n&gt;          (line AHF timevar, lcolor(red))                ///\n&gt;          , legend(off)                                  /// \n&gt;          ylabel(0(0.05)0.3, format(%4.2f))              ///\n&gt;          ytitle(\"AHF\")                                  ///\n&gt;          xtitle(\"Years from surgery\") \n. }"
  },
  {
    "objectID": "software/standsurv/standardized_survival_AF.html#references",
    "href": "software/standsurv/standardized_survival_AF.html#references",
    "title": "Attributable Fraction from Standardized Survival Functions",
    "section": "References",
    "text": "References\nSamuelsen S.O., Eide G.E. Attributable fractions with survival data. Statistics in Medicine 2008;27:1447–1467\nSjölander A. Estimation of causal effect measures with the R-package stdReg.European Journal of Epidemiology 2018"
  },
  {
    "objectID": "software/standsurv/standardized_survival_hazard.html",
    "href": "software/standsurv/standardized_survival_hazard.html",
    "title": "Hazard of Standardized Survival Functions",
    "section": "",
    "text": "This will be a short tutorial as the ideas are very simple. I have previously discussed standardized survival functions. In survival analysis we know that there is a simple mathematical transformation from hazard to survival function and vice versa. The idea here is to transform to a hazard function from the standardized survival function. Recall that a standardized survival funnction; \\(S_s(t|X=x,Z)\\) is estimated by\n\\[\nS_s(t|X=x,Z) = \\frac{1}{N}\\sum_{i=1}^{N}S(t|X=x,Z=z_i)\n\\]\nIf we apply the usual transformation from survival to hazard to function (\\(h(t) = \\frac{-d}{dt}\\log[S(t)]\\)) we get\n\\[\nh_s(t|X=x,Z) = \\frac{\\sum_{i=1}^{N}S(t|X=x,Z=z_i)h(t|X=x,Z=z_i)}{\\sum_{i=1}^{N}S(t|X=x,Z=z_i)}\n\\]\nThis is a weighted average of the \\(N\\) individual hazard functions with weights equal to \\(S(t|X=x,Z=z_i)\\), i.e. the predicted survival function for individual \\(i\\) when forced to take a specific value of the exposure variable, \\(X\\), but their observed values of confounding variables, \\(Z\\).\nThis is implemented in standsurv using the hazard option."
  },
  {
    "objectID": "software/standsurv/standardized_survival_hazard.html#example",
    "href": "software/standsurv/standardized_survival_hazard.html#example",
    "title": "Hazard of Standardized Survival Functions",
    "section": "Example",
    "text": "Example\nI will use the Rotterdam Breast cancer data. The code below loads and stset’s the data and then fits a model using stpm3.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm3 hormon age enodes pr_1, scale(lncumhazard) df(4) eform nolog tvc(hormon) dftvc(3)\n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  = 615.95\nLog likelihood = -2666.5968                             Prob &gt; chi2   = 0.0000\n\n-------------------------------------------------------------------------------------\n                    |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\nxb                  |\n             hormon |   .8499802   .0963501    -1.43   0.152     .6806444    1.061445\n                age |   1.013249   .0024115     5.53   0.000     1.008534    1.017987\n             enodes |   .1132408    .011008   -22.41   0.000     .0935963    .1370084\n               pr_1 |   .9061179   .0119267    -7.49   0.000     .8830411    .9297979\n--------------------+----------------------------------------------------------------\ntime                |\n               _ns1 |  -27.09524   2.109681   -12.84   0.000    -31.23014   -22.96034\n               _ns2 |   8.647725   1.122097     7.71   0.000     6.448455    10.84699\n               _ns3 |  -1.072205   .0477674   -22.45   0.000    -1.165827   -.9785823\n               _ns4 |  -.6930019   .0518048   -13.38   0.000    -.7945373   -.5914664\n                    |\nc.hormon#c._ns_tvc1 |   5.425507    3.92237     1.38   0.167    -2.262197    13.11321\n                    |\nc.hormon#c._ns_tvc2 |  -3.309698   2.096769    -1.58   0.114    -7.419291    .7998943\n                    |\nc.hormon#c._ns_tvc3 |  -.1256484    .195217    -0.64   0.520    -.5082667      .25697\n                    |\n              _cons |   .7984459   .1615956     4.94   0.000     .4817244    1.115168\n-------------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nI have made the effect of our exposure, hormon, time-dependent using the tvc option.\nI first calculate the standardized survival curves where everyone is forced to be exposed and then unexposed.\n. range timevar 0 10 100\n(2,882 missing values generated)\n\n. standsurv, surv timevar(timevar) ci frame(surv, replace) ///\n&gt;            at1(hormon 0) at2(hormon 1) atvar(S0 S1)      ///\n&gt;            contrast(difference) contrastvar(Sdiff) \n\n. \n. frame surv {\n.   twoway (rarea S0_lci S0_uci timevar, color(red%25))                     ///\n&gt;          (rarea S1_lci S1_uci timevar, color(blue%25))                    ///\n&gt;          (line S0 timevar, sort lcolor(red))                              ///\n&gt;          (line S1  timevar, sort lcolor(blue))                            ///\n&gt;          , legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ///\n&gt;                   ring(0) cols(1) pos(1))                                 ///\n&gt;          ylabel(0.5(0.1)1,angle(h) format(%3.1f))                         ///\n&gt;          ytitle(\"S(t)\")                                                   ///\n&gt;          xtitle(\"Years from surgery\")\n. }\n\nIf I run standsurv again with the hazard option I get the corresponding hazard functions of the standardized curves. This is the marginal hazard ratio (as a function of time).\n. standsurv, hazard  timevar(timevar) ci per(1000) frame(hazard, replace) ///\n&gt;            at1(hormon 0) at2(hormon 1) atvar(h0 h1)                     /// \n&gt;            contrast(ratio) contrastvar(hr)\nPlot the standardized hazard functions.\n. frame hazard {\n.   twoway (rarea h0_lci h0_uci timevar, color(red%30))  ///\n&gt;          (rarea h1_lci h1_uci timevar, color(blue%30)) ///\n&gt;          (line h0 timevar, color(red))                 ///\n&gt;          (line h1 timevar, color(blue))                ///\n&gt;           , legend(off)                                ///\n&gt;           ylabel(,angle(h) format(%3.1f))              ///\n&gt;           xtitle(\"Years from surgery\")   \n. }\n\nI can’t explain the lower and then higher hazard for those on hormon therapy. Perhaps better adjustment for confounders would change this.\nI can also plot the ratio of these two hazard functions with a 95% confidence interval.\n. frame hazard {\n.   twoway (rarea hr_lci hr_uci timevar, color(red%30))      ///\n&gt;          (line hr timevar, color(red))                     ///\n&gt;          if timevar&gt;0, yscale(log)                         ///\n&gt;          ylabel(0.5 1 2 4 8 20 40, angle(h) format(%3.1f)) ///\n&gt;          xtitle(\"Years from surgery\")                      ///\n&gt;          legend(off)                                       ///\n&gt;          yscale(log) \n. }\n\nIf I had used the difference argument of the contrast() option I would have obtained the absolute difference in the standardized hazard functions.\nI am still thinking about the usefulness of this - in general I prefer the idea of standardized survival functions rather than the corresponding hazard function. However, it is harder to see how the risk of events changes over follow-up time with a cumulative measure (i.e. standardized survival)."
  },
  {
    "objectID": "software/standsurv/why_not_stteffects.html",
    "href": "software/standsurv/why_not_stteffects.html",
    "title": "Some comments on using steffects in Stata",
    "section": "",
    "text": "There is a command in Stata called stteffects which calculates marginal effects for survival-time data. This is the description in the helpfile:\n“stteffects estimates average treatment effects, average treatment effects on the treated, and potential-outcome means using observational survival-time data. The available estimators are regression adjustment, inverse-probability weighting, and more efficient methods that combine regression adjustment and inverse-probability weighting.”\nI will concentrate on regression adjustment as this is essentially what standsurv does. The other estimators are just different methods to estimate the same underlying quantities.\nI do not use stteffects as the estimand of interest is based on the mean survival time. In many cases this relies on extrapolation beyond the range of follow-up. In my applications I am not willing to make such strong assumptions. I will illustrate this with an example using the Rotterdam Breast cancer data. The code below loads and stset’s the data. I restrict follow-up time to 5 years as ths highlights some of the extrapolation issues. I would usually use the exit() option of stset to restrict follow-up time, but for some reason sttefects does not allow you to do this.\n. use https://www.pclambert.net/data/rott3 if nodes&gt;0, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. gen os2  = cond(os&lt;(5*12),os,60)\n\n. gen osi2 = cond(os&lt;(5*12),osi,0)\n\n. stset os2, f(osi2==1) scale(12) \n\nSurvival-time data settings\n\n         Failure event: osi2==1\nObserved time interval: (0, os2]\n     Exit on or before: failure\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      1,546  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,546  observations remaining, representing\n        565  failures in single-record/single-failure data\n  6,343.591  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\n\n. \n. sts graph, by(hormon)\n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nI have plotted the Kaplan-Meier curve comparing those who receive and do not receive hormonal treatment, which shows that those taking treatment have slightly better survival. As shown in other examples there is imbalance between the groups for a number of potential confounders. For simplicity, I will just use age at diagnosis and the number of positive lymph nodes as potential confounders.\n. tabstat age nodes ,by(hormon)\n\nSummary statistics: Mean\nGroup variable: hormon (Hormonal therapy)\n\n  hormon |       age     nodes\n---------+--------------------\n      no |  54.12925  5.094449\n     yes |  62.54867  5.719764\n---------+--------------------\n   Total |  55.97542  5.231565\n------------------------------\nThose receiving treatment are older and have slightly more positive lymph nodes.\nI will first use stteffects using regression adjustment (ra) with age and enodes as covariates. I will use the potential outcomes framework,\n\n\\(T^{x=0}\\) is the potential survival time for the non-treated/unexposed.\n\\(T^{x=1}\\) is the potential survival time for the treated/exposed.\n\nAn average causal effect could be defined as the difference in the expected values of these two potential outcomes\n\\[\nE\\left[T^{x=1}\\right] - E\\left[T^{x=0}\\right]\n\\]\nI use stteffects to estimate this below,\n. stteffects ra (age enodes, weibull) (hormon), \n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nIteration 0:  EE criterion =  1.789e-18  \nIteration 1:  EE criterion =  1.067e-29  \n\nSurvival treatment-effects estimation           Number of obs     =      1,546\nEstimator      : regression adjustment\nOutcome model  : Weibull\nTreatment model: none\nCensoring model: none\n------------------------------------------------------------------------------\n             |               Robust\n          _t | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nATE          |\n      hormon |\n(yes vs no)  |   1.067025   1.230018     0.87   0.386    -1.343765    3.477816\n-------------+----------------------------------------------------------------\nPOmean       |\n      hormon |\n         no  |   7.841406   .3771598    20.79   0.000     7.102186    8.580625\n------------------------------------------------------------------------------\nThe output has given the mean potential outcome for those not receiving treatment and the average causal difference (labelled ATE). Thus, the estimated mean survival time is 7.84 years for those not taking treatment and estimated to be 1.07 year lower for those taking treatmnet. The 95% confidence interval for this difference spans zero.\nWhat has stteffects done? Well effectively it has fitted a Weibull regression model that includes age and enodes and hormon and the interactions between enodes and hormon and between age and hormon. It has also allowed the shape parameter of the Weibull model to vary by hormon. This model is the same as fitting separate Weibull models for the untreated and treated groups. It has also estimated the mean survival time if all individuals were untreated and the mean difference in survival time between the treated and untreated. It actually simultaneously estimates all this, but as I will show below, it is doing exactly the same as regression standardization using standsurv.\nI have assumed a Weibull model in the above code, so it is of interest to see if fitting a different model gives notable differences. Below I run steffects again, but now using a lognormal model.\n. stteffects ra (age enodes, lnormal) (hormon), \n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nIteration 0:  EE criterion =  1.716e-25  \nIteration 1:  EE criterion =  9.506e-30  \n\nSurvival treatment-effects estimation           Number of obs     =      1,546\nEstimator      : regression adjustment\nOutcome model  : lnormal\nTreatment model: none\nCensoring model: none\n------------------------------------------------------------------------------\n             |               Robust\n          _t | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nATE          |\n      hormon |\n(yes vs no)  |   3.430201   3.669848     0.93   0.350    -3.762568    10.62297\n-------------+----------------------------------------------------------------\nPOmean       |\n      hormon |\n         no  |   12.56943   1.027354    12.23   0.000     10.55586    14.58301\n------------------------------------------------------------------------------\nThe mean survival time for the non-treated has increased from 7.84 years to 12.57 and the average causal difference has increased from 1.07 years to 3.43 years. This should be concerning has the estimates appear to be strongly dependent on the choice of parametric distribution.\nLet’s explore what is happening here and why the estimates are so different. The code below fits all models available in streg to the non-treated group (hormon=0) and compares the estimated survival functions to the Kaplan-Meier estimate. I am not fitting covariates here as I am just making a point about extrapolating beyond the range of your data.\n\nforeach dist in weibull gompertz loglogistic lognormal ggamma {\n    streg if hormon == 1, dist(`dist')\n    predict surv_`dist', surv\n    estimates store `dist'\n}\n\nsts gen s_km = s if hormon == 1 \ntwoway  (line s_km _t, connect(stairstep) sort lcolor(black))   ///\n        (line surv_* _t, sort),                                 ///\n        legend(order(1 \"Kaplan-Meier\" 2 \"Weibull\" 3 \"Gompertz\"  ///\n                     4 \"LogLogistic\" 5 \"LogNormal\" 6 \"Ggamma\")  ///\n                     ring(0) cols(1) pos(1))                    ///\n        xtitle(\"Years from Surgery\")                            ///\n        ytitle(\"S(t)\")                                          ///\n        ylabel(,format(%3.1f))\n\nNone of the fitted lines are perfect (we will do better with stpm3 later), but are in broad agreement. The problems is we have censored survival data and the maximum follow-up time is 5 years. Mean survival can be calculated as the area under the survival function and so the graph above does not show what we want. I now perform predictions up to 80 years. Here were are extrapolating beyond the range of our follow-up.\n\npreserve\ngen oldt = _t\ndrop _t\nrange _t 0 80\nforeach dist in weibull gompertz loglogistic lognormal ggamma {\n    estimates restore `dist'\n    predict surv80_`dist', surv\n}\n\ntwoway  (line s_km oldt, connect(stairstep) sort lcolor(black)) ///\n        (line surv80_* _t, sort),                               ///\n        legend(order(1 \"Kaplan-Meier\" 2 \"Weibull\" 3 \"Gompertz\"  ///\n                     4 \"LogLogistic\" 5 \"LogNormal\" 6 \"Ggamma\")  ///\n          ring(0) cols(1) pos(1))                               ///\n        xtitle(\"Years from Surgery\")                            ///\n        ytitle(\"S(t)\")                                          ///\n        ylabel(,format(%3.1f))                                  ///\n        xline(5, lpattern(dash))\nrestore     \n\nNow we can see the difference between the estimated survival functions between the different models. There is very little difference up to 5 years, where we have follow-up information to, but they are very different beyond this point. The mean survival time is the area under each curve and we can see why the Weibull model gives a lower mean than the log-normal model. In fact the Log-logistic and Log-Normal model are still clearly above zero at 80 years.\nWhat does this mean? Well if you have a lot of censoring and the survival function is clearly above zero at the end of your follow-up then you are making strong assumptions about what happens beyond where you have data if you use stteffects."
  },
  {
    "objectID": "software/standsurv/why_not_stteffects.html#using-stteffects",
    "href": "software/standsurv/why_not_stteffects.html#using-stteffects",
    "title": "Some comments on using steffects in Stata",
    "section": "",
    "text": "There is a command in Stata called stteffects which calculates marginal effects for survival-time data. This is the description in the helpfile:\n“stteffects estimates average treatment effects, average treatment effects on the treated, and potential-outcome means using observational survival-time data. The available estimators are regression adjustment, inverse-probability weighting, and more efficient methods that combine regression adjustment and inverse-probability weighting.”\nI will concentrate on regression adjustment as this is essentially what standsurv does. The other estimators are just different methods to estimate the same underlying quantities.\nI do not use stteffects as the estimand of interest is based on the mean survival time. In many cases this relies on extrapolation beyond the range of follow-up. In my applications I am not willing to make such strong assumptions. I will illustrate this with an example using the Rotterdam Breast cancer data. The code below loads and stset’s the data. I restrict follow-up time to 5 years as ths highlights some of the extrapolation issues. I would usually use the exit() option of stset to restrict follow-up time, but for some reason sttefects does not allow you to do this.\n. use https://www.pclambert.net/data/rott3 if nodes&gt;0, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. gen os2  = cond(os&lt;(5*12),os,60)\n\n. gen osi2 = cond(os&lt;(5*12),osi,0)\n\n. stset os2, f(osi2==1) scale(12) \n\nSurvival-time data settings\n\n         Failure event: osi2==1\nObserved time interval: (0, os2]\n     Exit on or before: failure\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      1,546  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,546  observations remaining, representing\n        565  failures in single-record/single-failure data\n  6,343.591  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\n\n. \n. sts graph, by(hormon)\n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nI have plotted the Kaplan-Meier curve comparing those who receive and do not receive hormonal treatment, which shows that those taking treatment have slightly better survival. As shown in other examples there is imbalance between the groups for a number of potential confounders. For simplicity, I will just use age at diagnosis and the number of positive lymph nodes as potential confounders.\n. tabstat age nodes ,by(hormon)\n\nSummary statistics: Mean\nGroup variable: hormon (Hormonal therapy)\n\n  hormon |       age     nodes\n---------+--------------------\n      no |  54.12925  5.094449\n     yes |  62.54867  5.719764\n---------+--------------------\n   Total |  55.97542  5.231565\n------------------------------\nThose receiving treatment are older and have slightly more positive lymph nodes.\nI will first use stteffects using regression adjustment (ra) with age and enodes as covariates. I will use the potential outcomes framework,\n\n\\(T^{x=0}\\) is the potential survival time for the non-treated/unexposed.\n\\(T^{x=1}\\) is the potential survival time for the treated/exposed.\n\nAn average causal effect could be defined as the difference in the expected values of these two potential outcomes\n\\[\nE\\left[T^{x=1}\\right] - E\\left[T^{x=0}\\right]\n\\]\nI use stteffects to estimate this below,\n. stteffects ra (age enodes, weibull) (hormon), \n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nIteration 0:  EE criterion =  1.789e-18  \nIteration 1:  EE criterion =  1.067e-29  \n\nSurvival treatment-effects estimation           Number of obs     =      1,546\nEstimator      : regression adjustment\nOutcome model  : Weibull\nTreatment model: none\nCensoring model: none\n------------------------------------------------------------------------------\n             |               Robust\n          _t | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nATE          |\n      hormon |\n(yes vs no)  |   1.067025   1.230018     0.87   0.386    -1.343765    3.477816\n-------------+----------------------------------------------------------------\nPOmean       |\n      hormon |\n         no  |   7.841406   .3771598    20.79   0.000     7.102186    8.580625\n------------------------------------------------------------------------------\nThe output has given the mean potential outcome for those not receiving treatment and the average causal difference (labelled ATE). Thus, the estimated mean survival time is 7.84 years for those not taking treatment and estimated to be 1.07 year lower for those taking treatmnet. The 95% confidence interval for this difference spans zero.\nWhat has stteffects done? Well effectively it has fitted a Weibull regression model that includes age and enodes and hormon and the interactions between enodes and hormon and between age and hormon. It has also allowed the shape parameter of the Weibull model to vary by hormon. This model is the same as fitting separate Weibull models for the untreated and treated groups. It has also estimated the mean survival time if all individuals were untreated and the mean difference in survival time between the treated and untreated. It actually simultaneously estimates all this, but as I will show below, it is doing exactly the same as regression standardization using standsurv.\nI have assumed a Weibull model in the above code, so it is of interest to see if fitting a different model gives notable differences. Below I run steffects again, but now using a lognormal model.\n. stteffects ra (age enodes, lnormal) (hormon), \n\n        Failure _d: osi2==1\n  Analysis time _t: os2/12\n\nIteration 0:  EE criterion =  1.716e-25  \nIteration 1:  EE criterion =  9.506e-30  \n\nSurvival treatment-effects estimation           Number of obs     =      1,546\nEstimator      : regression adjustment\nOutcome model  : lnormal\nTreatment model: none\nCensoring model: none\n------------------------------------------------------------------------------\n             |               Robust\n          _t | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nATE          |\n      hormon |\n(yes vs no)  |   3.430201   3.669848     0.93   0.350    -3.762568    10.62297\n-------------+----------------------------------------------------------------\nPOmean       |\n      hormon |\n         no  |   12.56943   1.027354    12.23   0.000     10.55586    14.58301\n------------------------------------------------------------------------------\nThe mean survival time for the non-treated has increased from 7.84 years to 12.57 and the average causal difference has increased from 1.07 years to 3.43 years. This should be concerning has the estimates appear to be strongly dependent on the choice of parametric distribution.\nLet’s explore what is happening here and why the estimates are so different. The code below fits all models available in streg to the non-treated group (hormon=0) and compares the estimated survival functions to the Kaplan-Meier estimate. I am not fitting covariates here as I am just making a point about extrapolating beyond the range of your data.\n\nforeach dist in weibull gompertz loglogistic lognormal ggamma {\n    streg if hormon == 1, dist(`dist')\n    predict surv_`dist', surv\n    estimates store `dist'\n}\n\nsts gen s_km = s if hormon == 1 \ntwoway  (line s_km _t, connect(stairstep) sort lcolor(black))   ///\n        (line surv_* _t, sort),                                 ///\n        legend(order(1 \"Kaplan-Meier\" 2 \"Weibull\" 3 \"Gompertz\"  ///\n                     4 \"LogLogistic\" 5 \"LogNormal\" 6 \"Ggamma\")  ///\n                     ring(0) cols(1) pos(1))                    ///\n        xtitle(\"Years from Surgery\")                            ///\n        ytitle(\"S(t)\")                                          ///\n        ylabel(,format(%3.1f))\n\nNone of the fitted lines are perfect (we will do better with stpm3 later), but are in broad agreement. The problems is we have censored survival data and the maximum follow-up time is 5 years. Mean survival can be calculated as the area under the survival function and so the graph above does not show what we want. I now perform predictions up to 80 years. Here were are extrapolating beyond the range of our follow-up.\n\npreserve\ngen oldt = _t\ndrop _t\nrange _t 0 80\nforeach dist in weibull gompertz loglogistic lognormal ggamma {\n    estimates restore `dist'\n    predict surv80_`dist', surv\n}\n\ntwoway  (line s_km oldt, connect(stairstep) sort lcolor(black)) ///\n        (line surv80_* _t, sort),                               ///\n        legend(order(1 \"Kaplan-Meier\" 2 \"Weibull\" 3 \"Gompertz\"  ///\n                     4 \"LogLogistic\" 5 \"LogNormal\" 6 \"Ggamma\")  ///\n          ring(0) cols(1) pos(1))                               ///\n        xtitle(\"Years from Surgery\")                            ///\n        ytitle(\"S(t)\")                                          ///\n        ylabel(,format(%3.1f))                                  ///\n        xline(5, lpattern(dash))\nrestore     \n\nNow we can see the difference between the estimated survival functions between the different models. There is very little difference up to 5 years, where we have follow-up information to, but they are very different beyond this point. The mean survival time is the area under each curve and we can see why the Weibull model gives a lower mean than the log-normal model. In fact the Log-logistic and Log-Normal model are still clearly above zero at 80 years.\nWhat does this mean? Well if you have a lot of censoring and the survival function is clearly above zero at the end of your follow-up then you are making strong assumptions about what happens beyond where you have data if you use stteffects."
  },
  {
    "objectID": "software/standsurv/why_not_stteffects.html#equivalent-model-using-stpm3-and-standsurv",
    "href": "software/standsurv/why_not_stteffects.html#equivalent-model-using-stpm3-and-standsurv",
    "title": "Some comments on using steffects in Stata",
    "section": "Equivalent model using stpm3 and standsurv",
    "text": "Equivalent model using stpm3 and standsurv\nI will show that I can get the same estimates as stteffects by fitting an stpm3 model followed by using standsurv.\n. stpm3 i.hormon##(c.age c.enodes), ///\n&gt;       scale(lncumhazard) df(1) eform nolog tvc(i.hormon) dftvc(1)\n\n                                                        Number of obs =  1,546\n                                                        Wald chi2(5)  = 163.86\nLog likelihood = -1329.3579                             Prob &gt; chi2   = 0.0000\n\n-----------------------------------------------------------------------------------\n                  |     exp(b)   Std. err.      z    P&gt;|z|     [95% conf. interval]\n------------------+----------------------------------------------------------------\nxb                |\n           hormon |\n             yes  |   .9289452   .7141543    -0.10   0.924      .205875    4.191569\n              age |   1.013167   .0036718     3.61   0.000     1.005996    1.020389\n           enodes |   .1548263   .0282304   -10.23   0.000     .1083029    .2213345\n                  |\n     hormon#c.age |\n             yes  |   .9973785   .0109109    -0.24   0.810     .9762212    1.018994\n                  |\n  hormon#c.enodes |\n             yes  |   .5988075   .2563495    -1.20   0.231     .2587545    1.385756\n------------------+----------------------------------------------------------------\ntime              |\n             _ns1 |   1.511474   .0660271    22.89   0.000     1.382064    1.640885\n                  |\nhormon#c._ns_tvc1 |\n             yes  |   .1523244   .1565794     0.97   0.331    -.1545657    .4592145\n                  |\n            _cons |  -2.790261   .2543394   -10.97   0.000    -3.288757   -2.291765\n-----------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\nI have used df(1) as this is equivalent to a Weibull model. By using tvc(i.hormon) and dftvc(1) I have allowed the shape parameter of the Weibull model to vary between those receiving and not-receiving treatment. I could have fitted separate models by treatment group and the parameter estimates would be the same, but by fitting one model I will be able to form contrasts between the treatment groups using standsurv.\nI will now standsurv to estimate the marginal survival functions up to 40 years for the non-treated and treated subjects.\n. range ttlong 0 40 100\n(1,446 missing values generated)\n\n. standsurv, surv  timevar(ttlong) ci frame(survextrap, replace)   ///\n&gt;            at1(hormon 0)                                         ///\n&gt;            at2(hormon 1)                                         ///\n&gt;            atvar(S_h0b S_h1b)\nThe two survival functions can then plotted. A reference line at 5 years has been added to indicate where we have follow-up information to.\n. frame survextrap {\n.   twoway (line S_h0b ttlong, sort lcolor(red))                            ///\n&gt;          (line S_h1b ttlong, sort lcolor(blue))                           ///\n&gt;          , legend(order(1 \"No hormonal treatment\" 2 \"Hormonal treatment\") ///\n&gt;                   ring(0) cols(1) pos(1))                                 ///\n&gt;          ylabel(0(0.1)1,angle(h) format(%3.1f))                           ///\n&gt;          ytitle(\"S(t)\")                                                   ///\n&gt;          xtitle(\"Years from surgery\")                                       ///\n&gt;          xline(5, lpattern(dash) lcolor(black%50))\n. }\n\nThe estimated average potential outcome for the untreated can be approximated by using integ to approximate the area under the survival curve (I will use standsurv to do this better shortly).\n. frame survextrap: integ S_h0b ttlong\n\nnumber of points = 100\n\nintegral         = 7.8376078\nThis is similar to the output from stteffects above (7.841406 vs 7.8376079). Using the rmst option of standsurv will do more accurate integration. I will integrate up to 100 years (theoretically the integral is to infinity, but the survival is virtually zero at 100 years). rmst stands for restricted mean survival time, but if \\(t\\) is large enough so that \\(S(t)\\approx 0\\) then this is effectively the area under the full survival curve.\n. gen tt100 = 100 in 1 \n(1,545 missing values generated)\n\n. standsurv, rmst ci  timevar(tt100) trans(none) frame(survextrap2, replace) ///\n&gt;            at1(hormon 0)                                                   ///\n&gt;            at2(hormon 1)                                                   ///\n&gt;            atvars(rmst_h0 rmst_h1)                                         /// \n&gt;            contrast(difference)                                            ///\n&gt;            contrastvar(rmstdiff100) \n\n. frame survextrap2: list rmst_h0 rmst_h1 rmstdiff100* in 1, noobs\n\n  +-----------------------------------------------------------+\n  |   rmst_h0     rmst_h1   rmstd~100   rmstdi~lci   r~00_uci |\n  |-----------------------------------------------------------|\n  | 7.8414068   8.9084312   1.0670245   -1.1583821   3.292431 |\n  +-----------------------------------------------------------+\nI have used the mestimation option to calculate the equivalent of robust standard errors so that these and the confidence intervals are comparable with stteffects. I have also used the trans(none) option as sttefects calculates standard errors on the untransformed survival scale, while the default in standsurv is the log scale.\nThe estimates are now very similar to stteffects (to 4 or 5 decimal places).\nThis has shown that I can obtain the same estimates as stteffects using standsurv, but generally I would not be happy in doing so as to obtain the estimated mean of the potential outcomes I have had to extrapolate my two survival functions way beyond the end of follow-up. I am not sure is this is obvious to users of stteffects."
  },
  {
    "objectID": "software/standsurv/why_not_stteffects.html#using-restricted-mean-survival-time-rmst-as-an-alternative.",
    "href": "software/standsurv/why_not_stteffects.html#using-restricted-mean-survival-time-rmst-as-an-alternative.",
    "title": "Some comments on using steffects in Stata",
    "section": "Using restricted mean survival time (RMST) as an alternative.",
    "text": "Using restricted mean survival time (RMST) as an alternative.\nI have previous discussed using RMST in another tutorial. As a reminder the restricted mean survival time at time \\(t^\\*\\) is defined as, \\[\nE\\left[min(t,t^*)\\right]\n\\] i.e. it is the mean up to some point \\(t^\\*\\). The RMST can be estimated by calculating the area under the survival curve between 0 and \\(t^\\*\\). In an observational study where we need to take account of potential confounders, we can define the RMST of the standardized survival function as\n\\[\nRMST(t^\\*|X=x,Z) = \\int_0^{t^\\*} E\\left[S(t|X=x,Z)\\right]\n\\]\nWe used the rmst option of standsurv above, but integrated the survival function to 100 years, to where \\(S(t)\\approx 0\\). So if we feed the timevar option a lower value of \\(t\\), then we can calculate RMST to a point within our follow-up period. In the code below I use 5 years.\n. gen tt5 = 5 in 1 \n(1,545 missing values generated)\n\n. standsurv, rmst ci  timevar(tt5) trans(none) frame(rmst5) ///\n&gt;            at1(hormon 0)                                  ///\n&gt;            at2(hormon 1)                                  ///\n&gt;            atvars(rmst5_h0 rmst5_h1)                      ///\n&gt;            contrast(difference)                           ///\n&gt;            contrastvar(rmstdiff5) \n\n. frame rmst5: list rmst5_h0 rmst5_h1 rmstdiff5* in 1, noobs\n\n  +-----------------------------------------------------------+\n  |  rmst5_h0    rmst5_h1   rmstdiff5   rmstd~lci   rmstd~uci |\n  |-----------------------------------------------------------|\n  | 4.1250222   4.3241716   .19914941   .04742237   .35087645 |\n  +-----------------------------------------------------------+\nWe get a difference of 0.199 (95% CI 0.055 to 0.343) years between the two groups. The difference in RMST can still be interpreted as a causal effect under the usual assumptions, but, unlike stteffects, does not reply on extrapolation. Alternatively, the difference in standardized survival functions could be presented."
  },
  {
    "objectID": "software/standsurv/why_not_stteffects.html#references",
    "href": "software/standsurv/why_not_stteffects.html#references",
    "title": "Some comments on using steffects in Stata",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "software/stcrprep/computational_benefits.html",
    "href": "software/stcrprep/computational_benefits.html",
    "title": "stcrprep - computational benefits",
    "section": "",
    "text": "When using stcrprep there are some computational benefits when compared to using Stata’s inbuilt stcrreg. One reason for this is that everytime you fit a model using stcrreg, the probability of censoring weights are calculated and the data must be expanded (in the background) when maximising the likelihood. When using stcrprep the data is expanded once and then diffenet models can be fitted to this expanded data.\nI have run some timings. If I fit a simple model to the embt1 data with risk score as the only covariate (2 dummy variables) then these are the timings on my current work laptop (Intel i5 - running Stata 15 MP4).\nFirst I load and stset the data.\n. use https://www.pclambert.net/data/ebmt1_stata.dta, clear\n(Written by R.              )\n\n. stset time, failure(status==1) scale(365.25) id(patid) noshow\n\nSurvival-time data settings\n\n           ID variable: patid\n         Failure event: status==1\nObserved time interval: (time[_n-1], time]\n     Exit on or before: failure\n     Time for analysis: time/365.25\n\n--------------------------------------------------------------------------\n      1,977  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      1,977  observations remaining, representing\n      1,977  subjects\n        456  failures in single-failure-per-subject data\n  3,796.057  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =  8.454483\nNow, I use Stata’s inbuilt stcrreg,\n. timer clear\n\n. timer on 1\n\n. stcrreg i.score, compete(status==2) nolog noshow\n\nCompeting-risks regression                        No. of obs      =      1,977\n                                                  No. of subjects =      1,977\nFailure event:   status == 1                      No. failed      =        456\nCompeting event: status == 2                      No. competing   =        685\n                                                  No. censored    =        836\n\n                                                  Wald chi2(2)    =       9.87\nLog pseudolikelihood = -3333.3217                 Prob &gt; chi2     =     0.0072\n\n                              (Std. err. adjusted for 1,977 clusters in patid)\n------------------------------------------------------------------------------\n             |               Robust\n          _t |        SHR   std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       score |\nMedium risk  |   1.271221   .1554323     1.96   0.050     1.000333    1.615465\n  High risk  |   1.769853   .3238535     3.12   0.002     1.236465    2.533337\n------------------------------------------------------------------------------\n\n. timer off 1\n\n. timer list\n   1:     12.64 /        1 =      12.6400\nThis takes 12.6 seconds to fit.\nI now reload and stset the data, but this time declaring both status=1 and status=2 as events.\n. use https://www.pclambert.net/data/ebmt1_stata.dta, clear\n\n. stset time, failure(status==1,2) scale(365.25) id(patid)\nWe can now run stcrprep.\n. timer on 2\n\n. stcrprep, events(status) keep(score) trans(1)   \n\n. timer off 2\n\n. timer list 2\n   2:      0.62 /        1 =       0.6230\nThis takes 0.6 seconds to run. However, this only restructures the data and calculates the weights. To fit the model, we first generate the event indicator and use stset.\n. gen      event = status == failcode\n\n. stset tstop [iw=weight_c], failure(event) enter(tstart) \nWe use stcox to fit the proportional subhazards model to the expanded data.\n. timer on 3\n\n. stcox i.score\n\n         Failure _d: event\n   Analysis time _t: tstop\n  Enter on or after: time tstart\n             Weight: [iweight=weight_c]\n\nIteration 0:  Log likelihood = -3338.1244\nIteration 1:  Log likelihood = -3333.4173\nIteration 2:  Log likelihood = -3333.3113\nIteration 3:  Log likelihood = -3333.3112\nRefining estimates:\nIteration 0:  Log likelihood = -3333.3112\n\nCox regression with Breslow method for ties\n\nNo. of subjects =     72,880                            Number of obs = 72,880\nNo. of failures =        456\nTime at risk    = 6,026.2743\n                                                        LR chi2(2)    =   9.63\nLog likelihood = -3333.3112                             Prob &gt; chi2   = 0.0081\n\n------------------------------------------------------------------------------\n          _t | Haz. ratio   Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       score |\nMedium risk  |   1.271235   .1593392     1.91   0.056     .9943389    1.625238\n  High risk  |   1.769899   .3219273     3.14   0.002     1.239148     2.52798\n------------------------------------------------------------------------------\n\n. timer off 3\n\n. timer list\n   1:     12.64 /        1 =      12.6400\n   2:      0.62 /        1 =       0.6230\n   3:      0.67 /        1 =       0.6730\nThis takes 0.7 seconds to run giving a combined total of 1.3 seconds. What is important is that if we want to fit other models (including other covariates etc), then we do not need to run stcrprep again.\nTo assess the time on larger data I have expanded the data by 20 times and added a small random number to each time, so that there are no ties. I used the following code.\nexpand 20\nreplace time = time + runiform()*0.0001\nreplace patid = _n\nThis leads to 19,770 indviduals in the analysis. The fact that there are no ties is perhaps a little unrealistic in a dataset this size, but this is still a usefull assessment of computational speed. The same analysis as above on this larger dataset gave the following times.\n\n\n\ncommand\nTime\n\n\n\n\nstcrreg\n2066.3 seconds\n\n\nstcrprep\n890.2 seconds\n\n\nstcox\n46.1 seconds\n\n\n\nI think this really highlights the benfits of restructuring the data and using stcox in terms of computational time. Unless there is need to recalculate the probability of censoring weights, there is no need to do this every time you fit a model. Thus, in this case the stcrreg model takes almost 35 minutes, whilst the same model using stcox, after using stcrprep, takes only 46 seconds.\nIt is worthwhile noting that Stata’s implementation of Fine and Grays proportional subhazards model using stcrreg seems particularly slow. If I fit the model in R using crr the model fitted to the expanded data it only takes 370 seconds compared to 2066 in Stata.\nThere are other benefits with using stcox to fit the subhazards model, mainly because we can now use many of the other commands and extensions associated with stcox. I will discuss these in other tutorials."
  },
  {
    "objectID": "software/stcrprep/stcox_instead_of_stcrreg.html",
    "href": "software/stcrprep/stcox_instead_of_stcrreg.html",
    "title": "stcrprep - using stcox' rather thanstcrreg`",
    "section": "",
    "text": "In the tutorial on using stcrep fo rnon-parametric etsimation of the cause-specific incidence function (CIF), weights were calculayed separately in each risk group. Although, we could do the same when modelling, to mimic the behaviour of stcrreg, we need the censoring distribution to not vary by covariates. I load the original data and run stcrprep without the byg() option.\nWe need to calculate the event indicator and using stset on th expanded data, and then can use `stcox’ to fit a proportional subhazards model for relapse.\nThe output gives the subhazard ratios for the medium- and high-risk groups. I have previously fitted a stcrreg model and compare the parameter estimates below.\nThe parameter estimates are the same as those produced by stcrreg to four decimal places. The standard errors are slightly different because I did not use a clustered sandwich estimator: Geskus (2011) showed that the sandwich estimator was asymptotically unbiased, but less efficient than using the standard errors derived with the observed information matrix.\nBelow I use stset again, but now use pweigts rather than iweights. To allow for cluster robust standard errors, I use vce(cluster patid) when using stcox.\nUsing pweights rather than iweights, along with the vce(cluster patid) option for the stcox command, leads to the standard errors being the same as stcrreg to four decimal places."
  },
  {
    "objectID": "software/stcrprep/stcox_instead_of_stcrreg.html#references",
    "href": "software/stcrprep/stcox_instead_of_stcrreg.html#references",
    "title": "stcrprep - using stcox' rather thanstcrreg`",
    "section": "References",
    "text": "References\nGeskus, R. B. Cause-specific cumulative incidence estimation and the Fine and Gray model under both left truncation and right censoring. Biometrics 2011; 67:39–49."
  },
  {
    "objectID": "software/stcrprep.html",
    "href": "software/stcrprep.html",
    "title": "stcrprep",
    "section": "",
    "text": "stcrprep prepares data for estimating and modelling cause-specific cumulative incidence functions using time-dependent weights. Once the data has been prepared and the weights incorporated using stset it is possible to obtain a graph of the non-parametric estimates of the cause-specific cumulative incidence function using sts graph. In addition a model that estimates subhazard ratios (equivalent to the Fine and Gray model) can be fitted using stcox. It is also possible to fit parametric models to directly estimate the cause-specific CIF (my main reason for developing the command), for example using stpm3.\nMore details can be found in the Stata Journal article\nI should point out that I am less keen on modelling the subhazard than when I wrote this command. Generally, I prefer to use fit cause-specific hazard models for each cause and then combine these to estimate the cause-sepcific CIFs.\nBelow are some simple examples of using stcrprep."
  },
  {
    "objectID": "software/stcrprep.html#examples",
    "href": "software/stcrprep.html#examples",
    "title": "stcrprep",
    "section": "Examples",
    "text": "Examples\n\nNon and semi parametric methods\n\nUsing sts graph for cause-specific CIFs\nUsing stcox instead of stcrreg\nComputational benefits of using stcrprep\nSchoenfeld residuals\n\n\n\nParametric models\n\nUsing stpm3 to model the cause-specific CIF\nAlternative link functions."
  },
  {
    "objectID": "software/stpm2/knot_positions_sensitivity.html",
    "href": "software/stpm2/knot_positions_sensitivity.html",
    "title": "Sensitivity analysis to location of knots (proportional hazards)",
    "section": "",
    "text": "When using stpm2 with the df() option the location of the knots for the restricted cubic splines are selected using the defaults. These are the based at the centiles of \\(\\ln(t)\\) for the events (i.e. the non censored observations). The boundary knots are placed at the minimum and maximum log event times. For example, with 5 knots there will be knots placed at the \\(0^{th}\\), \\(25^{th}\\), \\(50^{th}\\), \\(75^{th}\\), and \\(100^{th}\\) centiles of the log event times. The location of the internal knots can be changed using the knots() option and the location of the boundary knots can be changed using the bknots() option.\nI was asked recently by Enzo Coviello why we use these knot locations and why not the knot locations suggested by Frank Harrell when using restricted cubic spines in his execellent book Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression, and Survival Analysis. The table below shows the knot locations suggested by Harrell and those we use in stpm2.\n\n\n\nNo. of knots\nPercentiles (Harrell)\nPercentiles (stpm2)\n\n\n\n\n3\n10 50 90\n0 50 100\n\n\n4\n5 35 65 95\n0 33 67 100\n\n\n5\n5 27.5 50 72.5 95\n0 25 50 75 100\n\n\n6\n5 23 41 59 77 95\n0 20 40 60 80 100\n\n\n7\n2.5 18.33 34.17 50 65.83 81.67 97.5\n0 17 33 50 67 83 100\n\n\n\nWe have performed a number of sensitivity analysis to internal knot location, i.e. still keeping the boundary knots at the minimum and maximum log event times, and have found predicted hazard and survival functions to be very robust to these changes. However, we have not changed the boundary knots so much. The only time I can remember this is when fitting cure models (Andersson et al. 2011).\nIn my reply to Enzo I explained that we had motivated our choice of knots by the fact that it is better not to make linearity assumptions within the range of the data, but the linearity assumption outside the range of the data adds some stability to the function at the extremes. I also ran a very quick simulation study based on the same scenarios in Mark Rutherford’s simulation paper (Rutherford 2015 et al.). I extend that simulation study here.\nI will simulate the same 4 scenarios as in Mark’s paper, but will not simulate any covariate effects as I am only really interested in how well the restricted cubic spline function performs. Each of the scenarios was simulated from a mixture Weibull distributon,\n\\[\nS(t) = \\pi \\exp(-\\lambda_1 t^{\\gamma_1}) + (1-\\pi)\\exp(-\\lambda_2 t^{\\gamma_2})\n\\]\nThe following parameters are used for each scenario,\n\n\n\nScenario\n\\(\\lambda_1\\)\n\\(\\lambda_1\\)\n\\(\\gamma_1\\)\n\\(\\gamma_2\\)\n\\(\\pi\\)\n\n\n\n\n1\n0.6\n-\n0.8\n–\n1\n\n\n2\n0.2\n1.6\n0.8\n1.0\n0.2\n\n\n3\n1\n1\n1.5\n0.5\n0.5\n\n\n4\n0.03\n0.3\n1.9\n2.5\n0.7\n\n\n\nThe true survival and the hazard functions can be plotted for each scenario. Below is a program I use to do this. I first declare some local macros to define the Weibull mixture parameters in each scenario. These will also be used when running the simulations.\n. local scenario1 lambda1(0.6) lambda2(0.6) gamma1(0.8) gamma2(0.8) pi(1) maxt(5)\n\n. local scenario2 lambda1(0.2) lambda2(1.6) gamma1(0.8) gamma2(1) pi(0.2) maxt(5)\n\n. local scenario3 lambda1(1) lambda2(1) gamma1(1.5) gamma2(0.5) pi(0.5) maxt(5)\n\n. local scenario4 lambda1(0.03) lambda2(0.3) gamma1(1.9) gamma2(2.5) pi(0.7) maxt(5)\nI can then delclare and run the program to plot the true survival and hazard functions.\n. capture pr drop weibmixplot\n\n. program define weibmixplot\n  1.   syntax [, OBS(integer 1000) lambda1(real 1) lambda2(real 1) ///\n&gt;       gamma1(real 1) gamma2(real 1) pi(real 0.5) maxt(real 5)  scenario(integer 1)]\n  2.   local S1 exp(-`lambda1'*x^(`gamma1'))\n  3.   local S2 exp(-`lambda2'*x^(`gamma2'))\n  4.   local h1 `lambda1'*`gamma1'*x^(`gamma1' - 1)\n  5.   local h2 `lambda2'*`gamma2'*x^(`gamma2' - 1)\n  6.   \n.   twoway function y = `pi'*`S1' + (1-`pi')*`S2' ///\n&gt;     , range(0 `maxt') name(s`scenario',replace) ///\n&gt;     xtitle(\"Time (years)\") ///\n&gt;     ytitle(\"S(t)\") ///\n&gt;     ylabel(,angle(h) format(%3.1f)) ///\n&gt;         title(\"Scenario `scenario'\")\n  7.   twoway function y = (`pi'*`h1'*`S1' +(1-`pi')*`h2'*`S2') / ///\n&gt;                       (`pi'*`S1' + (1-`pi')*`S2') ///\n&gt;     , range(0 `maxt') name(h`scenario',replace) ///\n&gt;     xtitle(\"Time (years)\") ///\n&gt;     ytitle(\"h(t)\") ///\n&gt;     ylabel(,angle(h) format(%3.1f)) ///\n&gt;         title(\"Scenario `scenario'\")\n  8. end\n\n. \n. forvalues i = 1/4 {\n  2.         weibmixplot ,  `scenario`i'' scenario(`i')\n  3. }\n\n. graph combine s1 s2 s3 s4, nocopies name(true_s, replace) title(\"Survival functions\")\n\n. graph combine h1 h2 h3 h4, nocopies name(true_h, replace) title(\"Hazard functions\")\nThe true survival function for each scenario is shown below.\n\nand here are the true hazard functions.\n\nFor more details on the choice of these functions see Rutherford et al. 2015.\n\n\nIn order to peform a simulation study I will write a program that does three jobs. It will (i) simulate the data, (ii) analyse the data (perhaps using different methods/models) and (iii) store the results. Once I have written the program I can use Stata’s simulate command to run my program many times (e.g. 1000). In my program I will fit models with 4, 5 and 6 df (5, 6 and 7 knots) and use stpm2’s default knot positions and the knot positions given by Harrell. I will then store the AIC and BIC so that these can then be compared. The full program is shown below and I will then explain some of the lines of code.\nclear all\nprogram define enzosim, rclass\n  syntax [, OBS(integer 1000) lambda1(real 1) lambda2(real 1) ///\n      gamma1(real 1) gamma2(real 1) pi(real 0.5) maxt(real 5)]\n  clear\n  set obs `obs'\n  survsim t d, mixture lambda(`lambda1' `lambda2') gamma(`gamma1' `gamma2') ///\n    pmix(`pi') maxt(`maxt')\n  replace t = ceil(t*365.24)/365.24\n  stset t, f(d==1)\n  local harrell4 27.5 50 72.5\n  local harrell4b 5 95\n  local harrell5 23 41 59 77\n  local harrell5b 5 95\n  local harrell6 18.33 34.17 50 65.83 81.67\n  local harrell6b 2.5 97.5\n  foreach i in 4 5 6  {\n    stpm2, df(`i') scale(hazard)\n    return scalar AIC1_df`i' = e(AIC)\n    return scalar BIC1_df`i' = e(BIC)\n    stpm2, knots(`harrell`i'') knscale(centile) scale(hazard) bknots(`harrell`i'b')\n    return scalar AIC2_df`i' = e(AIC)\n    return scalar BIC2_df`i' = e(BIC)\n  }\n  ereturn clear\nend\nI first drop the program as I need to create a new version whilst I am editing it (fixing bugs etc). I name the program enzosim and make it an rclass program as I want it to return some results. I use the syntax command to allow my program to take options. The options include the number of observations in each simulated data set, the parameters of the mixture Weibull distribution and length of follow-up. Each of these is given a default value.\nThe next five lines are as follows,\nclear\nset obs `obs'\nsurvsim t d, mixture lambda(`lambda1' `lambda2') gamma(`gamma1' `gamma2') ///\n  pmix(`pi') maxt(`maxt')\nreplace t = ceil(t*365.24)/365.24\nstset t, f(d==1)\nI first clear any data in memory and set the observations to whatever was specified in the obs() option (or use the default of 1000 if not specified. I then use the survsim command to simulate from the mixture Weibull model (Crowther and Lambert 2012). The will create two new variables t (the survival time) and d the event indicator. The maxt() option means that any simulated time after 5 years will be censored at 5 years. Note that survsim uses the parameters I pass to my program for the mixture Weibull distribution. After generating data in years, I transform to days and round up to the nearest integer and then transform back to years. The reason for this is that some very small survival times can lead to numerical problems. It also better reflects real data, where survival is often measured to the nearest day. I then stset the data so I can now fit some models.\nI then declare some local macros to define the knots positions given by Harrell,\nlocal harrell4 27.5 50 72.5\nlocal harrell4b 5 95\nlocal harrell5 23 41 59 77\nlocal harrell5b 5 95\nlocal harrell6 18.33 34.17 50 65.83 81.67\nlocal harrell6b 2.5 97.5\nI have to give the internal knots and the boundary knots separately.\nI then write a small loop that loops over different degrees of freedom (4, 5 and 6).\nforeach i in 4 5 6  {\n  stpm2, df(`i') scale(hazard)\n  return scalar AIC1_df`i' = e(AIC)\n  return scalar BIC1_df`i' = e(BIC)\n  stpm2, knots(`harrell`i'') knscale(centile) scale(hazard) bknots(`harrell`i'b')\n  return scalar AIC2_df`i' = e(AIC)\n  return scalar BIC2_df`i' = e(BIC)\n }\nFor each df an stpm2 model is fitted using the default knot placement and then using knot positions recommended by Harrell. Note the use of the knots() option for the internal knots, the bknots() option for the boundary knots and the knscale(centile) option so I can specify the knots as centiles rather than specific point in time (the default). After fitting each model I use return to store both the AIC and BIC.\nThe final line of code,\nereturn clear\nis just a bit of laziness on my part as if you do not specify anything to monitor when using the simulate command it will monitor the coefficients of the model in memory. If no model is stored in memory then it will monitor anything stored in r(), which is what I want. Therefore, I use ereturn clear to remove the last model from memory and now I do not have to give a long list of the things I want to monitor.\n\n\n\nWhen I am developing a simulation program I will run it once. This allows me to check any variables that have been created, spot any potential bugs, make sure any analysis I am performing is correct and make sure the results I want to store are actually stored. If I just type enzosim then it will run my program using the default values specified in the syntax statement of the program. This give the following results,\n. enzosim,\nnumber of observations (_N) was 0, now 1,000\nWarning: 8 survival times were above the upper limit of 5\n         They have been set to 5 and can be considered censored\n         You can identify them by _survsim_rc = 3\n\n     failure event:  d == 1\nobs. time interval:  (0, t]\n exit on or before:  failure\n\n------------------------------------------------------------------------------\n      1,000  total observations\n          0  exclusions\n------------------------------------------------------------------------------\n      1,000  observations remaining, representing\n        992  failures in single-record/single-failure data\n  1,006.047  total analysis time at risk and under observation\n                                                at risk from t =         0\n                                     earliest observed entry t =         0\n                                          last observed exit t =         5\n\nIteration 0:   log likelihood = -1615.2795  \nIteration 1:   log likelihood = -1615.0025  \nIteration 2:   log likelihood = -1615.0024  \n\nLog likelihood = -1615.0024                     Number of obs     =      1,000\n\n------------------------------------------------------------------------------\n             |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nxb           |\n       _rcs1 |   1.275779   .0422624    30.19   0.000     1.192946    1.358612\n       _rcs2 |  -.0492945   .0335147    -1.47   0.141    -.1149821    .0163931\n       _rcs3 |   .0072627    .019518     0.37   0.710    -.0309919    .0455174\n       _rcs4 |   .0009645   .0117572     0.08   0.935    -.0220792    .0240082\n       _cons |  -.5789954   .0405764   -14.27   0.000    -.6585236   -.4994671\n------------------------------------------------------------------------------\n\n..... remaining output has been omitted.\nThe program runs without error and fit the models I intend. I can check that everything I want stored is actually stored using return list.\n. return list\n\nscalars:\n           r(BIC2_df6) =  3275.609609295175\n           r(AIC2_df6) =  3241.325674693275\n           r(BIC1_df6) =  3275.271719530712\n           r(AIC1_df6) =  3240.987784928811\n           r(BIC2_df5) =  3273.020999377406\n           r(AIC2_df5) =  3243.634769718634\n           r(BIC1_df5) =  3273.049041974547\n           r(AIC1_df5) =  3243.662812315775\n           r(BIC2_df4) =  3267.19499496639\n           r(AIC2_df4) =  3242.706470250746\n           r(BIC1_df4) =  3266.905797538291\n           r(AIC1_df4) =  3242.417272822648\nI can see that all the AIC and BIC values have been returned.\n\n\n\nNow I am ready to simulate 1000 data sets for each scenario using the simulate command. I can loop over the 4 scenarios making use of the local macros already declared for each scenario.\nset seed 78126378\nforvalues i = 1/4 {\n  simulate , reps(1000) saving(sim_scenaro`i', replace double): enzosim, `scenario`i''\n}\nI pass the relevent local macro for the options for each scenario. The results are saved using the saving option. Each of the created data sets will contain 1000 observations, one for each simulated data set. I then go and make a cup of coffee while I wait for the results…\n\n\n\nOnce the simulations have run I can start looking at the results. I will first plot the data comparing the AIC between the default knot placement with Harrell’s knot placement for each of the 4, 5 ad 6 df models.\n. forvalues s =1/4 {\n  2.   quietly {\n  3.     use sim_scenaro`s', replace\n  4.     forvalues df = 4/6 {\n  5.           gen AICdiff_df`df' = AIC2_df`df' - AIC1_df`df'\n  6.           hist AICdiff_df`df', name(AIC`df', replace) ylabel(none) ///\n&gt;                 ytitle(\"\") xline(0) ///\n&gt;                 xtitle(\"Difference in AIC\") ///\n&gt;                 title(\"`df' df\", ring(0) pos(1) size(*0.8))\n  7. \n.     }\n  8.   }\n  9.   graph combine AIC4 AIC5 AIC6, cols(3) nocopies name(scenario`s', replace) ///\n&gt;     ycommon xcommon title(\"Scenario `s'\", size(*0.8))\n 10. }\n\n. graph combine scenario1 scenario2 scenario3 scenario4, nocopies cols(1) imargin(0 0 0 0)\nThis code calculates the difference in the AIC between Harrell’s knot locations and stpm2’s default knot locations. A positive value indicates a lower AIC for the default knot locations. Note there is no point calculating the difference in the BIC as well as this is identical to the difference in the AIC as the number of parameters is the same in the models we are comparing. The resulting plot can be seen below.\n\nThis plot shows that for all scenarios there tends to be a lower AIC for the default knot locations. This is particularly so for scenarios 2 and 3. The change in the AIC is much larger for these two scenarios.\nI will next calculate the percentage of time the AIC is lower for the default knot locations.\n. forvalues s =1/4 {\n  2.   quietly use sim_scenaro`s', replace\n  3.   display _newline \"Scenario `s'\"\n  4.   display \"------------\"\n  5.   forvalues df = 4/6 {\n  6.     quietly count if AIC2_df`df' &gt; AIC1_df`df'\n  7.     di \"Default knot locations had lower AIC for `df' df:\" %4.1f 100*`r(N)'/_N \"%\"\n  8.   }\n  9. }\n\nScenario 1\n------------\nDefault knot locations had lower AIC for 4 df:72.8%\nDefault knot locations had lower AIC for 5 df:73.4%\nDefault knot locations had lower AIC for 6 df:74.2%\n\nScenario 2\n------------\nDefault knot locations had lower AIC for 4 df:99.0%\nDefault knot locations had lower AIC for 5 df:97.5%\nDefault knot locations had lower AIC for 6 df:85.4%\n\nScenario 3\n------------\nDefault knot locations had lower AIC for 4 df:98.9%\nDefault knot locations had lower AIC for 5 df:98.8%\nDefault knot locations had lower AIC for 6 df:90.7%\n\nScenario 4\n------------\nDefault knot locations had lower AIC for 4 df:68.3%\nDefault knot locations had lower AIC for 5 df:57.5%\nDefault knot locations had lower AIC for 6 df:53.1%\nAgain we can see the dominance of the default knot locations, particularly for scenarios 2 and 3.\nAnother question is to see which of the models fitted to each simulated data set gives the lowest AIC and whether this differs between the default knot locations and Harrell’s knot locations. I create some code to find the df with the lowest AIC and BIC.\n. forvalues s =1/4 {\n  2.   quietly use sim_scenaro`s', replace\n  3.   egen double minAIC1 = rowmin(AIC1_df?)\n  4.   egen double minAIC2 = rowmin(AIC2_df?)\n  5.   gen AICmin1 = 4*(minAIC1==AIC1_df4) + 5*(minAIC1==AIC1_df5)+6*(minAIC1==AIC1_df6)\n  6.   gen AICmin2 = 4*(minAIC2==AIC2_df4) + 5*(minAIC2==AIC2_df5)+6*(minAIC2==AIC2_df6)\n  7.   egen double minBIC1 = rowmin(BIC1_df?)\n  8.   egen double minBIC2 = rowmin(BIC2_df?)\n  9.   gen BICmin1 = 4*(minBIC1==BIC1_df4) + 5*(minBIC1==BIC1_df5)+6*(minBIC1==BIC1_df6)\n 10.   gen BICmin2 = 4*(minBIC2==BIC2_df4) + 5*(minBIC2==BIC2_df5)+6*(minBIC2==BIC2_df6)\n 11.   di _newline \"Scenario `s'\"\n 12.   di \"AIC\"\n 13.   tab AICmin1 AICmin2\n 14.   di \"BIC\"\n 15.   tab BICmin1 BICmin2\n 16. }\n\nScenario 1\nAIC\n\n           |             AICmin2\n   AICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |       694         26          8 |       728 \n         5 |        23        106         25 |       154 \n         6 |        28          0         90 |       118 \n-----------+---------------------------------+----------\n     Total |       745        132        123 |     1,000 \n\nBIC\n\n           |        BICmin2\n   BICmin1 |         4          5 |     Total\n-----------+----------------------+----------\n         4 |       975          6 |       981 \n         5 |         7         10 |        17 \n         6 |         2          0 |         2 \n-----------+----------------------+----------\n     Total |       984         16 |     1,000 \n\n\nScenario 2\nAIC\n\n           |             AICmin2\n   AICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |        59         20        379 |       458 \n         5 |         1         19        240 |       260 \n         6 |         2          0        280 |       282 \n-----------+---------------------------------+----------\n     Total |        62         39        899 |     1,000 \n\nBIC\n\n           |             BICmin2\n   BICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |       602         53        282 |       937 \n         5 |         1          5         40 |        46 \n         6 |         0          0         17 |        17 \n-----------+---------------------------------+----------\n     Total |       603         58        339 |     1,000 \n\n\nScenario 3\nAIC\n\n           |             AICmin2\n   AICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |         8         10         52 |        70 \n         5 |         0         12        162 |       174 \n         6 |         2          0        754 |       756 \n-----------+---------------------------------+----------\n     Total |        10         22        968 |     1,000 \n\nBIC\n\n           |             BICmin2\n   BICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |       357         22        318 |       697 \n         5 |         4          8        119 |       131 \n         6 |         0          0        172 |       172 \n-----------+---------------------------------+----------\n     Total |       361         30        609 |     1,000 \n\n\nScenario 4\nAIC\n\n           |             AICmin2\n   AICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |       528         83         14 |       625 \n         5 |        31        131         66 |       228 \n         6 |        20          4        123 |       147 \n-----------+---------------------------------+----------\n     Total |       579        218        203 |     1,000 \n\nBIC\n\n           |             BICmin2\n   BICmin1 |         4          5          6 |     Total\n-----------+---------------------------------+----------\n         4 |       935         24          5 |       964 \n         5 |         9         19          3 |        31 \n         6 |         1          0          4 |         5 \n-----------+---------------------------------+----------\n     Total |       945         43         12 |     1,000 \n\nWhat I find interesting is that there is a tendency for AIC to select fewer knots for the default knot locations. As above, this is especially so for scenarios 2 and 3. This is not the case for the more simple scenario 1. Here the truth is a Weibull distribution and so all models are overfitting when compared with the truth.\nI don’t think the differences we see here are that great and of course we are only looking at a few scenarios. However, it is reassuring to me that our default knot locations seem sensible. A more detailed analysis would compare hazard and survival functions with the true function. When we use splines, I don’t really think that they represent the true model, but they should give a very good approximation to it. This is of crucial importance as with real data, we never know the true model.\n\n\n\nAndersson, T.M.-L., Dickman, P.W., Eloranta, S., Lambert, P.C. Estimating and modelling cure in population-based cancer studies within the framework of flexible parametric survival models. BMC Med Res Methodol 2011;11:96\nCrowther, M.J., Lambert, P.C. Simulating complex survival data. The Stata Journal 2012;12:674-687.\nHarrell, F.E. Regression modeling strategies with application to linear models, logistic regression and survival analysis. Springer, 2001\nRutherford, M.J., Crowther, M.J., Lambert, P.C. The use of restricted cubic splines to approximate complex hazard functions in the analysis of time-to-event data: a simulation study. Journal of Statistical Computation and Simulation 2015;85:777-793"
  },
  {
    "objectID": "software/stpm2/knot_positions_sensitivity.html#references",
    "href": "software/stpm2/knot_positions_sensitivity.html#references",
    "title": "Sensitivity analysis to location of knots (proportional hazards)",
    "section": "",
    "text": "Andersson, T.M.-L., Dickman, P.W., Eloranta, S., Lambert, P.C. Estimating and modelling cure in population-based cancer studies within the framework of flexible parametric survival models. BMC Med Res Methodol 2011;11:96\nCrowther, M.J., Lambert, P.C. Simulating complex survival data. The Stata Journal 2012;12:674-687.\nHarrell, F.E. Regression modeling strategies with application to linear models, logistic regression and survival analysis. Springer, 2001\nRutherford, M.J., Crowther, M.J., Lambert, P.C. The use of restricted cubic splines to approximate complex hazard functions in the analysis of time-to-event data: a simulation study. Journal of Statistical Computation and Simulation 2015;85:777-793"
  },
  {
    "objectID": "software/stpm2/sensitivity_analysis.html",
    "href": "software/stpm2/sensitivity_analysis.html",
    "title": "Sensitivity analysis to number of knots (proportional hazards)",
    "section": "",
    "text": "Sensitivity Analysis\nWe first load the example Rotterdam breast cancer data (rott2b.dta) and then use stset to declare the survival time (relapse free survival) and event indicator. Follow-up is restricted to 5 years using the exit() option.\n. use https://www.pclambert.net/data/rott2b, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset rf, f(rfi==1) scale(12) exit(time 60)\n\n     failure event:  rfi == 1\nobs. time interval:  (0, rf]\n exit on or before:  time 60\n    t for analysis:  time/12\n\n------------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n------------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,181  failures in single-record/single-failure data\n 11,130.825  total analysis time at risk and under observation\n                                                at risk from t =         0\n                                     earliest observed entry t =         0\n                                          last observed exit t =         5\nI will use different degrees of freedom for the baseline. The easiest way to do this is in a loop. The following code fits between 1 and 6 df, predicts the baseline hazard and survival functions and stores each model (using estimates store). I use quietly to suppress the output. I also generate a new time variable (temptime) for the predictions, rather than use the default of _t.\n. range temptime 0 5 200\n(2,782 missing values generated)\n\n. forvalues i = 1/6 {\n  2.         quietly stpm2 hormon, df(`i') scale(hazard) \n  3.         predict h0_df`i', hazard timevar(temptime) per(1000) zeros\n  4.         predict s0_df`i', survival timevar(temptime) zeros\n  5.         estimates store df`i'\n  6. }\nWe can now compare the results from fitting the 6 different models.\n. estimates table df*, keep(hormon) b(%6.5f) se(%6.5f) stats(AIC BIC) stfmt(%6.2f)\n\n--------------------------------------------------------------------------\n    Variable |   df1       df2       df3       df4       df5       df6    \n-------------+------------------------------------------------------------\n      hormon | 0.23312   0.22044   0.22038   0.22023   0.22020   0.22007  \n             | 0.08642   0.08643   0.08643   0.08643   0.08643   0.08643  \n-------------+------------------------------------------------------------\n         AIC | 6362.72   6210.98   6212.43   6213.72   6213.75   6215.98  \n         BIC | 6377.94   6231.28   6237.80   6244.17   6249.27   6256.57  \n--------------------------------------------------------------------------\n                                                              legend: b/se\nThe log hazard ratios are very similar between the different models, particularly from 2df and above (using 1 df is equivalent to fitting a Weibull model). The standard errors are also very similar.\nThe AIC and BIC can be used as an informal guide (certainly not definitive) to the choice of model. Both the AIC and BIC are lowest for the model with 2df.\nOne of the advantages of using parametric models is the simplicity in which we can predict hazard, survival and other useful functions. In the loop when the 6 different models were fitted the baseline hazard and survival functions were also obtained. We can now compare these by plotting them.\nFirst, the baseline hazard functions. Note I used the per(1000) option when I predicted the hazard functions to give the rate per 1000 person years.\n. twoway  (line h0_df* temptime), ///\n&gt;                 ytitle(\"hazard rate (per 1000 py)\") ///\n&gt;                 xtitle(\"Years from surgery\") ///\n&gt;                 ylabel(,format(%2.0f) angle(h)) ///\n&gt;                 legend(order(1 \"1 df\" 2 \"2 df\" 3 \"3df\" 4 \"4df\" 5 \"5df\" 6 \"6df\") ///\n&gt;                         ring(0) cols(1) pos(5))\nThe graph is shown below. The model with 1 df (equivalent to a Weibull model) stands out. The hazard function for the Weibull model is monotonic and so can’t pick up the turning point. There is fairly good agreement between the other models. Remember that the AIC and BIC indicate that models with 3df or more are over fitting.\n\nNow, using similar code we can plot the six baseline survival functions.\n. twoway  (line s0_df* temptime), ///\n&gt;                 ytitle(\"Survival function - S(t)\") ///\n&gt;                 xtitle(\"Years from surgery\") ///\n&gt;                 ylabel(,format(%3.1f) angle(h)) ///\n&gt;                 legend(order(1 \"1 df\" 2 \"2 df\" 3 \"3df\" 4 \"4df\" 5 \"5df\" 6 \"6df\") ///\n&gt;                         ring(0) cols(1) pos(1))\nThis graph is shown below and again the model with 1 df stands out, which is not surprising given the hazard function. However, there is excellent agreement between the remaining 5 models. In general, one sees better agreement when comparing survival functions as it is a cumulative measure the small differences seen the hazard functions cancel out.\n\nThis has been a simple sensitivity analysis where I have assumed proportional hazards and only fitted a single covariate, but I hope that it shows how simple it is to try these things.\nWhat I see as the key point here is that even when selecting a too complex model (as indicated by the AIC and BIC) it makes little difference to the hazard ratio or the estimated hazard and survival functions. Of course one could argue that this is a single data set, but see Rutherord et al. for a more detailed simulation study on the ability of these models to capture complex hazard functions.\n\nReferences\nRutherford M.J., Crowther M.J., Lambert, P.C. The use of restricted cubic splines to approximate complex hazard functions in the analysis of time-to-event data: a simulation study. Journal of Statistical Computation and Simulation 2015;4:777–793"
  },
  {
    "objectID": "software/stpm2/temporal_recalibration.html",
    "href": "software/stpm2/temporal_recalibration.html",
    "title": "Temporal Recalibration",
    "section": "",
    "text": "Download Stata Do file here"
  },
  {
    "objectID": "software/stpm2/temporal_recalibration.html#background",
    "href": "software/stpm2/temporal_recalibration.html#background",
    "title": "Temporal Recalibration",
    "section": "Background",
    "text": "Background\n\nTrends in survival over calendar time\nClinical risk prediction models should produce well-calibrated (accurate) predictions for patients who have been recently diagnosed with a particular health condition. However, often there are improvements in survival over time due to new treatments and healthcare policies. For example, survival following a diagnosis of cancer has improved over the past 20 years in many countries.\nAs we do not have long-term follow-up data for recently diagnosed patients, we have to rely on including patients who were diagnosed many years ago in order to develop prognostic models that can produce long-term survival predictions. However, if survival has improved over time, including these patients means that the predictions will be out-of-date and will under-estimate the survival of new patients.\nThis idea is illustrated in the graph below that shows the Kaplan-Meier curves increasing over calendar time. The Kaplan-Meier for the entire cohort (pink dashed line) is effectively an average of these curves and therefore does not provide an accurate estimate of the survival of the recently diagnosed patients.\n\n\n\nPeriod analysis\nOne approach for producing more up-to-date estimates of survival is to use period analysis. This ensures that only the most recent data is used to estimate the hazard rates using delayed entry. The period window (red box) defines the follow-up time and events that are included. Whilst people diagnosed 10 years ago can still contribute towards the analysis (Patient A), they only contribute towards the estimates of the long-term hazard rates. This allows the short-term hazards to be estimated from only the most recently diagnosed patients (Patient F) meaning that these estimates are as up-to-date as possible. Using this approach produces a Kaplan-Meier curve that agrees much more closely with the survival estimates of the recently diagnosed patients (grey dashed line).\nThe sample size and number of events are reduced as those who die before the period window are excluded (Patients B and D). Therefore, a disadvantage of using this method as the basis for developing a prognostic model is that this may limit the number of predictors that can be included in the model else it may lead to issues of overfitting.\n\n\n\nTemporal Recalibration\nTemporal recalibration aims to combine the advantage of having up-to-date estimates from period analysis with retaining the full dataset to estimate the predictor effects. It is a two-step process where the standard model is first developed as usual to obtain the predictor effects (linear predictor). The second step is to recalibrate the model by re-estimating the baseline in the subset defined by the period window whilst constraining the predictor effects to remain the same. This can be achieved by including the linear predictor as an offset term (if a PH model is fitted) or by adding constraints for the coefficients of each of the predictor parameters. The second approach will work even in the case of non-proportional hazards (note: if time-dependent effects are included in flexible parametric survival models, the same knot locations from the original model should also be used). Once this recalibration is performed, the predictions can be obtained as usual."
  },
  {
    "objectID": "software/stpm2/temporal_recalibration.html#example",
    "href": "software/stpm2/temporal_recalibration.html#example",
    "title": "Temporal Recalibration",
    "section": "Example",
    "text": "Example\nIn this example, I’ll show how to perform temporal recalibration when developing a prognostic model. I’ll also illustrate how this method can be beneficial when survival is improving over time by testing how well this model performs in producing predictions for recently diagnosed patients in comparison to using the standard method.\n\nData\nThe simulated data in this example is loosely based on survival following a diagnosis of cancer. The lower short-term and higher long-term hazards for more recent patients could occur if a new treatment delays deaths from occurring in the short-term. This leads to an overall improvement in survival over time as shown by the Kaplan-Meier curves.\n\nThis simulated dataset contains the following variables: ID number (id), year of diagnosis (yydx, 2009-2019), date of diagnosis (dx), date of death/censoring (exit), survival status (status, 0 = Alive, 1 = Dead), age at diagnosis (age, 44-93), sex (sex, 0 = Male, 1 = Female) and stage of tumour at diagnosis (stage, 1-3).\nThe derivation dataset (val=0) includes patients diagnosed between 2009 and 2019. In order to test how well temporal recalibration performs for making predictions for recently diagnosed patients, the validation dataset (val=1) includes patients diagnosed in 2019.\n\n\nModel development\nI’ll fit a simple prognostic model that contains age, sex and stage of tumour as predictors so I’ll first need to create the dummy variables relating to sex and stage.\nIn this example, I simulated the effect of age to be linear for simplicity so I’ll just model it as a linear term. However, in practice, age is often a non-linear effect and should instead be modelled using a method that can capture this trend such as restricted cubic splines or fractional polynomials. To make the baseline interpretable, I’ll centre the age variable on 70 (the mean age).\nuse https://www.pclambert.net/data/simulated_improvements, clear\ntab stage, gen(stage)\ngen female = sex == 1 \ngen age_centre = age-70\nI’ll fit the following 3 models:\n\nM1: The standard approach (not accounting for improvements in survival)\nM2: Temporal recalibration of model M1 using a 5 year period window (2015-2019)\nM3: Temporal recalibration of model M1 using a 2 year period window (2018-2019)\n\nHere I’ll use stpm2 to fit flexible parametric survival models. These models use restricted cubic splines to model the log cumulative baseline hazard. This is my preferred approach for prognostic modelling since having a fully parametric baseline makes it easy to produce smooth predicted survival curves both in and out-of-sample. However, temporal recalibration can also be applied to Cox PH models using stcox which I’ll show later.\n\nStandard method (no adjustments for survival improvements)\nFirstly I’ll use stset to create the survival times of patients in the development dataset (val=0), censoring any individuals who are alive at the end of 2019 or after 10 years of follow-up.\n. stset exit if val==0, origin(dx) fail(status==1) scale(365.25) ///\n&gt; exit(time min(dx+10*365.25,mdy(12,31,2019)))\n\nSurvival-time data settings\n\n         Failure event: status==1\nObserved time interval: (origin, exit]\n     Exit on or before: time min(dx+10*365.25,mdy(12,31,2019))\n     Time for analysis: (time-origin)/365.25\n                Origin: time dx\n      Keep observations \n                if exp: val==0\n\n--------------------------------------------------------------------------\n     64,913  total observations\n      9,863  ignored at outset because of if exp\n--------------------------------------------------------------------------\n     55,050  observations remaining, representing\n     15,750  failures in single-record/single-failure data\n 227,227.58  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nThe model can then be fitted. I’ll also store the model in memory and estimate the linear predictor for use when performing temporal recalibration. Using the xb option includes the parameters relating to the restricted cubic spline function in the baseline so the xbnobaseline option should be used to calculate the linear predictor.\n. stpm2 age_centre female stage2 stage3, df(3) scale(hazard) noorthog\n\nIteration 0:  Log likelihood = -45144.513  \nIteration 1:  Log likelihood = -45141.502  \nIteration 2:  Log likelihood =   -45141.5  \n\nLog likelihood = -45141.5                               Number of obs = 55,050\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n  age_centre |   .0290524   .0013306    21.83   0.000     .0264445    .0316603\n      female |  -.0793949   .0159424    -4.98   0.000    -.1106414   -.0481484\n      stage2 |   1.221257   .0273876    44.59   0.000     1.167578    1.274936\n      stage3 |   3.067474   .0264141   116.13   0.000     3.015703    3.119244\n       _rcs1 |   .7857653   .0216787    36.25   0.000     .7432758    .8282548\n       _rcs2 |  -.0027358   .0032212    -0.85   0.396    -.0090493    .0035777\n       _rcs3 |   .0044443   .0047324     0.94   0.348     -.004831    .0137197\n       _cons |  -3.730169   .0627114   -59.48   0.000    -3.853082   -3.607257\n------------------------------------------------------------------------------\n\n. estimates store standard\n\n. predict lp, xbnobaseline\n\n\nTemporal recalibration\nTo temporally recalibrate the model, stset is required to define the period analysis subsample. Firstly I’ll perform temporal recalibration using a 5 year window and then with a 2 year window to illustrate how the size of the window affects the sample size, number of events and the calibration of the resulting predictions.\nTo ensure that the predictor effects remain the same in the temporally recalibrated models, I’ll create a constraint to include the linear predictor as an offset term.\n. stset exit if val==0, origin(dx) fail(status==1) scale(365.25) ///\n&gt; entry(time mdy(1,1,2015)) exit(time min(dx+10*365.25,mdy(12,31,2019)))\n\nSurvival-time data settings\n\n         Failure event: status==1\nObserved time interval: (origin, exit]\n     Enter on or after: time mdy(1,1,2015)\n     Exit on or before: time min(dx+10*365.25,mdy(12,31,2019))\n     Time for analysis: (time-origin)/365.25\n                Origin: time dx\n      Keep observations \n                if exp: val==0\n\n--------------------------------------------------------------------------\n     64,913  total observations\n      9,863  ignored at outset because of if exp\n      7,088  observations end on or before enter()\n--------------------------------------------------------------------------\n     47,962  observations remaining, representing\n      8,662  failures in single-record/single-failure data\n 154,675.08  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. constraint 1 _b[lp] = 1\n\n. stpm2 lp, scale(hazard) noorthog constraints(1) df(3) \nnote: delayed entry models are being fitted\n\nIteration 0:  Log likelihood = -23120.497  \nIteration 1:  Log likelihood = -23119.369  \nIteration 2:  Log likelihood = -23119.369  \n\nLog likelihood = -23119.369                             Number of obs = 47,962\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n          lp |          1  (constrained)\n       _rcs1 |   .8481359   .0387457    21.89   0.000     .7721958     .924076\n       _rcs2 |  -.0256607   .0066633    -3.85   0.000    -.0387205   -.0126009\n       _rcs3 |   .0452753    .010843     4.18   0.000     .0240233    .0665272\n       _cons |  -4.130539   .0880844   -46.89   0.000    -4.303181   -3.957897\n------------------------------------------------------------------------------\n\n. estimates store recal5 \nUsing a period window of 5 years reduced the sample size from 55,050 in the standard analysis to 47,962 and the number of events from 15,750 to 8,662. As you can see, using a narrower window of 2 years, reduced these further to 42,872 and 3,572 respectively.\n. stset exit if val==0, origin(dx) fail(status==1) scale(365.25) ///\n&gt; entry(time mdy(1,1,2018)) exit(time min(dx+10*365.25,mdy(12,31,2019)))\n\nSurvival-time data settings\n\n         Failure event: status==1\nObserved time interval: (origin, exit]\n     Enter on or after: time mdy(1,1,2018)\n     Exit on or before: time min(dx+10*365.25,mdy(12,31,2019))\n     Time for analysis: (time-origin)/365.25\n                Origin: time dx\n      Keep observations \n                if exp: val==0\n\n--------------------------------------------------------------------------\n     64,913  total observations\n      9,863  ignored at outset because of if exp\n     12,178  observations end on or before enter()\n--------------------------------------------------------------------------\n     42,872  observations remaining, representing\n      3,572  failures in single-record/single-failure data\n 70,571.919  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\n\n. stpm2 lp, scale(hazard) noorthog constraints(1) df(3) \nnote: delayed entry models are being fitted\n\nIteration 0:  Log likelihood = -9242.6684  \nIteration 1:  Log likelihood = -9237.6059  \nIteration 2:  Log likelihood = -9237.5939  \nIteration 3:  Log likelihood = -9237.5939  \n\nLog likelihood = -9237.5939                             Number of obs = 42,872\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n          lp |          1  (constrained)\n       _rcs1 |   .8498527    .064545    13.17   0.000     .7233468    .9763587\n       _rcs2 |   -.036646    .011776    -3.11   0.002    -.0597266   -.0135654\n       _rcs3 |   .0669358    .020309     3.30   0.001     .0271308    .1067408\n       _cons |   -4.34597   .1395017   -31.15   0.000    -4.619389   -4.072552\n------------------------------------------------------------------------------\n\n. estimates store recal2\n\n\n\nObtaining predictions\nOnce the models are fitted, the predictions for the external validation dataset can be produced as usual using the predict (or standsurv) command.\n\n10-year survival\nThe 10-year survival predictions for each of the patients in the validation dataset can be calculated using the timevar() option.\ngen t10 = 10\n\n// Standard method\nestimates restore standard\npredict standard_10 if val==1, surv timevar(t10)\n\n// Temporal recalibration\nforeach model in \"recal5\" \"recal2\" {\n    estimates restore `model'\n    predict `model'_10 if val==1, surv timevar(t10)\n}\nPerforming temporal recalibration updates the baseline survival of the model which increases the 10-year survival prediction for each of the individuals. Using a narrower period window further restricts the data used to estimate the short-term hazard rates which can result in more up-to-date survival estimates.\n. summ standard_10 recal5_10 recal2_10\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n standard_10 |      9,863     .589459    .3104698   .0037656   .9353574\n   recal5_10 |      9,863    .5995616    .3100445   .0049988   .9385352\n   recal2_10 |      9,863    .6070969    .3094904   .0061271   .9408247\n\n\n\nPredictions for individual patients\nWe can also produce survival curves for patients by specifying their covariate patterns. I’ll create predictions for the following individuals:\n\nA man aged 70 at diagnosis with a stage 1 tumour (baseline of the model)\nA woman aged 82 at diagnosis with a stage 2 tumour\nA woman aged 53 at diagnosis with a stage 3 tumour\nA man aged 85 at diagnosis with a stage 3 tumour\n\nTo make the predictions from the standard model, I can use the at() and zeros options to specify the covariate pattern (remembering that age was centred on age 70).\n. range timevar10 0 10 101\n(64,812 missing values generated)\n\n. estimates restore standard\n(results standard are active now)\n\n. predict p1_standard, zeros surv timevar(timevar10)\n\n. predict p2_standard, at(age_centre 12 female 1 stage2 1) ///\n&gt;                      zeros surv timevar(timevar10)\n\n. predict p3_standard, at(age_centre -17 female 1 stage3 1) ///\n&gt;                      zeros surv timevar(timevar10)\n\n. predict p4_standard, at(age_centre 15 stage3 1) ///\n&gt;                      zeros surv timevar(timevar10)\nAs the temporally recalibrated models were fitted by including the linear predictor as an offset term, I first need to calculate the value of the linear predictor for these covariate patterns before making the survival predictions from the model.\nestimates restore standard\nlocal p2 = _b[age_centre]*12 + _b[female] + _b[stage2] \nlocal p3 = _b[age_centre]*(-17) + _b[female] + _b[stage3] \nlocal p4 = _b[age_centre]*(15) + _b[stage3] \n\nforeach model in \"recal5\" \"recal2\" {\n    estimates restore `model'\n    predict p1_`model', zeros surv timevar(timevar10)\n    predict p2_`model', at(lp `p2') zeros surv timevar(timevar10)\n    predict p3_`model', at(lp `p3') zeros surv timevar(timevar10)\n    predict p4_`model', at(lp `p4') zeros surv timevar(timevar10)\n}\nHere it can be seen that accounting for improvements in survival as part of model development led to higher survival predictions, where particular improvements can be seen in the survival predictions for the high risk patients. Using a narrower period window of 2 years led to the highest survival estimates. However, this choice is a bias-variance trade-off since the sample size and number of events used to estimate the baseline hazard is further reduced.\n\n\n\nMarginal survival predictions\nOne approach to assess the calibration-in-the-large is to compare the marginal predicted survival to the marginal observed survival. The marginal survival is calculated by estimating the survival curves for each of the individuals in the validation dataset and then taking the average. This can be calculated using meansurv with the predict command or alternatively using standsurv.\n\\[ \\bar{S}(t) = \\frac{1}{N} \\sum_{i=1}^{N} {\\widehat{S}(t|x_i)} \\]\nThe marginal observed survival can be quantified by calculating the Kaplan-Meier in the validation dataset. If the model is well-calibrated, these two measures should agree closely. The validation dataset contains patients who were diagnosed in 2019 and as this is simulated data we can estimate their 10-year observed survival by using follow-up data until 2030.\n// Standard method\nestimates restore standard\npredict marg_standard if val==1, timevar(timevar10) meansurv\n\n// Temporal recalibration\nforeach model in \"recal5\" \"recal2\" {\n    estimates restore `model'\n    predict marg_`model' if val==1, timevar(timevar10) meansurv\n}\n\n// Observed survival\nstset exit if val==1, origin(dx) fail(status==1) scale(365.25) ///\nexit(time dx+10*365.25)\nsts gen marg_obs = s\nHere it can be seen that not accounting for trends in survival over time led to under-estimating the marginal survival across the full 10-year period. However, using temporal recalibration for model development improved the calibration of the survival predictions. Decreasing the size of the period window has the potential to produce more up-to-date estimates and here it can be seen that using a 2 year window produced the best agreement with the observed survival.\n\n\n\n\nCox PH models\nIn the above example, I’ve shown how to perform temporal recalibration using flexible parametric survival models. However, temporal recalibration can also be applied when fitting PH Cox models. The only difference is that offset() is used instead of constraints().\nstset exit if val==0, origin(dx) fail(status==1) scale(365.25) ///\nexit(time min(dx+10*365.25,mdy(12,31,2019)))\n\nstcox age_centre female stage2 stage3\npredict lp_cox, xb\n\nstset exit if val==0, origin(dx) fail(status==1) scale(365.25) ///\nentry(time mdy(1,1,2015)) exit(time min(dx+10*365.25,mdy(12,31,2019)))\n\nstcox, estimate offset(lp_cox)"
  },
  {
    "objectID": "software/stpm2/temporal_recalibration.html#references",
    "href": "software/stpm2/temporal_recalibration.html#references",
    "title": "Temporal Recalibration",
    "section": "References",
    "text": "References\nArnold, M. et al. Progress in cancer survival, mortality, and incidence in seven high-income countries 1995-2014 (ICBP SURVMARK-2): a population-based study. The Lancet Oncology 2019; 20(11): 1493-1505\nBrenner, H. & Gefeller, O. An alternative approach to monitoring cancer patient survival. Cancer 1996; 78(9): 2004-2010\nBooth, S.; Riley, R. D.; Ensor, J.; Lambert P. C. & Rutherford, M. J. Temporal recalibration for improving prognostic model development and risk predictions in settings where survival is improving over time. International Journal of Epidemiology 2020; 49(4): 1316–1325"
  },
  {
    "objectID": "software/stpm2_standsurv.html",
    "href": "software/stpm2_standsurv.html",
    "title": "stpm2_standsurv",
    "section": "",
    "text": "This command is no longer updated and has been replaced by standsurv.\nWhen transferring my website to quarto, I did not update the pages as there are better, and more up-to-date versions, in the standsurv page page."
  },
  {
    "objectID": "software/stpm3/extended_functions.html",
    "href": "software/stpm3/extended_functions.html",
    "title": "Extended Functions",
    "section": "",
    "text": "A new addition to stpm3 is the use of extended functions within a model varlist. This allows you to specify various spline, polynomials, fractional polynomials functions directly when specifying the model. This makes fitting the model slightly easier, but the main advantage is the ease at which you can get predictions from complex models.\nWe first load the Rotterdam 2 breast cancer data and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott2b, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 60)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 60\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n        753  failures in single-record/single-failure data\n 13,038.968  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nIf you want to include a non-linear effect for a covariate in a model, the usual approach would be to generate some new derived variables and then include these in the model. For example, by generating a quadratic and cubic term or generating spline basis functions using mkspline or rcsgen.\nThe code below shows how to include non-linear effects using restricted cubic splines with rcsgen with 4 knots, which equates to 3 spline variables.\n. rcsgen age, gen(agercs) df(3)\nVariables agercs1 to agercs3 were created\n\n. global ageknots `r(knots)'\n\n. stpm3 i.hormon agercs1-agercs3, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n     agercs1 |  -.0430389   .0160545    -2.68   0.007    -.0745051   -.0115727\n     agercs2 |  -.0000314    .000038    -0.82   0.410    -.0001059    .0000432\n     agercs3 |  -1.70e-07   .0000357    -0.00   0.996    -.0000701    .0000697\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |   .3065984    .606017     0.51   0.613    -.8811731     1.49437\n------------------------------------------------------------------------------\n\n. estimates store stpm3_rcsgen\nI have stored the knot locations as these will be needed for certain predictions.\nTo fit an identical model, but using extended function we can use @rcs(age, df(3)) within an stpm3 varlist.\n. stpm3 i.hormon @rcs(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n_rcs_f1_age1 |  -.0430389   .0160545    -2.68   0.007    -.0745051   -.0115727\n_rcs_f1_age2 |  -.0000314    .000038    -0.82   0.410    -.0001059    .0000432\n_rcs_f1_age3 |  -1.70e-07   .0000357    -0.00   0.996    -.0000701    .0000697\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |   .3065984    .606017     0.51   0.613    -.8811731     1.49437\n------------------------------------------------------------------------------\nExtended functions\n (1) @rcs(age, df(3))\nIf you compare the model coefficients and log-likelihoods you will see they are identical.\nFrom here on I will use natural splines - these will give the same predicted values as when using restricted cubic splines, but have some useful additional properties.\n. stpm3 i.hormon @ns(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n _ns_f1_age1 |  -1.769774   1.089136    -1.62   0.104    -3.904441    .3648924\n _ns_f1_age2 |  -1.233782   .4602279    -2.68   0.007    -2.135812   -.3317519\n _ns_f1_age3 |  -1.709216   .4899396    -3.49   0.000     -2.66948   -.7489521\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |  -.1364105   .2354592    -0.58   0.562     -.597902     .325081\n------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n\n. estimates store stpm3_ns\nThe coefficients for the spline variables are now different, but if you predict for a specified covariate pattern, the predictions will be identical."
  },
  {
    "objectID": "software/stpm3/extended_functions.html#include-non-linear-function-in-a-varlist",
    "href": "software/stpm3/extended_functions.html#include-non-linear-function-in-a-varlist",
    "title": "Extended Functions",
    "section": "",
    "text": "A new addition to stpm3 is the use of extended functions within a model varlist. This allows you to specify various spline, polynomials, fractional polynomials functions directly when specifying the model. This makes fitting the model slightly easier, but the main advantage is the ease at which you can get predictions from complex models.\nWe first load the Rotterdam 2 breast cancer data and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott2b, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 60)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 60\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n        753  failures in single-record/single-failure data\n 13,038.968  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =         5\nIf you want to include a non-linear effect for a covariate in a model, the usual approach would be to generate some new derived variables and then include these in the model. For example, by generating a quadratic and cubic term or generating spline basis functions using mkspline or rcsgen.\nThe code below shows how to include non-linear effects using restricted cubic splines with rcsgen with 4 knots, which equates to 3 spline variables.\n. rcsgen age, gen(agercs) df(3)\nVariables agercs1 to agercs3 were created\n\n. global ageknots `r(knots)'\n\n. stpm3 i.hormon agercs1-agercs3, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n     agercs1 |  -.0430389   .0160545    -2.68   0.007    -.0745051   -.0115727\n     agercs2 |  -.0000314    .000038    -0.82   0.410    -.0001059    .0000432\n     agercs3 |  -1.70e-07   .0000357    -0.00   0.996    -.0000701    .0000697\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |   .3065984    .606017     0.51   0.613    -.8811731     1.49437\n------------------------------------------------------------------------------\n\n. estimates store stpm3_rcsgen\nI have stored the knot locations as these will be needed for certain predictions.\nTo fit an identical model, but using extended function we can use @rcs(age, df(3)) within an stpm3 varlist.\n. stpm3 i.hormon @rcs(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n_rcs_f1_age1 |  -.0430389   .0160545    -2.68   0.007    -.0745051   -.0115727\n_rcs_f1_age2 |  -.0000314    .000038    -0.82   0.410    -.0001059    .0000432\n_rcs_f1_age3 |  -1.70e-07   .0000357    -0.00   0.996    -.0000701    .0000697\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |   .3065984    .606017     0.51   0.613    -.8811731     1.49437\n------------------------------------------------------------------------------\nExtended functions\n (1) @rcs(age, df(3))\nIf you compare the model coefficients and log-likelihoods you will see they are identical.\nFrom here on I will use natural splines - these will give the same predicted values as when using restricted cubic splines, but have some useful additional properties.\n. stpm3 i.hormon @ns(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2120.3306  \nIteration 1:  Log likelihood = -2120.0705  \nIteration 2:  Log likelihood = -2120.0694  \nIteration 3:  Log likelihood = -2120.0694  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(4)  =  69.03\nLog likelihood = -2120.0694                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3966145   .1041656     3.81   0.000     .1924536    .6007754\n _ns_f1_age1 |  -1.769774   1.089136    -1.62   0.104    -3.904441    .3648924\n _ns_f1_age2 |  -1.233782   .4602279    -2.68   0.007    -2.135812   -.3317519\n _ns_f1_age3 |  -1.709216   .4899396    -3.49   0.000     -2.66948   -.7489521\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -22.10362   2.190797   -10.09   0.000    -26.39751   -17.80974\n        _ns2 |   6.252487    1.18838     5.26   0.000     3.923304     8.58167\n        _ns3 |  -1.093169   .0583025   -18.75   0.000    -1.207439   -.9788977\n        _ns4 |  -.5425182   .0376756   -14.40   0.000    -.6163609   -.4686754\n        _ns5 |   -.376672   .0361107   -10.43   0.000    -.4474477   -.3058964\n       _cons |  -.1364105   .2354592    -0.58   0.562     -.597902     .325081\n------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n\n. estimates store stpm3_ns\nThe coefficients for the spline variables are now different, but if you predict for a specified covariate pattern, the predictions will be identical."
  },
  {
    "objectID": "software/stpm3/extended_functions.html#predictions-with-extended-functions",
    "href": "software/stpm3/extended_functions.html#predictions-with-extended-functions",
    "title": "Extended Functions",
    "section": "Predictions with extended functions",
    "text": "Predictions with extended functions\nIf we generated the spline variables for age at diagnosis and then included these in the model, we would have to work out the values of the spline variables at the age at diagnosis of interest. For example, using the scalar option of rcsgen to predict survival for a 70 year old on hormonal treatment the code below can be used.\n. estimates restore stpm3_rcsgen\n(results stpm3_rcsgen are active now)\n\n. rcsgen, scalar(70) gen(c) knots(${ageknots})\nScalars c1 to c3 were created\n\n. predict S70a, survival ci                                             ///\n&gt;               at1(agercs1 `=c1' agercs2 `=c2' agercs3 `=c3' hormon 1) ///\n&gt;               timevar(0 5, step(0.1))                                 ///\n&gt;               frame(f1)\nPredictions are stored in frame - f1\nBy storing the knots and passing these to rcsgen combined with the scalar option, the values of the restricted cubic spline variables for a 70 year old are obtained. These can then be passed to the predict command.\nIf you use an extended function to fit an equivalent model this simplifies the predictions. For example predicting for a 70 year old woman on hormonal treatment we can use the following predict command.\n. estimates restore stpm3_ns\n(results stpm3_ns are active now)\n\n. predict S70b, survival ci          ///\n&gt;               at1(age 70 hormon 1) ///\n&gt;               frame(f1, merge)\nPredictions are stored in frame - f1\nThese predictions have been merged into frame f1, so we can compare the predictions.\n. frame f1: list in 1/21, noobs\n\n  +-----------------------------------------------------------------------------+\n  |  tt        S70a    S70a_lci    S70a_uci        S70b    S70b_lci    S70b_uci |\n  |-----------------------------------------------------------------------------|\n  |   0           1           1           1           1           1           1 |\n  |  .1   .99980531   .99901994   .99996134   .99980531   .99901994   .99996134 |\n  |  .2    .9990375   .99724993   .99966333    .9990375   .99724993   .99966333 |\n  |  .3   .99757461   .99484041   .99886071   .99757461   .99484041   .99886071 |\n  |  .4   .99537568   .99175595   .99740816   .99537568   .99175595   .99740816 |\n  |-----------------------------------------------------------------------------|\n  |  .5   .99243419   .98793852   .99525821   .99243419   .98793852   .99525821 |\n  |  .6   .98876195   .98333349   .99242911   .98876195   .98333349   .99242911 |\n  |  .7   .98438145   .97790805    .9889687   .98438145   .97790805    .9889687 |\n  |  .8   .97932165   .97166223   .98492686   .97932165   .97166223   .98492686 |\n  |  .9   .97361549   .96462911   .98034204   .97361549   .96462911   .98034204 |\n  |-----------------------------------------------------------------------------|\n  |   1   .96729824   .95686644   .97523978   .96729824   .95686644   .97523978 |\n  | 1.1   .96040644   .94844522     .969637   .96040644   .94844522     .969637 |\n  | 1.2   .95297712   .93943933   .96354746   .95297712   .93943933   .96354746 |\n  | 1.3   .94504732   .92991782   .95698631   .94504732   .92991782   .95698631 |\n  | 1.4   .93665358   .91993953    .9499734   .93665358   .91993953    .9499734 |\n  |-----------------------------------------------------------------------------|\n  | 1.5   .92783183   .90954967   .94253584   .92783183   .90954967   .94253584 |\n  | 1.6   .91861703   .89877754   .93470981   .91861703   .89877754   .93470981 |\n  | 1.7   .90904198   .88763238   .92654197   .90904198   .88763238   .92654197 |\n  | 1.8   .89913147   .87609834   .91808407   .89913147   .87609834   .91808407 |\n  | 1.9   .88890629   .86417228   .90937397   .88890629   .86417228   .90937397 |\n  |-----------------------------------------------------------------------------|\n  |   2   .87838596   .85187732   .90042978   .87838596   .85187732   .90042978 |\n  +-----------------------------------------------------------------------------+\nThe predictions are identical, but obtaining the predictions using extended functions was much easier. If the model includes interactions then I would say it is much, much easier and less prone to coding errors.\nThe current extended functions are\n\n\n\n@bs()\nB-splines\n\n\n@fn()\ngeneral transformation\n\n\n@fp()\nfractional polynomials\n\n\n@ns()\nnatural cubic splines\n\n\n@poly()\npolynomials\n\n\n@rcs()\nrestricted cubic splines\n\n\n\nSee the help file for options for each of these functions. For example, with the spline functions you specify knots positions or the degree for B-splines. For fractional polynomials there are scale and center options. For all extended functions, except fractional polynomials, it is possible to perform winsorising before the derived variables are generated using the winsor() option."
  },
  {
    "objectID": "software/stpm3/extended_functions.html#predictions-in-more-complex-models",
    "href": "software/stpm3/extended_functions.html#predictions-in-more-complex-models",
    "title": "Extended Functions",
    "section": "Predictions in more complex models",
    "text": "Predictions in more complex models\nIf the model get complex with numerous interactions and non-linear effects and interactions with time, the predictions remain simple.\nConsider the model below with main effects and an interaction between hormon and a natural spline function for age. stpm3 stores the details of the extended function and so when predictions are made the appropriate values of the derived variables can be obtained.\nIn the code below, I obtain predictions for 70 year old women with and without hormonal treatment.\n. stpm3 i.hormon##@ns(age, df(3)), scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2117.3742  \nIteration 1:  Log likelihood = -2117.1157  \nIteration 2:  Log likelihood = -2117.1148  \nIteration 3:  Log likelihood = -2117.1148  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(7)  =  77.72\nLog likelihood = -2117.1148                             Prob &gt; chi2   = 0.0000\n\n--------------------------------------------------------------------------------------\n                     | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n---------------------+----------------------------------------------------------------\nxb                   |\n              hormon |\n                yes  |   1.295954   .5457098     2.37   0.018      .226382    2.365525\n         _ns_f1_age1 |  -1.006332    1.17959    -0.85   0.394    -3.318285    1.305621\n         _ns_f1_age2 |  -1.519938    .473222    -3.21   0.001    -2.447436   -.5924397\n         _ns_f1_age3 |  -1.322119   .5553445    -2.38   0.017    -2.410574   -.2336639\n                     |\nhormon#c._ns_f1_age1 |\n                yes  |  -6.312222    4.38403    -1.44   0.150    -14.90476    2.280319\n                     |\nhormon#c._ns_f1_age2 |\n                yes  |   3.192456   2.152641     1.48   0.138    -1.026642    7.411555\n                     |\nhormon#c._ns_f1_age3 |\n                yes  |  -2.436599   1.186322    -2.05   0.040    -4.761746   -.1114511\n---------------------+----------------------------------------------------------------\ntime                 |\n                _ns1 |  -22.10808   2.190478   -10.09   0.000    -26.40134   -17.81483\n                _ns2 |   6.252367   1.188247     5.26   0.000     3.923447    8.581288\n                _ns3 |  -1.094601   .0583504   -18.76   0.000    -1.208966   -.9802364\n                _ns4 |  -.5429931   .0377085   -14.40   0.000    -.6169004   -.4690859\n                _ns5 |  -.3770147   .0361414   -10.43   0.000    -.4478506   -.3061788\n               _cons |  -.2889299   .2699311    -1.07   0.284    -.8179851    .2401253\n--------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n\n. \n. predict S70h0 S70h1, survival ci              ///\n&gt;                      at1(age 70 hormon 0)     ///\n&gt;                      at2(age 70 hormon 1)     ///\n&gt;                      timevar(0 5, step(0.1))  ///\n&gt;                      frame(f2)\nPredictions are stored in frame - f2\nThe nice thing here is that thehe predict command would be identical if there was no interaction.\nEven if there are time-dependent effects, the predict statement does not change. The model below adds an interaction for the time-dependent effects for hormon and age.\n. stpm3 i.hormon##@ns(age, df(3)),                 ///\n&gt;       tvc(i.hormon##@ns(age, df(2))) dftvc(2)    ///\n&gt;       scale(lncumhazard) df(5)                           \n\nIteration 0:  Log likelihood = -2116.6275  \nIteration 1:  Log likelihood = -2107.5573  \nIteration 2:  Log likelihood = -2103.0051  \nIteration 3:  Log likelihood = -2102.7883  \nIteration 4:  Log likelihood = -2102.7869  \nIteration 5:  Log likelihood = -2102.7869  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(7)  =  74.61\nLog likelihood = -2102.7869                             Prob &gt; chi2   = 0.0000\n\n-------------------------------------------------------------------------------------------------\n                                | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------------------+----------------------------------------------------------------\nxb                              |\n                         hormon |\n                           yes  |     1.2372    .559703     2.21   0.027     .1402021    2.334198\n                    _ns_f1_age1 |  -.9347474    1.18498    -0.79   0.430    -3.257267    1.387772\n                    _ns_f1_age2 |  -1.538365   .4738744    -3.25   0.001    -2.467142   -.6095881\n                    _ns_f1_age3 |  -1.308583   .5588214    -2.34   0.019    -2.403853   -.2133128\n                                |\n           hormon#c._ns_f1_age1 |\n                           yes  |  -5.991194   4.385156    -1.37   0.172    -14.58594    2.603554\n                                |\n           hormon#c._ns_f1_age2 |\n                           yes  |   3.188885   2.145601     1.49   0.137    -1.016415    7.394185\n                                |\n           hormon#c._ns_f1_age3 |\n                           yes  |  -2.318151   1.205093    -1.92   0.054    -4.680089    .0437866\n--------------------------------+----------------------------------------------------------------\ntime                            |\n                           _ns1 |  -19.18669   7.212764    -2.66   0.008    -33.32345   -5.049932\n                           _ns2 |   5.607982   3.176181     1.77   0.077    -.6172182    11.83318\n                           _ns3 |   -1.05599   .2202421    -4.79   0.000    -1.487656    -.624323\n                           _ns4 |  -.5553481   .1523431    -3.65   0.000    -.8539351   -.2567611\n                           _ns5 |  -.3960238   .1116303    -3.55   0.000    -.6148151   -.1772324\n                                |\n              hormon#c._ns_tvc1 |\n                           yes  |   4.903816   4.856667     1.01   0.313    -4.615075    14.42271\n                                |\n              hormon#c._ns_tvc2 |\n                           yes  |   .0799753   1.642765     0.05   0.961    -3.139786    3.299736\n                                |\n       c._ns_f2_age1#c._ns_tvc1 |  -29.15335   8.875221    -3.28   0.001    -46.54847   -11.75824\n                                |\n       c._ns_f2_age1#c._ns_tvc2 |   .6654049   1.325155     0.50   0.616     -1.93185     3.26266\n                                |\n       c._ns_f2_age2#c._ns_tvc1 |  -.8954604   11.34532    -0.08   0.937    -23.13188    21.34096\n                                |\n       c._ns_f2_age2#c._ns_tvc2 |   .3600924   2.127002     0.17   0.866    -3.808755     4.52894\n                                |\nhormon#c._ns_f2_age1#c._ns_tvc1 |\n                           yes  |  -117.1348   72.85753    -1.61   0.108    -259.9329    25.66332\n                                |\nhormon#c._ns_f2_age1#c._ns_tvc2 |\n                           yes  |  -.4836296   6.116531    -0.08   0.937    -12.47181    11.50455\n                                |\nhormon#c._ns_f2_age2#c._ns_tvc1 |\n                           yes  |  -5.302671   20.04585    -0.26   0.791    -44.59182    33.98648\n                                |\nhormon#c._ns_f2_age2#c._ns_tvc2 |\n                           yes  |  -1.511553   5.134032    -0.29   0.768    -11.57407    8.550965\n                                |\n                          _cons |  -.3015535   .2724136    -1.11   0.268    -.8354743    .2323674\n-------------------------------------------------------------------------------------------------\nExtended functions\n (1) @ns(age, df(3))\n (2) @ns(age, df(2))\n\n.       \n. predict S70h0 S70h1, survival ci                ///\n&gt;                      at1(age 70 hormon 0)       ///\n&gt;                      at2(age 70 hormon 1)       ///\n&gt;                      timevar(0 5, step(0.1))    ///\n&gt;                      frame(f3)\nPredictions are stored in frame - f3\nThe key point is that the predict command stays simple. Note that I use a different function for the time-dependent effect, so two @ns() functions at the end of the model output.\nFinally I will fit a model with a spline function that winsorises the variables before the spline basis functions are generated. This can improve model stability in the tails in complex models. I use B-splines rather than natural splines for the effect of age.\n. stpm3 i.hormon##@bs(age, df(3) degree(2) winsor(2 98)), ///\n&gt;       scale(lncumhazard) df(5)                           \n\nIteration 0:  Log likelihood = -2117.8269  \nIteration 1:  Log likelihood = -2117.5679  \nIteration 2:  Log likelihood = -2117.5669  \nIteration 3:  Log likelihood = -2117.5669  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(7)  =  75.27\nLog likelihood = -2117.5669                             Prob &gt; chi2   = 0.0000\n\n--------------------------------------------------------------------------------------\n                     | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n---------------------+----------------------------------------------------------------\nxb                   |\n              hormon |\n                yes  |  -.2013625   .8479376    -0.24   0.812     -1.86329    1.460565\n         _bs_f1_age1 |   -.789629   .2399149    -3.29   0.001    -1.259854   -.3194044\n         _bs_f1_age2 |  -.3251852   .1782746    -1.82   0.068     -.674597    .0242265\n         _bs_f1_age3 |   .2358417   .2106851     1.12   0.263    -.1770935     .648777\n                     |\nhormon#c._bs_f1_age1 |\n                yes  |    1.71135   1.096385     1.56   0.119    -.4375242    3.860225\n                     |\nhormon#c._bs_f1_age2 |\n                yes  |  -.2149046   .8373336    -0.26   0.797    -1.856048    1.426239\n                     |\nhormon#c._bs_f1_age3 |\n                yes  |   .9610499   .9192863     1.05   0.296    -.8407181    2.762818\n---------------------+----------------------------------------------------------------\ntime                 |\n                _ns1 |  -22.10814   2.191013   -10.09   0.000    -26.40245   -17.81384\n                _ns2 |   6.253144   1.188507     5.26   0.000     3.923714    8.582574\n                _ns3 |  -1.093972   .0583289   -18.76   0.000    -1.208295   -.9796495\n                _ns4 |  -.5428561   .0376962   -14.40   0.000    -.6167393   -.4689729\n                _ns5 |  -.3769876   .0361375   -10.43   0.000    -.4478158   -.3061593\n               _cons |  -.9075211   .1468767    -6.18   0.000    -1.195394   -.6196481\n--------------------------------------------------------------------------------------\nExtended functions\n (1) @bs(age, df(3) degree(2) winsor(2 98))\n\n.       \n. predict S70h0 S70h1, survival ci                 ///\n&gt;                      at1(age 70 hormon 0)        ///\n&gt;                      at2(age 70 hormon 1)        ///\n&gt;                      timevar(0 5, step(0.1))     ///\n&gt;                      frame(f4)\nPredictions are stored in frame - f4\nThe winsor(2 98) option replaces values less than the 2nd centile with the value at the 2nd centile and values greater than the 98th centile with the values at the 98th centile. There is a values suboption where you can directly specifying values for the cutoffs rather than centiles.\nAgain, the key point here is that the predict commands does not change."
  },
  {
    "objectID": "software/stpm3/predictions.html",
    "href": "software/stpm3/predictions.html",
    "title": "Using frames for predictions",
    "section": "",
    "text": "Predictions are much improved in stpm3.\nWe first load the Rotterdam breast cancer data and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nI will fit a simple proportional hazards model just include hormon and age.\n. stpm3 i.hormon age, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2909.4582  \nIteration 1:  Log likelihood = -2908.4666  \nIteration 2:  Log likelihood = -2908.4635  \nIteration 3:  Log likelihood = -2908.4635  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(2)  =  64.07\nLog likelihood = -2908.4635                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3229905   .0876157     3.69   0.000     .1512669    .4947141\n         age |   .0149851    .002374     6.31   0.000     .0103322    .0196381\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -24.01501   1.921081   -12.50   0.000    -27.78026   -20.24976\n        _ns2 |   6.695913   1.028047     6.51   0.000     4.680978    8.710849\n        _ns3 |  -1.221354   .0499264   -24.46   0.000    -1.319208   -1.123501\n        _ns4 |  -.8156036   .0389592   -20.93   0.000    -.8919622   -.7392449\n        _ns5 |  -.5046344   .0422296   -11.95   0.000     -.587403   -.4218658\n       _cons |  -1.391522   .1368464   -10.17   0.000    -1.659736   -1.123308\n------------------------------------------------------------------------------\nWe can predict the survival function for a 60 year old women who did not take hormon therapy using,\n. predict S, survival ci                 ///\n&gt;            at1(age 60 hormon 0)        ///\n&gt;            timevar(0 10, step(0.1)) \nPredictions are stored in frame - stpm3_pred\nThe predict command has requested a survival function with a 95% confidence interval. The values of the covariates to predict at are given in the at1() option. It is possible to have multiple at options. The predictions will be at times between 0 and 10 in steps of 0.1, leading to 101 observations.\nWe can list or plot the results in frame stpm3_pred.\n. frame stpm3_pred: list in 1/21, noobs\n\n  +-----------------------------------------+\n  |  tt           S       S_lci       S_uci |\n  |-----------------------------------------|\n  |   0           1           1           1 |\n  |  .1   .99987272   .99948675   .99996844 |\n  |  .2   .99939144   .99844378   .99976209 |\n  |  .3   .99849308    .9969857   .99924694 |\n  |  .4   .99715658   .99513109   .99834016 |\n  |-----------------------------------------|\n  |  .5   .99537771   .99288014   .99700048 |\n  |  .6   .99316099   .99022634    .9952166 |\n  |  .7   .99051598   .98716155   .99299707 |\n  |  .8   .98745529   .98367965   .99036174 |\n  |  .9   .98399346   .97977945   .98733494 |\n  |-----------------------------------------|\n  |   1   .98014617   .97546655   .98394053 |\n  | 1.1   .97592979    .9707539   .98019903 |\n  | 1.2   .97136109   .96566103    .9761267 |\n  | 1.3   .96645696   .96021236   .97173595 |\n  | 1.4   .96123425   .95443524   .96703632 |\n  |-----------------------------------------|\n  | 1.5   .95570969   .94835805   .96203579 |\n  | 1.6   .94989974    .9420086   .95674187 |\n  | 1.7   .94382061   .93541289   .95116257 |\n  | 1.8   .93748813   .92859406   .94530721 |\n  | 1.9   .93091774   .92157156   .93918715 |\n  |-----------------------------------------|\n  |   2   .92412448   .91436051   .93281647 |\n  +-----------------------------------------+\nstpm3 saves predictions to a new frame by default. The default name for the prediction frame is stpm3_pred, but you can, and generally should, choose a frame name using the frame() option.\n. predict S1, survival ci               ///\n&gt;             at1(age 60 hormon 0)      ///\n&gt;             timevar(0 10, step(0.1))  ///\n&gt;             frame(f1)\nPredictions are stored in frame - f1"
  },
  {
    "objectID": "software/stpm3/predictions.html#stpm3-makes-use-of-frames-for-predictions",
    "href": "software/stpm3/predictions.html#stpm3-makes-use-of-frames-for-predictions",
    "title": "Using frames for predictions",
    "section": "",
    "text": "Predictions are much improved in stpm3.\nWe first load the Rotterdam breast cancer data and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott3, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nI will fit a simple proportional hazards model just include hormon and age.\n. stpm3 i.hormon age, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2909.4582  \nIteration 1:  Log likelihood = -2908.4666  \nIteration 2:  Log likelihood = -2908.4635  \nIteration 3:  Log likelihood = -2908.4635  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(2)  =  64.07\nLog likelihood = -2908.4635                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |\n        yes  |   .3229905   .0876157     3.69   0.000     .1512669    .4947141\n         age |   .0149851    .002374     6.31   0.000     .0103322    .0196381\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -24.01501   1.921081   -12.50   0.000    -27.78026   -20.24976\n        _ns2 |   6.695913   1.028047     6.51   0.000     4.680978    8.710849\n        _ns3 |  -1.221354   .0499264   -24.46   0.000    -1.319208   -1.123501\n        _ns4 |  -.8156036   .0389592   -20.93   0.000    -.8919622   -.7392449\n        _ns5 |  -.5046344   .0422296   -11.95   0.000     -.587403   -.4218658\n       _cons |  -1.391522   .1368464   -10.17   0.000    -1.659736   -1.123308\n------------------------------------------------------------------------------\nWe can predict the survival function for a 60 year old women who did not take hormon therapy using,\n. predict S, survival ci                 ///\n&gt;            at1(age 60 hormon 0)        ///\n&gt;            timevar(0 10, step(0.1)) \nPredictions are stored in frame - stpm3_pred\nThe predict command has requested a survival function with a 95% confidence interval. The values of the covariates to predict at are given in the at1() option. It is possible to have multiple at options. The predictions will be at times between 0 and 10 in steps of 0.1, leading to 101 observations.\nWe can list or plot the results in frame stpm3_pred.\n. frame stpm3_pred: list in 1/21, noobs\n\n  +-----------------------------------------+\n  |  tt           S       S_lci       S_uci |\n  |-----------------------------------------|\n  |   0           1           1           1 |\n  |  .1   .99987272   .99948675   .99996844 |\n  |  .2   .99939144   .99844378   .99976209 |\n  |  .3   .99849308    .9969857   .99924694 |\n  |  .4   .99715658   .99513109   .99834016 |\n  |-----------------------------------------|\n  |  .5   .99537771   .99288014   .99700048 |\n  |  .6   .99316099   .99022634    .9952166 |\n  |  .7   .99051598   .98716155   .99299707 |\n  |  .8   .98745529   .98367965   .99036174 |\n  |  .9   .98399346   .97977945   .98733494 |\n  |-----------------------------------------|\n  |   1   .98014617   .97546655   .98394053 |\n  | 1.1   .97592979    .9707539   .98019903 |\n  | 1.2   .97136109   .96566103    .9761267 |\n  | 1.3   .96645696   .96021236   .97173595 |\n  | 1.4   .96123425   .95443524   .96703632 |\n  |-----------------------------------------|\n  | 1.5   .95570969   .94835805   .96203579 |\n  | 1.6   .94989974    .9420086   .95674187 |\n  | 1.7   .94382061   .93541289   .95116257 |\n  | 1.8   .93748813   .92859406   .94530721 |\n  | 1.9   .93091774   .92157156   .93918715 |\n  |-----------------------------------------|\n  |   2   .92412448   .91436051   .93281647 |\n  +-----------------------------------------+\nstpm3 saves predictions to a new frame by default. The default name for the prediction frame is stpm3_pred, but you can, and generally should, choose a frame name using the frame() option.\n. predict S1, survival ci               ///\n&gt;             at1(age 60 hormon 0)      ///\n&gt;             timevar(0 10, step(0.1))  ///\n&gt;             frame(f1)\nPredictions are stored in frame - f1"
  },
  {
    "objectID": "software/stpm3/predictions.html#merging-to-an-existing-frame",
    "href": "software/stpm3/predictions.html#merging-to-an-existing-frame",
    "title": "Using frames for predictions",
    "section": "Merging to an existing frame",
    "text": "Merging to an existing frame\nOne feature is that you can merge new predictions to an existing frame. When you do this the time variable stored in the existing frame will be used. For example, we could predict for a 70 year old woman and merge with frame f1.\n. predict S2, survival ci                 ///\n&gt;             at1(age 70 hormon 0)        ///\n&gt;             frame(f1, merge)\nPredictions are stored in frame - f1"
  },
  {
    "objectID": "software/stpm3/predictions.html#plotting-from-a-frame",
    "href": "software/stpm3/predictions.html#plotting-from-a-frame",
    "title": "Using frames for predictions",
    "section": "Plotting from a frame",
    "text": "Plotting from a frame\nIt is simple to plot the predictions stored in a frame.\n. frame f1 {\n.   twoway line S1 S2 tt,                        ///\n&gt;          xtitle(Years since surgery)           ///\n&gt;          ytitle(Survival function)             ///\n&gt;          ylabel(0(0.2)1, format(%3.1f))        ///\n&gt;          legend(order(1 \"Age 60\" 2 \"Age 70\"))\n. }"
  },
  {
    "objectID": "software/stpm3/predictions.html#using-multiple-at-options",
    "href": "software/stpm3/predictions.html#using-multiple-at-options",
    "title": "Using frames for predictions",
    "section": "Using multiple `at’ options",
    "text": "Using multiple `at’ options\nNote that when using predict you can specify multiple at() options, which is often easier than having multiple predict commands. Below I use frame(f1, replace) to replace the existing frame f1.\n. predict S1 S2, survival ci                 ///\n&gt;                at1(age 60 hormon 0)        ///\n&gt;                at2(age 70 hormon 0)        ///\n&gt;                timevar(0 10, step(0.1))    ///\n&gt;                frame(f1, replace)\nPredictions are stored in frame - f1\nI will cover more details about multiple at() options when I discuss contrasts."
  },
  {
    "objectID": "software/stpm3/predictions.html#merging-a-different-type-of-prediction",
    "href": "software/stpm3/predictions.html#merging-a-different-type-of-prediction",
    "title": "Using frames for predictions",
    "section": "Merging a different type of prediction",
    "text": "Merging a different type of prediction\nUsing frame(..., merge) is useful when you require predictions of different types, for example when requiring predictions of both survival and hazard functions. The predictions for the hazard functions are merged with the survival predictions below.\n. predict h1 h2, hazard ci                   ///\n&gt;                at1(age 60 hormon 0)        ///\n&gt;                at2(age 70 hormon 0)        ///\n&gt;                frame(f1, merge)\nPredictions are stored in frame - f1\nAlternatively you may want to predict the hazard function to a new frame."
  },
  {
    "objectID": "software/stpm3/predictions.html#predicting-to-the-active-frame",
    "href": "software/stpm3/predictions.html#predicting-to-the-active-frame",
    "title": "Using frames for predictions",
    "section": "Predicting to the active frame",
    "text": "Predicting to the active frame\nSometimes you may want to merge the predictions into the active frame rather than create a new frame. You can do this with the merge option. This could be useful if you wanted to predict at each observed value in a dataset, for example at the observed event/censoring times (_t), or at a specific value of time.\nThe code below, predicts 10 year survival for each observation in the dataset.\n. predict S10, survival ci          ///\n&gt;              at1(.)               ///\n&gt;              timevar(10)          ///\n&gt;              merge\nNote that only one value of time has been specified in the timevar() option The default is to predict at this time for all individuals. The at1(.) option means that predictions will be at observed values of covariates rather than values specifed by the user.\nWe could plot a histogram of the 10 year survival probabilities.\n. hist S10\n(bin=34, start=.2766368, width=.01245414)"
  },
  {
    "objectID": "software/stpm3/scale_option.html",
    "href": "software/stpm3/scale_option.html",
    "title": "Change to the scale() option",
    "section": "",
    "text": "The scale() option has changed\nIn stpm2 the choice of options when using the scale() option included hazard and odds. These really meant log cumulative hazard and log odds respectively.\nIn stpm3 you need to refer to these models as scale(lncumhazard) or scale(lnodds). This is because stpm3 allows models to be fitted on the log hazard scale (scale(lnhazard)) and thus there is a need to distinguish between models on the log cumulative hazard and log hazard scales.\nWe first load the example Rotterdam breast cancer data (rott3.dta) and then use stset to declare the survival time and event indicator.\n. use https://www.pclambert.net/data/rott2b, clear\n(Rotterdam breast cancer data (augmented with cause of death))\n\n. stset os, f(osi==1) scale(12) exit(time 120)\n\nSurvival-time data settings\n\n         Failure event: osi==1\nObserved time interval: (0, os]\n     Exit on or before: time 120\n     Time for analysis: time/12\n\n--------------------------------------------------------------------------\n      2,982  total observations\n          0  exclusions\n--------------------------------------------------------------------------\n      2,982  observations remaining, representing\n      1,171  failures in single-record/single-failure data\n 20,002.424  total analysis time at risk and under observation\n                                                At risk from t =         0\n                                     Earliest observed entry t =         0\n                                          Last observed exit t =        10\nThe scale(12) option converts the times recorded in months to years.\nTo fit an stpm2 model we would use,\n. stpm2 hormon, scale(hazard) df(5) \n\nIteration 0:  Log likelihood = -2929.2995  \nIteration 1:  Log likelihood = -2928.2998  \nIteration 2:  Log likelihood = -2928.2966  \nIteration 3:  Log likelihood = -2928.2966  \n\nLog likelihood = -2928.2966                              Number of obs = 2,982\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |   .4321954   .0861189     5.02   0.000     .2634054    .6009854\n       _rcs1 |    .914158   .0273548    33.42   0.000     .8605436    .9677725\n       _rcs2 |   .1672938   .0273886     6.11   0.000     .1136131    .2209746\n       _rcs3 |   .0360402   .0154393     2.33   0.020     .0057797    .0663006\n       _rcs4 |  -.0113638    .007644    -1.49   0.137    -.0263459    .0036182\n       _rcs5 |   .0058281   .0049328     1.18   0.237    -.0038401    .0154963\n       _cons |  -1.225443   .0332548   -36.85   0.000    -1.290622   -1.160265\n------------------------------------------------------------------------------\nThe equivalent model in stpm3 is,\n. stpm3 hormon, scale(lncumhazard) df(5) \n\nIteration 0:  Log likelihood = -2929.2995  \nIteration 1:  Log likelihood = -2928.2998  \nIteration 2:  Log likelihood = -2928.2966  \nIteration 3:  Log likelihood = -2928.2966  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  25.19\nLog likelihood = -2928.2966                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |   .4321954   .0861189     5.02   0.000     .2634054    .6009854\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |   -23.9834    1.92113   -12.48   0.000    -27.74874   -20.21805\n        _ns2 |   6.695765   1.027919     6.51   0.000     4.681082    8.710449\n        _ns3 |  -1.214676   .0497438   -24.42   0.000    -1.312172    -1.11718\n        _ns4 |  -.8095755   .0387379   -20.90   0.000    -.8855004   -.7336505\n        _ns5 |  -.4994385   .0418591   -11.93   0.000    -.5814808   -.4173963\n       _cons |  -.5713643   .0332128   -17.20   0.000    -.6364603   -.5062684\n------------------------------------------------------------------------------\nNote the log-likelihoods are identical as are the coefficients/standard errors for hormon. Note that different basis functions are used, so the coefficients for the spline terms are different. However, predicted values for the same covariate pattern will not differ.\nTo fit a model on the log hazard scale use scale(lnhazard),\n. stpm3 hormon, scale(lnhazard) df(5) \n\nIteration 0:  Log likelihood = -15102.783  \nIteration 1:  Log likelihood = -3027.1718  \nIteration 2:  Log likelihood = -2947.4369  \nIteration 3:  Log likelihood = -2932.3794  \nIteration 4:  Log likelihood =  -2930.192  \nIteration 5:  Log likelihood = -2930.1318  \nIteration 6:  Log likelihood = -2930.1318  \n\n                                                        Number of obs =  2,982\n                                                        Wald chi2(1)  =  25.25\nLog likelihood = -2930.1318                             Prob &gt; chi2   = 0.0000\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n      hormon |    .432754   .0861241     5.02   0.000     .2639539    .6015541\n-------------+----------------------------------------------------------------\ntime         |\n        _ns1 |  -8.918703   1.582022    -5.64   0.000    -12.01941   -5.817997\n        _ns2 |     4.3015   .9609478     4.48   0.000     2.418077    6.184923\n        _ns3 |   .3920384    .185592     2.11   0.035     .0282847     .755792\n        _ns4 |   .1022445   .1620363     0.63   0.528    -.2153409    .4198298\n        _ns5 |   .0909831   .3382751     0.27   0.788     -.572024    .7539901\n       _cons |  -2.913227   .1465419   -19.88   0.000    -3.200443    -2.62601\n------------------------------------------------------------------------------\nQuadrature method: tanh-sinh with 30 nodes.\nAnalytical integration before first and after last knot."
  },
  {
    "objectID": "software/stpm3.html",
    "href": "software/stpm3.html",
    "title": "stpm3",
    "section": "",
    "text": "stpm3 fits flexible parametric survival models. These models use splines to model the effect of the time scale. stpm3 replaces stpm2, though stpm2 will continue to be available on SSC.\nI have added some examples to explain some of the features of stpm3 and differences to stpm2."
  },
  {
    "objectID": "software/stpm3.html#fitting-stpm3-models.",
    "href": "software/stpm3.html#fitting-stpm3-models.",
    "title": "stpm3",
    "section": "Fitting stpm3 models.",
    "text": "Fitting stpm3 models.\n\nChange to the scale option\nUse of factor variables"
  },
  {
    "objectID": "software/stpm3.html#predictions-conditional-on-covariate-values",
    "href": "software/stpm3.html#predictions-conditional-on-covariate-values",
    "title": "stpm3",
    "section": "Predictions (conditional on covariate values)",
    "text": "Predictions (conditional on covariate values)\n\nFrames for prediction\nExtended functions\nMultiple at options and contrasts\nRelative survival models"
  },
  {
    "objectID": "software/stpm3.html#marginal-predictions",
    "href": "software/stpm3.html#marginal-predictions",
    "title": "stpm3",
    "section": "Marginal predictions",
    "text": "Marginal predictions\n\nUsing standsurv with factor variables"
  },
  {
    "objectID": "software/stpm3.html#other-details",
    "href": "software/stpm3.html#other-details",
    "title": "stpm3",
    "section": "Other Details",
    "text": "Other Details\n\n[Numerical integration for models on log hazard scale]"
  },
  {
    "objectID": "software/stpm3.html#releases",
    "href": "software/stpm3.html#releases",
    "title": "stpm3",
    "section": "Releases",
    "text": "Releases\nSee stpm3_releases.txt"
  },
  {
    "objectID": "software/stpp.html",
    "href": "software/stpp.html",
    "title": "stpp",
    "section": "",
    "text": "stpp calculates the Pohar-Perme non-parametric estimate of marginal relative survival, which under assumptions can be interpreted as marginal net survival. The estimate is a step function and changes at each event time. This is a different implementation to strs and stnet where the time-scale is split into a number of intervals. stns is another command that can be used to give an estimate of marginal relative survival. The motivation for developing stpp was to directly standardize the estimates using both traditional standardization and by using individual weights and to extend to estimation of other related measures. The other measures include crude probabilities and the ability to incorporate a second expected rate file, which can be used to estimate measures defined by Sasieni and Brentnall and non-parametric estimates of reference adjusted measures.\nThe single example currently just replicates the help file, but with some added description."
  },
  {
    "objectID": "software/stpp.html#examples",
    "href": "software/stpp.html#examples",
    "title": "stpp",
    "section": "Examples",
    "text": "Examples\n\nBasic examples\n\nUsing stpp\nAll cause and crude probabilities\nReference adjusted all cause and crude probabilities"
  },
  {
    "objectID": "software/stpp.html#releases",
    "href": "software/stpp.html#releases",
    "title": "stpp",
    "section": "Releases",
    "text": "Releases\nSee stpp_releases.txt"
  }
]